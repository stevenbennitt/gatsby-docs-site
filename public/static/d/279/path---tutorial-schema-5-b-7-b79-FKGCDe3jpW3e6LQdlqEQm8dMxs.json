{"data":{"site":{"siteMetadata":{"title":"Apollo Docs","description":"How to use the Apollo GraphQL platform","subtitle":"Platform","spectrumPath":"apollo-platform"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"content":"\nThe first step on our journey toward building our graph API is constructing its **schema**. You can think of a schema as a blueprint for all of the data you can access in your graph. Throughout this section, you'll learn how to build and explore your graph's schema with Apollo.\n\n<h2 id=\"setup\">Set up Apollo Server</h2>\n\nBefore we write our schema, we need to set up our graph API's server. **Apollo Server** is a library that helps you build a production-ready graph API over your data. It can connect to any data source, including REST APIs and databases, and it seamlessly integrates with Apollo developer tooling.\n\nFrom the root, let's install our project's dependencies:\n\n```bash\ncd start/server && npm install\n```\n\nThe two packages you need to get started with Apollo Server are `apollo-server` and `graphql`, which we've already installed for you. Now, let's navigate to `src/index.js` so we can create our server. Copy the code below into the file.\n\n_src/index.js_\n\n```js\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\n\nconst server = new ApolloServer({ typeDefs });\n```\n\nTo build our graph API, we need to import the `ApolloServer` class from `apollo-server`. We also need to import our schema from `src/schema.js`. Next, let's create a new instance of `ApolloServer` and pass our schema to the `typeDefs` property on the configuration object.\n\nBefore we can start the server, we need to write our schema first.\n\n<h2 id=\"write-schema\">Write your graph's schema</h2>\n\nEvery graph API is centered around its schema. You can think of a schema as a blueprint that describes all of your data's types and their relationships. A schema also defines what data we can fetch through queries and what data we can update through mutations. It is strongly typed, which unlocks powerful developer tooling.\n\nSchemas are at their best when they are designed around the needs of the clients that are consuming them. Since a schema sits in between your clients and your underlying services, it serves as a perfect middle ground for frontend and backend teams to collaborate. We recommend that teams practice **Schema First Development** and agree upon the schema first before any API development begins.\n\nLet's think about the data we will need to expose in order to build our app. Our app needs to:\n\n- Fetch all upcoming rocket launches\n- Fetch a specific launch by its ID\n- Login the user\n- Book launch trips if the user is logged in\n- Cancel launch trips if the user is logged in\n\nOur schema will be based on these features. In `src/schema.js`, import `gql` from Apollo Server and create a variable called `typeDefs` for your schema. Your schema will go inside the `gql` function (between the backticks in this portion: <code>gql\\`\\`</code>).\n\n_src/schema.js_\n\n```js\nconst { gql } = require('apollo-server');\n\nconst typeDefs = gql``;\n\nmodule.exports = typeDefs;\n```\n\n<h3 id=\"query\">Query type</h3>\n\nWe'll start with the **Query type**, which is the entry point into our schema that describes what data we can fetch.\n\nThe language we use to write our schema is GraphQL's schema definition language (SDL). If you've used TypeScript before, the syntax will look familiar. Copy the following SDL code between the backticks where the `gql` function is invoked in  `src/schema.js`\n\n_src/schema.js_\n\n```graphql\ntype Query {\n  launches: [Launch]!\n  launch(id: ID!): Launch\n  # Queries for the current user\n  me: User\n}\n```\n\nFirst, we define a `launches` query to fetch all upcoming rocket launches. This query returns an array of launches, which will never be null. Since all types in GraphQL are nullable by default, we need to add the `!` to indicate that our query will always return data. Next, we define a query to fetch a `launch` by its ID. This query takes an argument of `id` and returns a single launch. Finally, we will add a `me` query to fetch the current user's data. Above the `me` query is an example of a comment added to the schema.\n\nHow do we define what properties are exposed by `Launch` and `User`? For these types, we need to define a GraphQL object type.\n\n<h3 id=\"object\">Object & scalar types</h3>\n\nLet's define what the structure of `Launch` looks like by creating an **object type**:\n\n_src/schema.js_\n\n```graphql\ntype Launch {\n  id: ID!\n  site: String\n  mission: Mission\n  rocket: Rocket\n  isBooked: Boolean!\n}\n```\n\nThe `Launch` type has **fields** that correspond to object and scalar types. A **scalar type** is a primitive type like `ID`, `String`, `Boolean`, or `Int`. You can think of scalars as the leaves of your graph that all fields resolve to. GraphQL has many scalars built in, and you can also define [custom scalars](/docs/apollo-server/features/scalars-enums.html) like `Date`.\n\nThe `Mission` and `Rocket` types represent other object types. Let's define the fields on `Mission`, `Rocket`, and `User`:\n\n_src/schema.js_\n\n```graphql\ntype Rocket {\n  id: ID!\n  name: String\n  type: String\n}\n\ntype User {\n  id: ID!\n  email: String!\n  trips: [Launch]!\n}\n\ntype Mission {\n  name: String\n  missionPatch(size: PatchSize): String\n}\n\nenum PatchSize {\n  SMALL\n  LARGE\n}\n```\n\nYou'll notice that the field `missionPatch` takes an argument of `size`. GraphQL is flexible because any fields can contain arguments, not just queries. The `size` argument corresponds to an **enum type**, which we're defining at the bottom with `PatchSize`.\n\nThere are some other less common types you might also encounter when building your graph's schema. For a full list, you can reference this handy [cheat sheet](https://devhints.io/graphql#schema).\n\n<h3 id=\"mutation\">Mutation type</h3>\n\nNow, let's define the **Mutation type**. The `Mutation` type is the entry point into our graph for modifying data. Just like the `Query` type, the `Mutation` type is a special object type.\n\n_src/schema.js_\n\n```graphql\ntype Mutation {\n  # if false, booking trips failed -- check errors\n  bookTrips(launchIds: [ID]!): TripUpdateResponse!\n\n  # if false, cancellation failed -- check errors\n  cancelTrip(launchId: ID!): TripUpdateResponse!\n\n  login(email: String): String # login token\n}\n```\n\nBoth the `bookTrips` and `cancelTrip` mutations take an argument and return a `TripUpdateResponse`. The return type for your GraphQL mutation is completely up to you, but we recommend defining a special response type to ensure a proper response is returned back to the client. In a larger project, you might abstract this type into an interface, but for now, we're going to define `TripUpdateResponse`:\n\n_src/schema.js_\n\n```graphql\ntype TripUpdateResponse {\n  success: Boolean!\n  message: String\n  launches: [Launch]\n}\n```\n\nOur mutation response type contains a success status, a corresponding message, and the launch that we updated. It's always good practice to return the data that you're updating in order for the Apollo Client cache to update automatically.\n\n<h2 id=\"apollo-server-run\">Run your server</h2>\n\nNow that we have scoped out our app's schema, let's run the server by calling `server.listen()`.\n\n_src/index.js_\n\n```js\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\n\nconst server = new ApolloServer({ typeDefs });\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀 Server ready at ${url}`);\n});\n```\n\nIn your terminal, run `npm start` to start your server! 🎉 Apollo Server will now be available on port 4000.\n\n<h3 id=\"apollo-server-explore\">Explore your schema</h3>\n\nBy default, Apollo Server supports [GraphQL Playground](/docs/apollo-server/features/graphql-playground.html). The Playground is an interactive, in-browser GraphQL IDE for exploring your schema and testing your queries. Apollo Server automatically serves GraphQL Playground in development only.\n\nThe GraphQL Playground provides the ability to introspect your schema. **Introspection** is a technique used to provide detailed information about a graph's schema. To see this in action, check out the right hand side of GraphQL Playground and click on the `schema` button.\n\n<div style=\"text-align:center\">\n  <img src=\"../images/schematab.png\" alt=\"Schema button\">\n</div>\n\nYou can quickly have access to the documentation of a GraphQL API via the `schema` button.\n\n<div style=\"text-align:center\">\n  <img src=\"../images/moredetailsonatype.png\" alt=\"More details on a Schema Type\">\n</div>\n\nThat's all for building our schema. Let's move on to the next part of our tutorial.\n","title":"1. Build a schema","description":"Create a blueprint for your graph's data","version":{"id":"dev","basePath":"/","contents":[{"title":null,"pages":[{"title":"Welcome","description":"Start here to learn about the Apollo platform","content":"\nWelcome! 👋 We're excited you're here to learn about Apollo.\n\nThe Apollo GraphQL platform is an implementation of GraphQL that helps you manage data from the cloud to your UI. It's incrementally adoptable and can be layered over your existing services, including REST APIs and databases. Apollo includes two open-source libraries for the client and server, in addition to developer tooling that provides everything you need to run a graph API in production with confidence.\n\n<div class=\"documentation-buttons\">\n  <a href=\"/docs/tutorial/introduction.html\" class=\"btn default\">Try it out!</a>\n  <a href=\"/docs/intro/platform.html\" class=\"btn default hollow\">Learn more</a>\n</div>\n\n<div style=\"text-align:center\">\n  <img src=\"./img/platform.jpg\" alt=\"Graph layer\">\n</div>\n","path":"/","filePath":"docs/source/index.md"},{"title":"The Apollo GraphQL platform","description":"How Apollo helps you go from zero to production with GraphQL","content":"\nApollo is an implementation of GraphQL designed for the needs of product\nengineering teams building modern, data-driven applications. It\nencourages an agile, incremental approach and takes special care to\navoid requiring any changes to existing APIs and services. Apollo puts\nparticular emphasis on tooling and workflows.\n\nApollo is best used as a new layer in your stack that sits between your\nservices and your applications. It's a combination of open source\ncomponents, commercial extensions, and cloud services. The major pieces\nare:\n\n<div style=\"text-align:center\">\n  <img src=\"../img/platform-diagram.png\" alt=\"Graph layer\">\n</div>\n\n<h2 id=\"open-source\">Core open source components</h2>\n\n- **Apollo Server** is a JavaScript GraphQL server for defining a\n  _schema_ and a set of _resolvers_ that implement each part of that\n  schema. Typically Apollo Server is extensible: plugins can hook in to each stage of the\n  request pipeline and server's own lifecycle, making it possible to\n  implement custom behaviors in add-on packages. Apollo Server supports\n  AWS Lambda and other serverless environments.\n\n- **Apollo Client** is a sophisticated GraphQL client that\n  manages data and state in an application. Among other benefits, it\n  enables a declarative programming style that lets developers define\n  queries as part of UI components; the client manages all the hairy\n  details of binding query results to the UI, managing consistency,\n  caching, and so on. Apollo Client also supports an\n  exceptionally elegant approach to state management by _extending_ the\n  GraphQL schema inside the client with additional structure. Apollo Client\n  includes integrations for React, React Native, Vue, Angular, and\n  other view layers.\n\n- **iOS and Android** clients, originally contributed by the community,\n  make it possible to query a GraphQL API from native iOS and\n  Android applications.\n\n- **Apollo CLI** is a simple command line client that provides\n  access to Apollo cloud services.\n\n<h2 id=\"cloud-services\">Cloud services</h2>\n\n- **Schema registry** &mdash; a registry for GraphQL schemas that acts\n  as a central source of truth for a schema, enriched with additional\n  metadata like field-level usage statistics.\n\n- **Client registry** &mdash; a registry to track each known consumer\n  of a schema, which can include both pre-registered and ad-hoc clients.\n\n- **Operation registry** &mdash; a registry of all the known operations\n  against the schema, which similarly can include both pre-registered\n  and ad-hoc operations.\n\n- **Trace warehouse** &mdash; a data pipeline and storage layer that\n  captures structured information about each GraphQL operation\n  processed by an Apollo Server (or any other server that implements\n  the Apollo trace API), including the specific set of fields accessed,\n  the tree of resolver calls that were made with timing data for each,\n  and important metadata such as client identity and which version\n  of the schema was queried.\n\n<h2 id=\"gateway\">Gateway</h2>\n\n- **Apollo Gateway** &mdash; a configuration of Apollo Server and additional plugins\n  that functions as a GraphQL gateway. The gateway composes separately deployed \"micro-schemas\" that reference each other into a single master schema, which looks to a client just like any regular GraphQL schema. To answer queries, the gateway builds a query plan, fetches data from each upstream GraphQL service, and assembles it all back together into a single result.\n\n<h2 id=\"workflows\">Workflows</h2>\n\nOn top of these components, Apollo implements some useful workflows for\nmanaging a GraphQL API. Each of these workflows makes use of several\ndifferent parts of the platform, working together. Some examples are:\n\n<h3 id=\"schema-validation\">Schema change validation</h3>\n\nApollo includes a facility for checking the compatibility of a given\nschema against a set of previously-observed operations. This uses the\ntrace warehouse, operation registry, and (typically) the client\nregistry. As an example, an operation that references a missing field or\nan operation that doesn't pass a required argument to a field would\ncause an incompatibility error. The compatibility check runs statically,\ntaking advantage of the schema's type definitions, so it doesn't require\na running server.\n\n<h3 id=\"safelisting\">Safelisting</h3>\n\nApollo provides an end-to-end mechanism for _safelisting_ known clients\nand queries, a recommended best practice that limits production use of a\nGraphQL API to specific pre-arranged operations. There are two parts\nhere. First, the Apollo CLI extracts all the queries from a client\ncodebase, computes the over-the-wire subset of the query (stripping out\nthe part that references the client's local schema), and stores it in\nthe operation registry. Separately, an Apollo Server plugin synchronizes\nthe list of pre-registered operations to the server, which then rejects\nqueries that aren't present in its local copy.\n","path":"/intro/platform","filePath":"docs/source/intro/platform.md"},{"title":"Why GraphQL?","description":"Why adopting GraphQL and Apollo will help you ship features faster","content":"\nManaging data in modern applications can present a number of challenges. Developers have to aggregate data from multiple sources, distribute it upon multiple platforms, and plumb it into an app's UI. On top of that, front-end developers have to decide how to manage state on the client, all while executing complicated features such as caching and optimistic UI.\n\nAdopting GraphQL in your organization will ease these pain points considerably. Read on to learn how GraphQL's declarative approach to data fetching will simplify data transformation and speed up your API. You'll also learn how the Apollo platform enables faster development cycles thanks to its advanced ecosystem of tooling and excellent developer experience.\n\n<h2 id=\"dev-experience\">Developer experience</h2>\n\nImplementing GraphQL in your organization via the Apollo platform can help you ship features faster due to its excellent developer experience. Our #1 goal is to simplify data management across the stack. Features that are normally difficult to execute, such as fullstack caching, data normalization, and optimistic UI suddenly become trivial thanks to Apollo Client, Apollo Server, and Apollo Engine. Let's learn how!\n\n<h3 id=\"explore-api\">Explore your API</h3>\n\nGraphQL's strongly typed query language enables developers to take advantage of incredible tooling for exploring GraphQL APIs. Thanks to GraphQL's introspection system, developers can query a GraphQL schema for information about what queries and types it supports. Introspection unlocks some really cool features, such as automatic documentation, autocomplete, and more.\n\n<h4 id=\"graphql-playground\">GraphQL Playground</h4>\n\n[GraphQL Playground](https://github.com/prismagraphql/graphql-playground) by Prisma is an excellent IDE featuring automatically generated docs for your schema and query execution with autocomplete. At a glance, you can see all the data available in your GraphQL API without diving into the backend code or knowing what source it came from.\n\n![GraphQL Playground](../assets/graphql-playground.png)\n\nApollo Server 2+ sets up GraphQL Playground out of the box, so you can start exploring your schema and executing queries immediately.\n\n<h4 id=\"dev-tools\">Apollo DevTools</h4>\n\nApollo DevTools is a Chrome extension that allows you to inspect your Apollo Client cache, track active queries, and view mutations. You also have access to GraphiQL within Apollo DevTools which is convenient for testing queries as you're working on front-end code with Apollo Client.\n\n![Apollo DevTools](../assets/dev-tools.png)\n\n<h3 id=\"simplify-frontend\">Simplify front-end code</h3>\n\nIf you've worked with REST and a state management library like Redux, you're probably used to writing action creators, reducers, normalizing your data, and integrating middleware to make a single network request. With Apollo Client, you no longer have to worry about any of these concerns! Apollo Client sets up everything you need for a production-ready app so you can focus on writing queries instead of thousands of lines of state management code.\n\n```js\nimport ApolloClient from 'apollo-boost';\n\nconst client = new ApolloClient({\n  uri: 'https://dog-graphql-api.glitch.me/graphql'\n});\n```\n\nTeams who have switched to Apollo Client have reported [deleting thousands of lines of state management code](https://blog.apollographql.com/reducing-our-redux-code-with-react-apollo-5091b9de9c2a) and lots of complexity from their application. Since Apollo Client supports managing both local and remote data, you can use the Apollo cache as a single source of truth for all global state in your application.\n\n<h3 id=\"modern-tooling\">Modern tooling</h3>\n\nDeveloping your GraphQL API with the Apollo platform gives teams access to modern tooling that helps them uncover bugs quickly, gain visibility into their API, and develop challenging features such as caching with confidence.\n\n[Apollo Engine](https://engine.apollographql.com/login) is the only tool in the GraphQL ecosystem that can provide monitoring and analytics for your API. Apollo Engine displays per resolver tracing metrics that can help you pinpoint bugs, as well as performance distribution for every field in your schema. You can also pipe this data to services you're probably already using like DataDog, and set up Slack alerts if these numbers pass a certain threshold.\n\n![Apollo Engine](../assets/engine.png)\n\n<h2 id=\"declarative-data\">Declarative data fetching</h2>\n\nOne of the main advantages of adopting GraphQL is its declarative approach to data fetching. With GraphQL, there's no need to call multiple endpoints from the client or aggregate the data manually like you have to with traditional REST data fetching. Instead, you specify exactly the data you need and GraphQL gives you exactly what you asked for.\n\nWith REST, you would have to call all of these endpoints for each item in the list, filter down the data you need, and aggregate all of the remaining data into the shape your components consume.\n\n```bash\nGET /api/dogs/breeds\nGET /api/dogs/images\nGET /api/dogs/activities\n```\n\nNot only is this approach time-consuming, it's also prone to error and difficult to reuse logic across platforms. Compare this with GraphQL's declarative way to query data:\n\n```graphql\nconst GET_DOGS = gql`\n  query {\n    dogs {\n      id\n      breed\n      image {\n        url\n      }\n      activities {\n        name\n      }\n    }\n  }\n`;\n```\n\nHere, we're describing the shape of the object we want to receive from the server. GraphQL takes care of combining and filtering the data while returning exactly what we ask for.\n\nHow do we use this query in our app? Apollo Client builds off of GraphQL's declarative approach to data fetching. In a React app, all of the logic for retrieving your data, tracking loading and error states, and updating your UI is encapsulated in a single `Query` component. This encapsulation makes composing your data fetching components with your presentational components a breeze! Let’s see how to fetch GraphQL data with Apollo Client in a React app:\n\n```jsx\nconst Feed = () => (\n  <Query query={GET_DOGS}>\n    {({ loading, error, data }) => {\n      if (error) return <Error />;\n      if (loading || !data) return <Fetching />;\n\n      return <DogList dogs={data.dogs} />;\n    }}\n  </Query>\n);\n```\n\nApollo Client takes care of the request cycle from start to finish, including tracking loading and error states for you. There’s no middleware to set up or boilerplate to write before making your first request, nor do you need to worry about transforming and caching the response. All you have to do is describe the data your component needs and let Apollo Client do the heavy lifting. 💪\n\nYou’ll find that when you switch to Apollo Client, you’ll be able to delete a lot of unnecessary code related to data management. The exact amount will vary depending on your application, but some teams have reported up to thousands of lines. To learn more about how Apollo Client enables advanced features like optimistic UI, refetching, and pagination with less code, check out our [documentation for Apollo Client](/docs/react/).\n\n<h2 id=\"performance\">Improved performance</h2>\n\nIn many cases, layering a GraphQL API over your existing REST endpoints can improve your app's performance, especially on devices with slow network connections. While you should always measure to determine how integrating GraphQL will affect your application, it's generally accepted that GraphQL improves performance by helping avoid round trips to the server and reducing payload size.\n\n<h3 id=\"smaller-payload\">Smaller payloads</h3>\n\nSince the response back from the server contains only the properties you specify in your query, GraphQL can significantly reduce payload size compared to a REST endpoint. Let's take a look at our dogs query from earlier in the article:\n\n```graphql\nconst GET_DOGS = gql`\n  query {\n    dogs {\n      id\n      breed\n      image {\n        url\n      }\n      activities {\n        name\n      }\n    }\n  }\n`;\n```\n\nThe response back from the server will be a list of dog objects with `id`, `breed`, `image`, and `activities` properties. It doesn't matter if the underlying REST endpoints we call in our resolvers return back objects with 100 properties! All of those extraneous properties will be filtered out before the response is sent back to the client.\n\n<h3 id=\"round-trip\">Avoid round trips</h3>\n\nSince each GraphQL request returns only one response, switching to GraphQL can help you avoid costly round trips from the client to your server. With REST, each resource represents a round trip, which can quickly add up. If you're fetching items in a list, you'll have to complete a round trip for every resource multiplied by the number of items, causing slow load times, especially on mobile devices.\n\n```bash\nGET /api/dogs/breeds\nGET /api/dogs/images\nGET /api/dogs/activities\n```\n\nWith GraphQL, each query represents a single round trip from the client to server. If you'd like to reduce round trips even further, you can implement [query batching](/docs/react/advanced/network-layer#query-batching) to batch multiple queries into a single request.\n\n<h3 id=\"production\">Ready for production</h3>\n\nWhile the GraphQL specification was first made public by Facebook in 2015, GraphQL has been a key component of their mobile application deployment since 2012.\n\nAt Apollo, we found GraphQL to be an excellent solution to many of the problems we encountered with existing techniques, and now use it to power critical infrastructure. Over the years, we’ve worked with the open-source community along with customers and partners of all sizes to continually bring new innovations to the open-source Apollo offerings, and we're proud that those offerings are suitable for everything from startups to large-scale deployments.\n\nIn addition to our own experience, we have received extensive feedback, contributions and support from enterprise customers who are actively using Apollo GraphQL in production. A few of our most public and notable case-studies are:\n\n- [**The New York Times**](https://open.nytimes.com/the-new-york-times-now-on-apollo-b9a78a5038c): Learn how The New York Times switched from Relay to Apollo & implemented features in their app such as SSR and persisted queries.\n- [**Airbnb**](https://medium.com/airbnb-engineering/reconciling-graphql-and-thrift-at-airbnb-a97e8d290712): Airbnb is betting big on the Apollo platform to power the data layer for their microservices.\n- [**Express**](https://dev-blog.apollodata.com/changing-the-architecture-of-express-com-23c950d43323): Easy-to-use pagination with Apollo helped improve the Express eCommerce team's key product pages.\n- [**Major League Soccer**](https://dev-blog.apollodata.com/reducing-our-redux-code-with-react-apollo-5091b9de9c2a): MLS' switch from Redux to Apollo for state management enabled them to delete nearly all of their Redux code.\n- [**Expo**](https://dev-blog.apollodata.com/using-graphql-apollo-at-expo-4c1f21f0f115): Developing their React Native app with Apollo allowed the Expo engineers to focus on improving their product instead of writing data fetching logic.\n- [**KLM**](https://youtu.be/T2njjXHdKqw): Learn how the KLM team scaled their Angular app with GraphQL and Apollo.\n","path":"/intro/benefits","filePath":"docs/source/intro/benefits.md"}]},{"title":"Tutorial","pages":[{"title":"0. Introduction","description":"Start here to learn how to build fullstack apps with Apollo","content":"\nWelcome! We're excited that you've decided to learn Apollo. This fullstack tutorial will guide you through building your first app with the Apollo platform in about an hour. Throughout the tutorial, you'll learn how to build a graph API and connect it to a React frontend.\n\nWe want you to feel confident that you have the knowledge you need to build a production-ready app with Apollo, so we're forgoing hello world in favor of a real world example complete with authentication, pagination, testing, and more. Ready? Let's dive right in!\n\n<h2 id=\"what-is-apollo\">What is Apollo?</h2>\n\nApollo is a complete platform for implementing a graph over your data. It includes two runtime libraries, **Apollo Server** and **Apollo Client**, for building and querying your graph's API. It also features developer tooling that integrates with your existing workflow and gives you full visibility into the performance and security of your graph.\n\nWhy do you need a graph? Today, one of the most difficult parts of building an app is figuring out your data layer. Often, there's many data sources you need to fetch from and many clients you need to support. When you layer a graph in between your services and your UI, you can remove a lot of complexity from your data fetching logic and ship features faster.\n\n<div style=\"text-align:center\">\n  <img src=\"../images/graph-layer.png\" alt=\"Graph layer\">\n</div>\n\n**[GraphQL](https://www.graphql.org/)** is the specification that we'll be using to communicate between our graph API and client. The spec itself is language-agnostic and unopinionated, so we're choosing to implement GraphQL with the Apollo platform.\n\n<h2 id=\"tutorial-app\">What we'll build</h2>\n\nIn this tutorial, we'll build an interactive app for reserving your spot on an upcoming Space-X launch. You can think of it as an Airbnb for space travel! All of the data is real, thanks to the [SpaceX-API](https://github.com/r-spacex/SpaceX-API).\n\nHere's what the finished app will look like:\n\n<div style=\"text-align:center\">\n  <img src=\"../images/space-explorer.png\" alt=\"Space explorer\">\n</div>\n\nThe app has five screens: a login screen, a list of launches, a launch detail, a profile page, and a cart. The graph API powering our space app connects to a REST API and a SQLite database. Don't worry if you're unfamiliar with those technologies, you don't need to know how to build a REST API or SQLite database from scratch in order to complete the tutorial.\n\nWe want this to model a real world Apollo app as much as possible, so we're covering essential topics like authentication, pagination, state management, testing, and deployment.\n\n<h2 id=\"prerequisites\">Prerequisites</h2>\n\nThe tutorial assumes that you're comfortable with JavaScript/ES6, you've fetched data from an API before, and you have basic familiarity with React. If you need to brush up on your React skills, we recommend going through the [official tutorial](https://reactjs.org/tutorial/tutorial.html). Building your frontend with React is not a requirement for using Apollo, although it is the most popular way developers integrate with Apollo Client. Even if you use another view layer like Angular or Vue, you will still be able to pick up on the concepts covered in the client section and apply them to your view layer of choice.\n\n<h3 id=\"system-requirements\">System requirements</h3>\n\nBefore we begin, make sure you have:\n\n- [Node.js](https://nodejs.org/) v6.9.0 or greater\n- [npm](https://www.npmjs.com/) 3.10.8 or greater\n- [git](https://git-scm.com/) v2.14.1 or greater\n\nWhile it's not a requirement, we recommend using [VSCode](https://code.visualstudio.com/) as your editor so you can take advantage of all the awesome features the Apollo VSCode extension enables. We're hoping to support other editors in the future.\n\n<h2 id=\"dev-environment\">Set up your development environment</h2>\n\nNow the fun begins! First, you'll need to install our developer tools:\n\n- [Apollo Engine (required)](https://engine.apollographql.com) : Our cloud service where you'll register and manage your graph API.\n- [Apollo DevTools for Chrome (suggested)](https://chrome.google.com/webstore/detail/apollo-client-developer-t/jdkknkkbebbapilgoeccciglkfbmbnfm) : Our Chrome extension giving you full visibility into your client.\n- [Apollo VSCode (suggested)](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo): Our editor integration that offers intelligent autocomplete, metrics, and more.\n\nNext, in your terminal, clone [this repository](https://github.com/apollographql/fullstack-tutorial):\n\n```bash\ngit clone https://github.com/apollographql/fullstack-tutorial/\n```\n\nThere are two folders: one for the starting point (`start`) and one for the final version (`final`). Within each directory are two folders: one for the server and one for the client. We will be working in the server folder first. If you're comfortable with building a graph API already and you want to skip to the client portion, navigate to the [last half of the tutorial](./client.html).\n\n<!--\nTODO: Add in this section after Apollo VSCode works for server development\n<h3 id=\"vscode\">Configure Apollo VSCode</h3> -->\n\n<h3 id=\"help\">Where can I get help?</h3>\n\nWe know that learning a new technology can sometimes be overwhelming, and it's totally normal to get stuck! If that happens, we recommend joining the [Apollo Spectrum](https://spectrum.chat/apollo) community and posting in the relevant channel (either #apollo-server or #apollo-client) for some quick answers.\n\nIf something in the tutorial seems confusing or contains an error, we'd love your feedback! Just click the Edit on GitHub link on the right side of the page to open a new pull request or open an issue on the repository.\n","path":"/tutorial/introduction","filePath":"docs/source/tutorial/introduction.md"},{"title":"1. Build a schema","description":"Create a blueprint for your graph's data","content":"\nThe first step on our journey toward building our graph API is constructing its **schema**. You can think of a schema as a blueprint for all of the data you can access in your graph. Throughout this section, you'll learn how to build and explore your graph's schema with Apollo.\n\n<h2 id=\"setup\">Set up Apollo Server</h2>\n\nBefore we write our schema, we need to set up our graph API's server. **Apollo Server** is a library that helps you build a production-ready graph API over your data. It can connect to any data source, including REST APIs and databases, and it seamlessly integrates with Apollo developer tooling.\n\nFrom the root, let's install our project's dependencies:\n\n```bash\ncd start/server && npm install\n```\n\nThe two packages you need to get started with Apollo Server are `apollo-server` and `graphql`, which we've already installed for you. Now, let's navigate to `src/index.js` so we can create our server. Copy the code below into the file.\n\n_src/index.js_\n\n```js\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\n\nconst server = new ApolloServer({ typeDefs });\n```\n\nTo build our graph API, we need to import the `ApolloServer` class from `apollo-server`. We also need to import our schema from `src/schema.js`. Next, let's create a new instance of `ApolloServer` and pass our schema to the `typeDefs` property on the configuration object.\n\nBefore we can start the server, we need to write our schema first.\n\n<h2 id=\"write-schema\">Write your graph's schema</h2>\n\nEvery graph API is centered around its schema. You can think of a schema as a blueprint that describes all of your data's types and their relationships. A schema also defines what data we can fetch through queries and what data we can update through mutations. It is strongly typed, which unlocks powerful developer tooling.\n\nSchemas are at their best when they are designed around the needs of the clients that are consuming them. Since a schema sits in between your clients and your underlying services, it serves as a perfect middle ground for frontend and backend teams to collaborate. We recommend that teams practice **Schema First Development** and agree upon the schema first before any API development begins.\n\nLet's think about the data we will need to expose in order to build our app. Our app needs to:\n\n- Fetch all upcoming rocket launches\n- Fetch a specific launch by its ID\n- Login the user\n- Book launch trips if the user is logged in\n- Cancel launch trips if the user is logged in\n\nOur schema will be based on these features. In `src/schema.js`, import `gql` from Apollo Server and create a variable called `typeDefs` for your schema. Your schema will go inside the `gql` function (between the backticks in this portion: <code>gql\\`\\`</code>).\n\n_src/schema.js_\n\n```js\nconst { gql } = require('apollo-server');\n\nconst typeDefs = gql``;\n\nmodule.exports = typeDefs;\n```\n\n<h3 id=\"query\">Query type</h3>\n\nWe'll start with the **Query type**, which is the entry point into our schema that describes what data we can fetch.\n\nThe language we use to write our schema is GraphQL's schema definition language (SDL). If you've used TypeScript before, the syntax will look familiar. Copy the following SDL code between the backticks where the `gql` function is invoked in  `src/schema.js`\n\n_src/schema.js_\n\n```graphql\ntype Query {\n  launches: [Launch]!\n  launch(id: ID!): Launch\n  # Queries for the current user\n  me: User\n}\n```\n\nFirst, we define a `launches` query to fetch all upcoming rocket launches. This query returns an array of launches, which will never be null. Since all types in GraphQL are nullable by default, we need to add the `!` to indicate that our query will always return data. Next, we define a query to fetch a `launch` by its ID. This query takes an argument of `id` and returns a single launch. Finally, we will add a `me` query to fetch the current user's data. Above the `me` query is an example of a comment added to the schema.\n\nHow do we define what properties are exposed by `Launch` and `User`? For these types, we need to define a GraphQL object type.\n\n<h3 id=\"object\">Object & scalar types</h3>\n\nLet's define what the structure of `Launch` looks like by creating an **object type**:\n\n_src/schema.js_\n\n```graphql\ntype Launch {\n  id: ID!\n  site: String\n  mission: Mission\n  rocket: Rocket\n  isBooked: Boolean!\n}\n```\n\nThe `Launch` type has **fields** that correspond to object and scalar types. A **scalar type** is a primitive type like `ID`, `String`, `Boolean`, or `Int`. You can think of scalars as the leaves of your graph that all fields resolve to. GraphQL has many scalars built in, and you can also define [custom scalars](/docs/apollo-server/features/scalars-enums.html) like `Date`.\n\nThe `Mission` and `Rocket` types represent other object types. Let's define the fields on `Mission`, `Rocket`, and `User`:\n\n_src/schema.js_\n\n```graphql\ntype Rocket {\n  id: ID!\n  name: String\n  type: String\n}\n\ntype User {\n  id: ID!\n  email: String!\n  trips: [Launch]!\n}\n\ntype Mission {\n  name: String\n  missionPatch(size: PatchSize): String\n}\n\nenum PatchSize {\n  SMALL\n  LARGE\n}\n```\n\nYou'll notice that the field `missionPatch` takes an argument of `size`. GraphQL is flexible because any fields can contain arguments, not just queries. The `size` argument corresponds to an **enum type**, which we're defining at the bottom with `PatchSize`.\n\nThere are some other less common types you might also encounter when building your graph's schema. For a full list, you can reference this handy [cheat sheet](https://devhints.io/graphql#schema).\n\n<h3 id=\"mutation\">Mutation type</h3>\n\nNow, let's define the **Mutation type**. The `Mutation` type is the entry point into our graph for modifying data. Just like the `Query` type, the `Mutation` type is a special object type.\n\n_src/schema.js_\n\n```graphql\ntype Mutation {\n  # if false, booking trips failed -- check errors\n  bookTrips(launchIds: [ID]!): TripUpdateResponse!\n\n  # if false, cancellation failed -- check errors\n  cancelTrip(launchId: ID!): TripUpdateResponse!\n\n  login(email: String): String # login token\n}\n```\n\nBoth the `bookTrips` and `cancelTrip` mutations take an argument and return a `TripUpdateResponse`. The return type for your GraphQL mutation is completely up to you, but we recommend defining a special response type to ensure a proper response is returned back to the client. In a larger project, you might abstract this type into an interface, but for now, we're going to define `TripUpdateResponse`:\n\n_src/schema.js_\n\n```graphql\ntype TripUpdateResponse {\n  success: Boolean!\n  message: String\n  launches: [Launch]\n}\n```\n\nOur mutation response type contains a success status, a corresponding message, and the launch that we updated. It's always good practice to return the data that you're updating in order for the Apollo Client cache to update automatically.\n\n<h2 id=\"apollo-server-run\">Run your server</h2>\n\nNow that we have scoped out our app's schema, let's run the server by calling `server.listen()`.\n\n_src/index.js_\n\n```js\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\n\nconst server = new ApolloServer({ typeDefs });\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀 Server ready at ${url}`);\n});\n```\n\nIn your terminal, run `npm start` to start your server! 🎉 Apollo Server will now be available on port 4000.\n\n<h3 id=\"apollo-server-explore\">Explore your schema</h3>\n\nBy default, Apollo Server supports [GraphQL Playground](/docs/apollo-server/features/graphql-playground.html). The Playground is an interactive, in-browser GraphQL IDE for exploring your schema and testing your queries. Apollo Server automatically serves GraphQL Playground in development only.\n\nThe GraphQL Playground provides the ability to introspect your schema. **Introspection** is a technique used to provide detailed information about a graph's schema. To see this in action, check out the right hand side of GraphQL Playground and click on the `schema` button.\n\n<div style=\"text-align:center\">\n  <img src=\"../images/schematab.png\" alt=\"Schema button\">\n</div>\n\nYou can quickly have access to the documentation of a GraphQL API via the `schema` button.\n\n<div style=\"text-align:center\">\n  <img src=\"../images/moredetailsonatype.png\" alt=\"More details on a Schema Type\">\n</div>\n\nThat's all for building our schema. Let's move on to the next part of our tutorial.\n","path":"/tutorial/schema","filePath":"docs/source/tutorial/schema.md"},{"title":"2. Hook up your data sources","description":"Connect REST and SQL data to your graph","content":"\nTime to accomplish: _10 Minutes_\n\nNow that we've constructed our schema, we need to hook up our data sources to our GraphQL API. GraphQL APIs are extremely flexible because you can layer them on top of any service, including any business logic, REST APIs, databases, or gRPC services.\n\nApollo makes connecting these services to your graph simple with our data source API. An **Apollo data source** is a class that encapsulates all of the data fetching logic, as well as caching and deduplication, for a particular service. By using Apollo data sources to hook up your services to your graph API, you're also following best practices for organizing your code.\n\nIn the next sections, we'll build data sources for a REST API and a SQL database and connect them to Apollo Server. Don't worry if you're not familiar with either of those technologies, you won't need to understand them deeply in order to follow the examples. 😀\n\n<h2 id=\"rest-api\">Connect a REST API</h2>\n\nFirst, let's connect the [Space-X v2 REST API](https://github.com/r-spacex/SpaceX-API) to our graph. To get started, install the `apollo-datasource-rest` package:\n\n```bash\nnpm install apollo-datasource-rest --save\n```\n\nThis package exposes the `RESTDataSource` class that is responsible for fetching data from a REST API. To build a data source for a REST API, extend the `RESTDataSource` class and define `this.baseURL`.\n\nIn our example, the `baseURL` for our API is `https://api.spacexdata.com/v2/`. Let's create our `LaunchAPI` data source by adding the code below to `src/datasources/launch.js`:\n\n_src/datasources/launch.js_\n\n```js\nconst { RESTDataSource } = require('apollo-datasource-rest');\n\nclass LaunchAPI extends RESTDataSource {\n  constructor() {\n    super();\n    this.baseURL = 'https://api.spacexdata.com/v2/';\n  }\n}\n\nmodule.exports = LaunchAPI;\n```\n\nThe Apollo `RESTDataSource` also sets up an in-memory cache that caches responses from our REST resources with no additional setup. We call this **partial query caching**. What's great about this cache is that you can reuse existing caching logic that your REST API exposes. If you're curious to learn more about partial query caching with Apollo data sources, please check out [our blog post](https://blog.apollographql.com/easy-and-performant-graphql-over-rest-e02796993b2b).\n\n<h3 id=\"fetching\">Write data fetching methods</h3>\n\nThe next step is to add methods to the `LaunchAPI` data source that correspond to the queries our graph API needs to fetch. According to our schema, we'll need a method to get all of the launches. Let's add a `getAllLaunches` method to our `LaunchAPI` class now:\n\n_src/datasources/launch.js_\n\n```js\nasync getAllLaunches() {\n  const response = await this.get('launches');\n  return Array.isArray(response)\n    ? response.map(launch => this.launchReducer(launch))\n    : [];\n}\n```\n\nThe Apollo REST data sources have helper methods that correspond to HTTP verbs like `GET` and `POST`. In the code above, `this.get('launches')`, makes a `GET` request to `https://api.spacexdata.com/v2/launches` and stores the returned launches in the `response` variable. Then, the `getAllLaunches` method maps over the launches and transforms the response from our REST endpoint with `this.launchReducer`. If there are no launches, an empty array is returned.\n\nNow, we need to write our `launchReducer` method in order to transform our launch data into the shape our schema expects. We recommend this approach in order to decouple your graph API from business logic specific to your REST API. First, let's recall what our `Launch` type looks like in our schema. You don't have to copy this code:\n\n_src/schema.js_\n\n```graphql\ntype Launch {\n  id: ID!\n  site: String\n  mission: Mission\n  rocket: Rocket\n  isBooked: Boolean!\n}\n```\n\nNext, let's write a `launchReducer` function to transform the data into that shape. Copy the following code into your `LaunchAPI` class:\n\n_src/datasources/launch.js_\n\n```js\nlaunchReducer(launch) {\n  return {\n    id: launch.flight_number || 0,\n    cursor: `${launch.launch_date_unix}`,\n    site: launch.launch_site && launch.launch_site.site_name,\n    mission: {\n      name: launch.mission_name,\n      missionPatchSmall: launch.links.mission_patch_small,\n      missionPatchLarge: launch.links.mission_patch,\n    },\n    rocket: {\n      id: launch.rocket.rocket_id,\n      name: launch.rocket.rocket_name,\n      type: launch.rocket.rocket_type,\n    },\n  };\n}\n```\n\nWith the above changes, we can easily make changes to the `launchReducer` method while the `getAllLaunches` method stays lean and concise. The `launchReducer` method also makes testing the `LaunchAPI` data source class easier, which we'll cover later.\n\nNext, let's take care of fetching a specific launch by its ID. Let's add two methods, `getLaunchById`, and `getLaunchesByIds` to the `LaunchAPI` class.\n\n_src/datasources/launch.js_\n\n```js\nasync getLaunchById({ launchId }) {\n  const response = await this.get('launches', { flight_number: launchId });\n  return this.launchReducer(response[0]);\n}\n\ngetLaunchesByIds({ launchIds }) {\n  return Promise.all(\n    launchIds.map(launchId => this.getLaunchById({ launchId })),\n  );\n}\n```\n\nThe `getLaunchById` method takes in a flight number and returns the data for a particular launch, while `getLaunchesByIds` returns several launches based on their respective `launchIds`.\n\nNow that we've connected our REST API successfully, let's connect our database!\n\n<h2 id=\"database\">Connect a database</h2>\n\nOur REST API is read-only, so we need to connect our graph API to a database for saving and fetching user data. This tutorial uses SQLite for our SQL database, and Sequelize for our ORM. Our `package.json` already included these packages, thus they were installed in the first part of this tutorial with `npm install`. Also, since this section contains some SQL-specific code that isn't necessary to understanding Apollo data sources, we've already built a `UserAPI` data source for you in `src/datasources/user.js`. Please navigate to that file so we can explain the overall concepts.\n\n<h3 id=\"custom-data-source\">Build a custom data source</h3>\n\nApollo doesn't have support for a SQL data source yet (although we'd love to help guide you if you're interested in contributing), so we will need to create a custom data source for our database by extending the generic Apollo data source class. You can create your own with the `apollo-datasource` package.\n\nHere are some of the core concepts for creating your own data source:\n\n- The `initialize` method: You'll need to implement this method if you want to pass in any configuration options to your class. Here, we're using this method to access our graph API's context.\n- `this.context`: A graph API's context is an object that's shared among every resolver in a GraphQL request. We're going to explain this in more detail in the next section. Right now, all you need to know is that the context is useful for storing user information.\n- Caching: While the REST data source comes with its own built in cache, the generic data source does not. You can use [our cache primitives](/docs/apollo-server/features/data-sources.html#using-memcached-redis-as-a-cache-storage-backend) to build your own, however!\n\nLet's go over some of the methods we created in `src/datasources/user.js` to fetch and update data in our database. You will want to reference these in the next section:\n\n- `findOrCreateUser({ email })`: Finds or creates a user with a given `email` in the database\n- `bookTrips({ launchIds })`: Takes an object with an array of `launchIds` and books them for the logged in user\n- `cancelTrip({ launchId })`: Takes an object with a `launchId` and cancels that launch for the logged in user\n- `getLaunchIdsByUser()`: Returns all booked launches for the logged in user\n- `isBookedOnLaunch({ launchId })`: Determines whether the logged in user booked a certain launch\n\n<h2 id=\"apollo-server\">Add data sources to Apollo Server</h2>\n\nNow that we've built our `LaunchAPI` data source to connect our REST API and our `UserAPI` data source to connect our SQL database, we need to add them to our graph API.\n\nAdding our data sources is simple, just create a `dataSources` property on your `ApolloServer` that corresponds to a function that returns an object with your instantiated data sources. Let's see what that looks like by navigating to `src/index.js` and adding the code below:\n\n_src/index.js_\n\n```js line=3,5,6,8,12-15\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\nconst { createStore } = require('./utils');\n\nconst LaunchAPI = require('./datasources/launch');\nconst UserAPI = require('./datasources/user');\n\nconst store = createStore();\n\nconst server = new ApolloServer({\n  typeDefs,\n  dataSources: () => ({\n    launchAPI: new LaunchAPI(),\n    userAPI: new UserAPI({ store })\n  })\n});\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀 Server ready at ${url}`);\n});\n```\n\nFirst, we import our `createStore` function to set up our database, as well as our data sources: `LaunchAPI` and `UserAPI`. Then, we create our database by calling `createStore`. Finally, we add the `dataSources` function to our `ApolloServer` to connect `LaunchAPI` and `UserAPI` to our graph. We also pass in our database we created to the `UserAPI` data source.\n\nIf you use `this.context` in your datasource, it's critical to create a new instance in the `dataSources` function and to not share a single instance. Otherwise, `initialize` may be called during the execution of asynchronous code for a specific user, and replace the  `this.context` by the context of another user.\n\nNow that we've hooked up our data sources to Apollo Server, it's time to move on to the next section and learn how to call our data sources from within our resolvers.\n","path":"/tutorial/data-source","filePath":"docs/source/tutorial/data-source.md"},{"title":"3. Write your graph's resolvers","description":"Learn how a GraphQL query fetches data","content":"\nTime to accomplish: _15 Minutes_\n\nUp until now, our graph API hasn't been very useful. We can inspect our graph's schema, but we can't actually run queries against it. Now that we've built our schema and data sources, it's time to leverage all of our hard work by calling our data sources in our graph API's resolver functions to possibly trigger business logic and/or to fetch and/or update data.\n\n<h2 id=\"resolver-api\">What is a resolver?</h2>\n\n**Resolvers** provide the instructions for turning a GraphQL operation (a query, mutation, or subscription) into data. They either return the same type of data we specify in our schema or a promise for that data.\n\nBefore we can start writing resolvers, we need to learn more about what a resolver function looks like. Resolver functions accept four arguments:\n\n```js\nfieldName: (parent, args, context, info) => data;\n```\n\n- **parent**: An object that contains the result returned from the resolver on the parent type\n- **args**: An object that contains the arguments passed to the field\n- **context**: An object shared by all resolvers in a GraphQL operation. We use the context to contain per-request state such as authentication information and access our data sources.\n- **info**: Information about the execution state of the operation which should only be used in advanced cases\n\nRemember the `LaunchAPI` and `UserAPI` data sources we created in the previous section and passed to the `context` property of `ApolloServer`? We're going to call them in our resolvers by accessing the `context` argument.\n\nThis might sound confusing at first, but it will start to make more sense once we dive into practical examples. Let's get started!\n\n<h3 id=\"apollo-server\">Connecting resolvers to Apollo Server</h3>\n\nFirst, let's connect our resolver map to Apollo Server. Right now, it's just an empty object, but we should add it to our `ApolloServer` instance so we don't have to do it later. Navigate to `src/index.js` and add the following code to the file:\n\n_src/index.js_\n\n```js line=4,13\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\nconst { createStore } = require('./utils');\nconst resolvers = require('./resolvers');\n\nconst LaunchAPI = require('./datasources/launch');\nconst UserAPI = require('./datasources/user');\n\nconst store = createStore();\n\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  dataSources: () => ({\n    launchAPI: new LaunchAPI(),\n    userAPI: new UserAPI({ store })\n  })\n});\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀 Server ready at ${url}`);\n});\n```\n\nApollo Server will automatically add the `launchAPI` and `userAPI` to our resolvers' context so we can easily call them.\n\n<h2 id=\"query\">Write Query resolvers</h2>\n\nFirst, let's start by writing our resolvers for the `launches`, `launch`, and `me` fields on our `Query` type. We structure our resolvers into a map where the keys correspond to the types and fields in our schema. If you ever get stuck remembering which fields are on a type, you can always check your graph API's schema.\n\nNavigate to `src/resolvers.js` and paste the code below into the file:\n\n_src/resolvers.js_\n\n```js\nmodule.exports = {\n  Query: {\n    launches: (_, __, { dataSources }) =>\n      dataSources.launchAPI.getAllLaunches(),\n    launch: (_, { id }, { dataSources }) =>\n      dataSources.launchAPI.getLaunchById({ launchId: id }),\n    me: (_, __, { dataSources }) => dataSources.userAPI.findOrCreateUser()\n  }\n};\n```\n\nThe code above shows the resolver functions for the `Query` type fields: `launches`, `launch`, and `me`. The first argument to our _top-level_ resolvers, `parent`, is always blank because it refers to the root of our graph. The second argument refers to any `arguments` passed into our query, which we use in our `launch` query to fetch a launch by its id. Finally, we destructure our data sources from the third argument, `context`, in order to call them in our resolvers.\n\nOur resolvers are simple and concise because the logic is embedded in the `LaunchAPI` and `UserAPI` data sources. We recommend keeping your resolvers thin as a best practice, which allows you to safely refactor without worrying about breaking your API.\n\n<h3 id=\"query-playground\">Run queries in the playground</h3>\n\nApollo Server sets up GraphQL Playground so that you can run queries and explore your schema with ease. Go ahead and start your server by running `npm start` and open up the playground in a browser window at `http://localhost:4000/`.\n\nStart by copying the GraphQL query below and pasting it in the left side of the playground. Then, hit the play button at the center to get a response.\n\n```graphql\nquery GetLaunches {\n  launches {\n    id\n    mission {\n      name\n    }\n  }\n}\n```\n\nWhen you write a GraphQL query, you always want to start with the **operation keyword** (either query or mutation) and its name (like `GetLaunches`). It's important to give your queries descriptive names so they're discoverable in Apollo developer tooling. Next, we use a pair of curly braces after the query name to indicate the body of our query. We specify the `launches` field on the `Query` type and use another pair of curly braces to indicate a **selection set**. The selection set describes which fields we want our query response to contain.\n\nWhat's awesome about GraphQL is that the shape of your query will match the shape of your response. Try adding and removing fields from your query and notice how the response shape changes.\n\nNow, let's write a launch query that accepts an argument. Copy the query below and paste it in the playground. Then, click the play button to get a response.\n\n```graphql\nquery GetLaunchById {\n  launch(id: 60) {\n    id\n    rocket {\n      id\n      type\n    }\n  }\n}\n```\n\nInstead of hard coding the argument `60`, you can also set variables in the bottom left corner. Here's how to run that same query with variables:\n\n```graphql\nquery GetLaunchById($id: ID!) {\n  launch(id: $id) {\n    id\n    rocket {\n      id\n      type\n    }\n  }\n}\n```\n\nYou can paste `{ \"id\": 60 }` into the Query Variables section below before running your query. Feel free to experiment with running more queries before moving on to the next section.\n\n<h3 id=\"pagination\">Paginated queries</h3>\n\nRunning the `launches` query returned a large data set of launches, which can slow down our app. How can we ensure we're not fetching too much data at once?\n\n**Pagination** is a solution to this problem that ensures that the server only sends data in small chunks. Cursor-based pagination is our recommended approach over numbered pages, because it eliminates the possibility of skipping items and displaying the same item more than once. In cursor-based pagination, a constant pointer (or **cursor**) is used to keep track of where in the data set the next items should be fetched from.\n\nWe'll use cursor-based pagination for our graph API. Open up the `src/schema.js` file and update the `Query` type with `launches` and also add a new type called `LaunchConnection` to the schema as shown below:\n\n_src/schema.js_\n\n```js\ntype Query {\n  launches( # replace the current launches query with this one.\n    \"\"\"\n    The number of results to show. Must be >= 1. Default = 20\n    \"\"\"\n    pageSize: Int\n    \"\"\"\n    If you add a cursor here, it will only return results _after_ this cursor\n    \"\"\"\n    after: String\n  ): LaunchConnection!\n  launch(id: ID!): Launch\n  me: User\n}\n\n\"\"\"\nSimple wrapper around our list of launches that contains a cursor to the\nlast item in the list. Pass this cursor to the launches query to fetch results\nafter these.\n\"\"\"\ntype LaunchConnection { # add this below the Query type as an additional type.\n  cursor: String!\n  hasMore: Boolean!\n  launches: [Launch]!\n}\n...\n```\n\nYou'll also notice we've added comments (also called docstrings) to our schema, indicated by `\"\"\"`. Now, the `launches` query takes in two parameters, `pageSize` and `after`, and returns a `LaunchConnection`. The `LaunchConnection` type returns a result that shows the list of launches, in addition to a `cursor` field that keeps track of where we are in the list and a `hasMore` field to indicate if there's more data to be fetched.\n\nOpen up the `src/utils.js` file in the repo you cloned in the previous section and check out the `paginateResults` function. The `paginateResults` function in the file is a helper function for paginating data from the server. Now, let's update the necessary resolver functions to accommodate pagination.\n\nLet's import `paginateResults` and replace the `launches` resolver function in the `src/resolvers.js` file with the code below:\n\n_src/resolvers.js_\n\n```js line=1,5-26\nconst { paginateResults } = require('./utils');\n\nmodule.exports = {\n  Query: {\n    launches: async (_, { pageSize = 20, after }, { dataSources }) => {\n      const allLaunches = await dataSources.launchAPI.getAllLaunches();\n      // we want these in reverse chronological order\n      allLaunches.reverse();\n\n      const launches = paginateResults({\n        after,\n        pageSize,\n        results: allLaunches\n      });\n\n      return {\n        launches,\n        cursor: launches.length ? launches[launches.length - 1].cursor : null,\n        // if the cursor of the end of the paginated results is the same as the\n        // last item in _all_ results, then there are no more results after this\n        hasMore: launches.length\n          ? launches[launches.length - 1].cursor !==\n            allLaunches[allLaunches.length - 1].cursor\n          : false\n      };\n    },\n    launch: (_, { id }, { dataSources }) =>\n      dataSources.launchAPI.getLaunchById({ launchId: id }),\n     me: async (_, __, { dataSources }) =>\n      dataSources.userAPI.findOrCreateUser(),\n  }\n};\n```\n\nLet's test the cursor-based pagination we just implemented. If you stopped your server, go ahead and restart your graph API again with `npm start`, and run this query in the playground:\n\n```graphql\nquery GetLaunches {\n  launches(pageSize: 3) {\n    launches {\n      id\n      mission {\n        name\n      }\n    }\n  }\n}\n```\n\nThanks to our pagination implementation, you should only see three launches returned back from our API.\n\n<h2 id=\"types\">Write resolvers on types</h2>\n\nIt's important to note that you can write resolvers for any types in your schema, not just queries and mutations. This is what makes GraphQL so flexible.\n\nYou may have noticed that we haven't written resolvers for all our types, yet our queries still run successfully. GraphQL has default resolvers; therefore, we don't have to write a resolver for a field if the parent object has a property with the same name.\n\nLet's look at a case where we do want to write a resolver on our `Mission` type. Navigate to `src/resolvers.js` and copy this resolver into our resolver map underneath the `Query` property:\n\n_src/resolvers.js_\n\n```js\nMission: {\n  // make sure the default size is 'large' in case user doesn't specify\n  missionPatch: (mission, { size } = { size: 'LARGE' }) => {\n    return size === 'SMALL'\n      ? mission.missionPatchSmall\n      : mission.missionPatchLarge;\n  },\n},\n```\n\n_src/schema.js_\n```js\n  type Mutation {\n    # ... with rest of schema\n    missionPatch(mission: String, size: PatchSize): PatchSize\n  }\n```\n\nThe first argument passed into our resolver is the parent, which refers to the mission object. The second argument is the size we pass to our `missionPatch` field, which we use to determine which property on the mission object we want our field to resolve to.\n\nNow that we know how to add resolvers on types other than `Query` and `Mutation`, let's add some more resolvers to the `Launch` and `User` types. Copy this code into your resolver map:\n\n_src/resolvers.js_\n\n```js\nLaunch: {\n  isBooked: async (launch, _, { dataSources }) =>\n    dataSources.userAPI.isBookedOnLaunch({ launchId: launch.id }),\n},\nUser: {\n  trips: async (_, __, { dataSources }) => {\n    // get ids of launches by user\n    const launchIds = await dataSources.userAPI.getLaunchIdsByUser();\n\n    if (!launchIds.length) return [];\n\n    // look up those launches by their ids\n    return (\n      dataSources.launchAPI.getLaunchesByIds({\n        launchIds,\n      }) || []\n    );\n  },\n},\n```\n\nYou may be wondering where we're getting the user from in order to fetch their booked launches. This is a great observation - we still need to authenticate our user! Let's learn how to authenticate users and attach their user information to the context in the next section before we move onto `Mutation` resolvers.\n\n<h2 id=\"authentication\">Authenticate users</h2>\n\nAccess control is a feature that almost every app will have to handle at some point. In this tutorial, we're going to focus on teaching you the essential concepts of authenticating users instead of focusing on a specific implementation.\n\nHere are the steps you'll want to follow:\n\n1. The context function on your `ApolloServer` instance is called with the request object each time a GraphQL operation hits your API. Use this request object to read the authorization headers.\n1. Authenticate the user within the context function.\n1. Once the user is authenticated, attach the user to the object returned from the context function. This allows us to read the user's information from within our data sources and resolvers, so we can authorize whether they can access the data.\n\nLet's open up `src/index.js` and update the `context` function on `ApolloServer` to the code shown below:\n\n_src/index.js_\n\n```js line=1,4,8,10\nconst isEmail = require('isemail');\n\nconst server = new ApolloServer({\n  context: async ({ req }) => {\n    // simple auth check on every request\n    const auth = (req.headers && req.headers.authorization) || '';\n    const email = Buffer.from(auth, 'base64').toString('ascii');\n\n    // if the email isn't formatted validly, return null for user\n    if (!isEmail.validate(email)) return { user: null };\n    // find a user by their email\n    const users = await store.users.findOrCreate({ where: { email } });\n    const user = users && users[0] ? users[0] : null;\n\n    return { user: { ...user.dataValues } };\n  },\n  // .... with the rest of the server object code below, typeDefs, resolvers, etc....\n```\n\nJust like in the steps outlined above, we're checking the authorization headers on the request, authenticating the user by looking up their credentials in the database, and attaching the user to the `context`. While we definitely don't advocate using this specific implementation in production since it's not secure, all of the concepts outlined here are transferable to how you'll implement authentication in a real world application.\n\nHow do we create the token passed to the `authorization` headers? Let's move on to the next section, so we can write our resolver for the `login` mutation.\n\n<h2 id=\"mutation\">Write Mutation resolvers</h2>\n\nWriting `Mutation` resolvers is similar to the resolvers we've already written. First, let's write the `login` resolver to complete our authentication flow. Add the code below to your resolver map underneath the `Query` resolvers:\n\n_src/resolvers.js_\n\n```js\nMutation: {\n  login: async (_, { email }, { dataSources }) => {\n    const user = await dataSources.userAPI.findOrCreateUser({ email });\n    if (user) return Buffer.from(email).toString('base64');\n  }\n},\n```\n\nThe `login` resolver receives an email address and returns a token if a user exists. In a later section, we'll learn how to save that token on the client.\n\nNow, let's add the resolvers for `bookTrips` and `cancelTrip` to `Mutation`:\n\n_src/resolvers.js_\n\n```js\nMutation: {\n  bookTrips: async (_, { launchIds }, { dataSources }) => {\n    const results = await dataSources.userAPI.bookTrips({ launchIds });\n    const launches = await dataSources.launchAPI.getLaunchesByIds({\n      launchIds,\n    });\n\n    return {\n      success: results && results.length === launchIds.length,\n      message:\n        results.length === launchIds.length\n          ? 'trips booked successfully'\n          : `the following launches couldn't be booked: ${launchIds.filter(\n              id => !results.includes(id),\n            )}`,\n      launches,\n    };\n  },\n  cancelTrip: async (_, { launchId }, { dataSources }) => {\n    const result = await dataSources.userAPI.cancelTrip({ launchId });\n\n    if (!result)\n      return {\n        success: false,\n        message: 'failed to cancel trip',\n      };\n\n    const launch = await dataSources.launchAPI.getLaunchById({ launchId });\n    return {\n      success: true,\n      message: 'trip cancelled',\n      launches: [launch],\n    };\n  },\n},\n```\n\nBoth `bookTrips` and `cancelTrips` must return the properties specified on our `TripUpdateResponse` type from our schema, which contains a success indicator, a status message, and an array of launches that we've either booked or cancelled. The `bookTrips` mutation can get tricky because we have to account for a partial success where some launches could be booked and some could fail. Right now, we're simply indicating a partial success in the `message` field to keep it simple.\n\n<h3 id=\"mutation-playground\">Run mutations in the playground</h3>\n\nIt's time for the fun part - running our mutations in the playground! Go back to the playground in your browser and reload the schema with the little return arrow at the top on the right of the address line.\n\nGraphQL mutations are structured exactly like queries, except they use the `mutation` keyword. Let's copy the mutation below and run in the playground:\n\n```graphql\nmutation LoginUser {\n  login(email: \"daisy@apollographql.com\")\n}\n```\n\nYou should receive back a string that looks like this: `ZGFpc3lAYXBvbGxvZ3JhcGhxbC5jb20=`. Copy that string because we will need it for the next mutation.\n\nNow, let's try booking some trips. Only authorized users are permitted to book trips, however. Luckily, the playground has a section where we can paste in our authorization header from the previous mutation to authenticate us as a user. First, paste this mutation into the playground:\n\n```graphql\nmutation BookTrips {\n  bookTrips(launchIds: [67, 68, 69]) {\n    success\n    message\n    launches {\n      id\n    }\n  }\n}\n```\n\nNext, paste our authorization header into the HTTP Headers box at the bottom:\n\n```json\n{\n  \"authorization\": \"ZGFpc3lAYXBvbGxvZ3JhcGhxbC5jb20=\"\n}\n```\n\nThen, run the mutation. You should see a success message, along with the ids of the mutations we just booked. Testing mutations manually in the playground is a good way to explore our API, but in a real-world application, we should run automated tests so we can safely refactor our code. In the next section, you'll actually learn about running your graph in production instead of testing your graph.\n","path":"/tutorial/resolvers","filePath":"docs/source/tutorial/resolvers.md"},{"title":"4. Run your graph in production","description":"Learn about deployment and essential developer tooling","content":"\nTime to accomplish: _15 Minutes_\n\nGreat job for making it this far! We've already learned how to build a GraphQL API with Apollo, connect it to REST and SQL data sources, and send GraphQL queries. Now that we've completed building our graph, it's finally time to deploy it! 🎉\n\nAn Apollo GraphQL API can be deployed to any cloud service, such as Heroku, AWS Lambda, or Netlify. In this tutorial, we'll deploy our graph API to [Zeit Now](https://zeit.co/now). You will need to create a [Now account](https://zeit.co/signup) in order to follow these steps. If you haven't already created an [Apollo Engine](https://engine.apollographql.com/) account, you will need to sign up for one.\n\n<h2 id=\"engine\">Publish your schema to Engine</h2>\n\nBefore we deploy our app, we need to publish our schema to the Apollo Engine cloud service in order to power developer tooling like VSCode and keep track of schema changes. Just like npm is a registry for JavaScript packages, Apollo Engine contains a schema registry that makes it simple to pull the most recent schema from the cloud.\n\nIn a production application, you should set up this publishing script as part of your CI workflow. For now, we will run a script in our terminal that uses the Apollo CLI to publish our schema to Engine.\n\n<h3 id=\"api-key\">Get an Engine API key</h3>\n\nFirst, we need an Apollo Engine API key. Navigate to [Apollo Engine](https://engine.apollographql.com/), login, and click on New Service at the top. The prompt will instruct you to name your service. When you're finished, click Create Service. You'll see a key appear prefixed by `service:`. Copy that key so we can save it as an environment variable.\n\nLet's save our key as an environment variable. It's important to make sure we don't check our Engine API key into version control. Go ahead and make a copy of the `.env.example` file located in `server/` and call it `.env`. Add your Engine API key that you copied from the previous step to the file:\n\n```\nENGINE_API_KEY=service:<your-service-name>:<hash-from-apollo-engine>\n```\n\nThe entry should basically look like this:\n\n```\nENGINE_API_KEY=service:my-service-439:E4VSTiXeFWaSSBgFWXOiSA\n```\n\nOur key is now stored under the environment variable `ENGINE_API_KEY`.\n\n<h3 id=\"publish\">Check and publish with the Apollo CLI</h3>\n\nIt's time to publish our schema to Engine! First, start your server in one terminal window by running `npm start`. In another terminal window, run:\n\n```bash\nnpx apollo service:push --endpoint=http://localhost:4000\n```\n\n> npx is a tool bundled with npm for easily running packages that are not installed globally.\n\nThis command publishes your schema to the Apollo registry. Once your schema is uploaded, you should be able to see your schema in the [Apollo Engine](https://engine.apollographql.com/) explorer. In future steps, we will pull down our schema from Engine in order to power the Apollo VSCode extension.\n\nFor subsequent publishes, we may first want to check for any breaking changes in our new schema against the old version. In a terminal window, run:\n\n```bash\nnpx apollo service:check --endpoint=http://localhost:4000\n```\n\n<h3 id=\"benefits\">What are the benefits of Engine?</h3>\n\nPublishing your schema to Apollo Engine unlocks many features necessary for running a graph API in production. Some of these features include:\n\n- **Schema explorer:** With Engine's powerful schema registry, you can quickly explore all the types and fields in your schema with usage statistics on each field. This metric makes you understand the cost of a field. How expensive is a field? Is a certain field in so much demand?\n- **Schema history:** Apollo Engine’s schema history allows developers to confidently iterate a graph's schema by validating the new schema against field-level usage data from the previous schema. This empowers developers to avoid breaking changes by providing insights into which clients will be broken by a new schema.\n- **Performance analytics:** Fine-grained insights into every field, resolvers and operations of your graph's execution\n- **Client awareness:** Report client identity (name and version) to your server for insights on client activity.\n\nWe also want to be transparent that the features we just described, such as viewing specific execution traces and validating schema changes against recent operations, are only available on a paid plan. Individual developers just getting started with GraphQL probably don't need these features, but they become incredibly valuable as you're working on a team. Additionally, layering these paid features on top of our free developer tools like Apollo VSCode makes them more intelligent over time.\n\nWe're committed to helping you succeed in building and running an Apollo graph API. This is why features such as publishing and downloading schemas from the registry, our open source offerings like Apollo Client and Apollo Server, and certain developer tools like Apollo VSCode and Apollo DevTools will always be free forever.\n\n<h2 id=\"deploy\">Deploy your graph API</h2>\n\nTo deploy our app to Now, run the `now` command from the `server` directory of the app. The command may prompt you to login if you haven't already.\n\n```bash\n$ npx now\n```\n\nThe `now` command immediately deploys our graph API to the cloud and returns the hosted URL. Make sure you either copy the URL or run `npx now ls` in your terminal to retrieve the URL, since we'll need it in the following section when we build our client.\n\nCongrats on deploying your first Apollo graph API! 🚀 Let's move on to the second half of the tutorial where we connect the API we just built to a React app.\n","path":"/tutorial/production","filePath":"docs/source/tutorial/production.md"},{"title":"5. Connect your API to a client","description":"Hook up your graph to Apollo Client","content":"\nTime to accomplish: _10 Minutes_\n\nThe next half of this tutorial exclusively focuses on connecting a graph API to a frontend with Apollo Client. **Apollo Client** is a complete data management solution for any client. It's view-layer agnostic, which means it can integrate with React, Vue, Angular, or even vanilla JS. Thanks to its intelligent cache, Apollo Client offers a single source of truth for all of the local and remote data in your application.\n\nWhile Apollo Client works with any view layer, it's most commonly used with React. In this section, you'll learn how to connect the graph API you just built in the previous half of this tutorial to a React app. Even if you're more comfortable with Vue or Angular, you should still be able to follow many of the examples since the concepts are the same. Along the way, you'll also learn how to build essential features like authentication and pagination, as well as tips for optimizing your workflow.\n\n<h2 id=\"dev-environment\">Set up your development environment</h2>\n\nFor this half of the tutorial, we will be working in the `client/` folder of the project. You should have the project already from the server portioned, but if you don't, make sure to clone [the tutorial](https://github.com/apollographql/fullstack-tutorial/). From the root of the project, run:\n\n```bash\ncd start/client && npm install\n```\n\nNow, our dependencies are installed. Here are the packages we will be using to build out our frontend:\n\n- `apollo-client`: A complete data management solution with an intelligent cache. In this tutorial, we will be using the Apollo Client 3.0 preview since it includes local state management capabilities and sets your cache up for you.\n- `react-apollo`: The view layer integration for React that exports components such as `Query` and `Mutation`\n- `graphql-tag`: The tag function `gql` that we use to wrap our query strings in order to parse them into an AST\n\n<h3 id=\"vscode\">Configure Apollo VSCode</h3>\n\nWhile Apollo VSCode is not required to successfully complete the tutorial, setting it up unlocks a lot of helpful features such as autocomplete for operations, jump to fragment definitions, and more.\n\nFirst, make a copy of the `.env.example` file located in `client/` and call it `.env`. Add your Engine API key that you already created in step #4 to the file:\n\n```\nENGINE_API_KEY=service:<your-service-name>:<hash-from-apollo-engine>\n```\n\nThe entry should basically look something like this:\n\n```\nENGINE_API_KEY=service:my-service-439:E4VSTiXeFWaSSBgFWXOiSA\n```\n\nOur key is now stored under the environment variable `ENGINE_API_KEY`. Apollo VSCode uses this API key to pull down your schema from the registry.\n\nNext, create an Apollo config file called `apollo.config.js`. This config file is how you configure both the Apollo VSCode extension and CLI. Paste the snippet below into the file:\n\n```js\nmodule.exports = {\n  client: {\n    name: 'Space Explorer [web]',\n    service: 'space-explorer',\n  },\n};\n```\n\nGreat, we're all set up! Let's dive into building our first client.\n\n<h2 id=\"apollo-client-setup\">Create an Apollo Client</h2>\n\nNow that we have installed the necessary packages, let's create an `ApolloClient` instance.\n\nNavigate to `src/index.js` so we can create our client. The `uri` that we pass in is the graph endpoint from the service you deployed in step 4.\n\nIf you didn't complete the server portion, you can use the `uri` from the code below. Otherwise, use your own deployment's URL, which may be different than the one below. Navigate to `src/index.js` and copy the code below:\n\n_src/index.js_\n\n```js\nimport { ApolloClient } from 'apollo-client';\nimport { InMemoryCache } from 'apollo-cache-inmemory';\nimport { HttpLink } from 'apollo-link-http';\n\nconst cache = new InMemoryCache();\nconst link = new HttpLink({\n  uri: 'http://localhost:4000/'\n})\nconst client = new ApolloClient({\n  cache,\n  link\n})\n\n```\n\nIn just a few lines of code, our client is ready to fetch data! Let's try making a query in the next section.\n\n<h2 id=\"first-query\">Make your first query</h2>\n\nBefore we show you how to use the React integration for Apollo, let's send a query with vanilla JavaScript.\n\nWith a `client.query()` call, we can query our graph's API. Add the following line of code to your imports in `src/index.js`.\n\n_src/index.js_\n\n```js line=1\nimport gql from \"graphql-tag\";\n```\nAnd add this code to the bottom of `index.js`:\n\n_src/index.js_\n```\n// ... above is the instantiation of the client object.\nclient\n  .query({\n    query: gql`\n      query GetLaunch {\n        launch(id: 56) {\n          id\n          mission {\n            name\n          }\n        }\n      }\n    `\n  })\n  .then(result => console.log(result));\n```\n\nOpen up your console and run `npm start`. This will compile your client app. Once it is finished, your browser should open to `http://localhost:3000/` automatically. When the index page opens, open up your [Developer Tools console](https://developers.google.com/web/tools/chrome-devtools/console/) and you should see an object with a `data` property containing the result of our query. You'll also see some other properties, like `loading` and `networkStatus`. This is because Apollo Client tracks the loading state of your query for you.\n\nApollo Client is designed to fetch graph data from any JavaScript frontend. No frameworks needed. However, there are view layer integrations for different frameworks that makes it easier to bind queries to the UI.\n\nGo ahead and delete the `client.query()` call you just made and the `gql` import statement. Now, we'll connect our client to React.\n\n<h2 id=\"react-apollo\">Connect your client to React</h2>\n\nConnecting Apollo Client to our React app with `react-apollo` allows us to easily bind GraphQL operations to our UI.\n\nTo connect Apollo Client to React, we will wrap our app in the `ApolloProvider` component exported from the `react-apollo` package and pass our client to the `client` prop. The `ApolloProvider` component is similar to React’s context provider. It wraps your React app and places the client on the context, which allows you to access it from anywhere in your component tree.\n\nOpen `src/index.js` and add the following lines of code:\n\n_src/index.js_\n\n```js lines=1,4,6\nimport { ApolloProvider } from 'react-apollo';\nimport React from 'react';\nimport ReactDOM from 'react-dom';\nimport Pages from './pages';\n\n// previous variable declarations\n\nReactDOM.render(\n  <ApolloProvider client={client}>\n    <Pages />\n  </ApolloProvider>, document.getElementById('root'));\n```\n\nNow, we're ready to start building our first `Query` components in the next section.\n","path":"/tutorial/client","filePath":"docs/source/tutorial/client.md"},{"title":"6. Fetch data with queries","description":"Learn how to fetch data with the Query component","content":"\n Time to accomplish: _15 Minutes_\n\nApollo Client simplifies fetching data from a graph API because it intelligently caches your data, as well as tracks loading and error state. In the previous section, we learned how to fetch a sample query with Apollo Client without using a view integration. In this section, we'll learn how to use the `Query` component from `react-apollo` to fetch more complex queries and execute features like pagination.\n\n<h2 id=\"fetch-data\">The Query component</h2>\n\nThe `Query` component is one of the most important building blocks of an Apollo app. It's a React component that fetches a GraphQL query and exposes the result so you can render your UI based on the data it returns.\n\nThe `Query` component uses the **render prop** pattern to fetch and load data from queries into our UI. The render prop pattern provides the ability to add a function as a child to our `Query` component that will notify React about what you want to render. It exposes the `error`, `loading` and `data` on a result object that is passed into the render prop function. Let's see an example:\n\n<h2 id=\"launches\">Fetching a list</h2>\n\nTo create a `Query` component, import `Query` from `react-apollo`, pass your query wrapped with `gql` to `this.props.query`, and provide a render prop function to `this.props.children` that uses the `loading`, `data`, and `error` properties on the result object to render UI in your app.\n\nFirst, we're going to build a GraphQL query that fetches a list of launches. We're also going to import some components that we will need in the next step. Navigate to `src/pages/launches.js` to get started and copy the code below into the file.\n\n_src/pages/launches.js_\n\n```js\nimport React, { Fragment } from 'react';\nimport { Query } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { LaunchTile, Header, Button, Loading } from '../components';\n\nconst GET_LAUNCHES = gql`\n  query launchList($after: String) {\n    launches(after: $after) {\n      cursor\n      hasMore\n      launches {\n        id\n        isBooked\n        rocket {\n          id\n          name\n        }\n        mission {\n          name\n          missionPatch\n        }\n      }\n    }\n  }\n`;\n```\n\nHere, we're defining a query to fetch a list of launches by calling the `launches` query from our schema. The `launches` query returns an object type with a list of launches, in addition to the `cursor` of the paginated list and whether or not the list `hasMore` launches. We need to wrap the query with the `gql` function in order to parse it into an AST.\n\nNow, let's pass that query to Apollo's `Query` component to render the list:\n\n_src/pages/launches.js_\n\n```js\nexport default function Launches() {\n  return (\n    <Query query={GET_LAUNCHES}>\n      {({ data, loading, error }) => {\n        if (loading) return <Loading />;\n        if (error) return <p>ERROR</p>;\n\n        return (\n          <Fragment>\n            <Header />\n            {data.launches &&\n              data.launches.launches &&\n              data.launches.launches.map(launch => (\n                <LaunchTile\n                  key={launch.id}\n                  launch={launch}\n                />\n              ))}\n          </Fragment>\n        );\n      }}\n    </Query>\n  );\n};\n```\n\nTo render the list, we pass the `GET_LAUNCHES` query from the previous step into our `Query` component. We then define a render prop function as the child of `Query` that's called with the state of our query (`loading`, `error`, and `data`). Depending on the state, we either render a loading indicator, an error message, or a list of launches.\n\nWe're not done yet! Right now, this query is only fetching the first 20 launches from the list. To fetch the full list of launches, we need to build a pagination feature that displays a `Load More` button for loading more items on the screen. Let's learn how!\n\n<h3 id=\"pagination\">Build a paginated list</h3>\n\nApollo Client has built-in helpers to make adding pagination to our app much easier than it would be if we were writing the logic ourselves.\n\nTo build a paginated list with Apollo, we first need to destructure the `fetchMore` function from the `Query` render prop function.\n\n_src/pages/launches.js_\n\n```js lines=4\nexport default function Launches() {\n  return (\n    <Query query={GET_LAUNCHES}>\n      {({ data, loading, error, fetchMore }) => {\n        // same as above\n      }}\n    </Query>\n  );\n};\n```\n\nNow that we have `fetchMore`, let's connect it to a Load More button to fetch more items when it's clicked. To do this, we will need to specify an `updateQuery` function on the return object from `fetchMore` that tells the Apollo cache how to update our query with the new items we're fetching.\n\nCopy the code below and add it above the closing `</Fragment>` tag in the render prop function we added in the previous step.\n\n_src/pages/launches.js_\n\n```js lines=5,9\n{data.launches &&\n  data.launches.hasMore && (\n    <Button\n      onClick={() =>\n        fetchMore({\n          variables: {\n            after: data.launches.cursor,\n          },\n          updateQuery: (prev, { fetchMoreResult, ...rest }) => {\n            if (!fetchMoreResult) return prev;\n            return {\n              ...fetchMoreResult,\n              launches: {\n                ...fetchMoreResult.launches,\n                launches: [\n                  ...prev.launches.launches,\n                  ...fetchMoreResult.launches.launches,\n                ],\n              },\n            };\n          },\n        })\n      }\n    >\n      Load More\n    </Button>\n  )\n}\n```\n\nFirst, we check to see if we have more launches available in our query. If we do, we render a button with a click handler that calls the `fetchMore` function from Apollo. The `fetchMore` function receives new variables for the list of launches query, which is represented by our cursor.\n\nWe also define the `updateQuery` function to tell Apollo how to update the list of launches in the cache. To do this, we take the previous query result and combine it with the new query result from `fetchMore`.\n\nIn the next step, we'll learn how to wire up the launch detail page to display a single launch when an item in the list is clicked.\n\n<h2 id=\"launch\">Fetching a single launch</h2>\n\nLet's navigate to `src/pages/launch.js` to build out our detail page. First, we should import some components and define our GraphQL query to get the launch details.\n\n_src/pages/launch.js_\n\n```js\nimport React, { Fragment } from 'react';\nimport { Query } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport Loading from '../components/loading';\nimport Header from '../components/header';\nimport ActionButton from '../containers/action-button';\nimport LaunchDetail from '../components/launch-detail';\n\nexport const GET_LAUNCH_DETAILS = gql`\n  query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      id\n      site\n      isBooked\n      rocket {\n        id\n        name\n        type\n      }\n      mission {\n        name\n        missionPatch\n      }\n    }\n  }\n`;\n```\n\nNow that we have a query, let's render a `Query` component to execute it. This time, we'll also need to pass in the `launchId` as a variable to the query, which we'll do by adding a `variables` prop to `Query`. The `launchId` comes through as a prop from the router.\n\n_src/pages/launch.js_\n\n```js\nexport default function Launch({ launchId }) {\n  return (\n    <Query query={GET_LAUNCH_DETAILS} variables={{ launchId }}>\n      {({ data, loading, error }) => {\n        if (loading) return <Loading />;\n        if (error) return <p>ERROR: {error.message}</p>;\n\n        return (\n          <Fragment>\n            <Header image={data.launch.mission.missionPatch}>\n              {data.launch.mission.name}\n            </Header>\n            <LaunchDetail {...data.launch} />\n            <ActionButton {...data.launch} />\n          </Fragment>\n        );\n      }}\n    </Query>\n  );\n}\n```\n\nJust like before, we use the status of the query to render either a `loading` or `error` state, or data when the query completes.\n\n<h3 id=\"fragments\">Using fragments to share code</h3>\n\nYou may have noticed that the queries for fetching a list of launches and fetching a launch detail share a lot of the same fields. When we have two GraphQL operations that contain the same fields, we can use a **fragment** to share fields between the two.\n\nTo learn how to build a fragment, navigate to `src/pages/launches.js` and copy the code below into the file:\n\n_`src/pages/launches.js`_\n\n```js\nexport const LAUNCH_TILE_DATA = gql`\n  fragment LaunchTile on Launch {\n    id\n    isBooked\n    rocket {\n      id\n      name\n    }\n    mission {\n      name\n      missionPatch\n    }\n  }\n`;\n```\n\nWe define a GraphQL fragment by giving it a name (`LaunchTile`) and defining it on a type on our schema (`Launch`). The name we give our fragment can be anything, but the type must correspond to a type in our schema.\n\nTo use our fragment in our query, we import it into the GraphQL document and use the spread operator to spread the fields into our query:\n\n_`src/pages/launches.js`_\n\n```js lines=6,10\nconst GET_LAUNCHES = gql`\n  query launchList($after: String) {\n    launches(after: $after) {\n      cursor\n      hasMore\n      launches {\n        ...LaunchTile\n      }\n    }\n  }\n  ${LAUNCH_TILE_DATA}\n`;\n```\n\nLet's use our fragment in our launch detail query too. Be sure to import the fragment from the `launches` page before you use it:\n\n```js lines=1,10,13\nimport { LAUNCH_TILE_DATA } from './launches';\n\nexport const GET_LAUNCH_DETAILS = gql`\n  query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      site\n      rocket {\n        type\n      }\n      ...LaunchTile\n    }\n  }\n  ${LAUNCH_TILE_DATA}\n`;\n```\n\nGreat, now we've successfully refactored our queries to use fragments. Fragments are a helpful tool that you'll use a lot as you're building GraphQL queries and mutations.\n\n<h3 id=\"fetch-policy\">Customizing the fetch policy</h3>\n\nSometimes, it's useful to tell Apollo Client to bypass the cache altogether if you have some data that constantly needs to be refreshed. We can do this by customizing the `Query` component's `fetchPolicy`.\n\nFirst, let's navigate to `src/pages/profile.js` and write our query:\n\n_src/pages/profile.js_\n\n```js\nimport React, { Fragment } from 'react';\nimport { Query } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { Loading, Header, LaunchTile } from '../components';\nimport { LAUNCH_TILE_DATA } from './launches';\n\nconst GET_MY_TRIPS = gql`\n  query GetMyTrips {\n    me {\n      id\n      email\n      trips {\n        ...LaunchTile\n      }\n    }\n  }\n  ${LAUNCH_TILE_DATA}\n`;\n```\n\nNext, let's render a `Query` component to fetch a logged in user's list of trips. By default, Apollo Client's fetch policy is `cache-first`, which means it checks the cache to see if the result is there before making a network request. Since we want this list to always reflect the newest data from our graph API, we set the `fetchPolicy` for this query to `network-only`:\n\n_src/pages/profile.js_\n\n```js lines=3\nexport default function Profile() {\n  return (\n    <Query query={GET_MY_TRIPS} fetchPolicy=\"network-only\">\n      {({ data, loading, error }) => {\n        if (loading) return <Loading />;\n        if (error) return <p>ERROR: {error.message}</p>;\n\n        return (\n          <Fragment>\n            <Header>My Trips</Header>\n            {data.me && data.me.trips.length ? (\n              data.me.trips.map(launch => (\n                <LaunchTile key={launch.id} launch={launch} />\n              ))\n            ) : (\n              <p>You haven't booked any trips</p>\n            )}\n          </Fragment>\n        );\n      }}\n    </Query>\n  );\n}\n```\n\nIf you try to render this query, you'll notice that it returns null. This is because we need to implement our login feature first. We're going to tackle login in the next section.\n\nNow that we've learned how to build `Query` components that can fetch a paginated list, share fragments, and customize the fetch policy, it's time to progress to the next section so we can learn how to update data with mutations!\n","path":"/tutorial/queries","filePath":"docs/source/tutorial/queries.md"},{"title":"7. Update data with mutations","description":"Learn how to update data with the Mutation component","content":"\nTime to accomplish: _12 Minutes_\n\nWith Apollo Client, updating data from a graph API is as simple as calling a function. Additionally, the Apollo Client cache is smart enough to automatically update in most cases. In this section, we'll learn how to use the `Mutation` component from `react-apollo` to login a user.\n\n<h2 id=\"query-component\">What is a Mutation component?</h2>\n\nThe `Mutation` component is another important building block in an Apollo app. It's a React component that provides a function to execute a GraphQL mutation. Additionally, it tracks the loading, completion, and error state of that mutation.\n\nUpdating data with a `Mutation` component from `react-apollo` is very similar to fetching data with a `Query` component. The main difference is that the first argument to the `Mutation` render prop function is a **mutate function** that actually triggers the mutation when it is called. The second argument to the `Mutation` render prop function is a result object that contains loading and error state, as well as the return value from the mutation. Let's see an example:\n\n<h2 id=\"fetch-data\">Update data with Mutation</h2>\n\nThe first step is defining our GraphQL mutation. To start, navigate to `src/pages/login.js` and copy the code below so we can start building out the login screen:\n\n_src/pages/login.js_\n\n```js\nimport React from 'react';\nimport { Mutation, ApolloConsumer } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { LoginForm, Loading } from '../components';\n\nconst LOGIN_USER = gql`\n  mutation login($email: String!) {\n    login(email: $email)\n  }\n`;\n```\n\nJust like before, we're using the `gql` function to wrap our GraphQL mutation so it can be parsed into an AST. We're also importing some components that we'll use in the next steps. Now, let's bind this mutation to our component by passing it to the `mutation` prop:\n\n_src/pages/login.js_\n\n```js\nexport default function Login() {\n  return (\n    <Mutation mutation={LOGIN_USER}>\n      {(login, { data }) => <LoginForm login={login} />}\n    </Mutation>\n  );\n}\n```\n\nOur `Mutation` component takes a render prop function as a child that exposes a mutate function (`login`) and the data object returned from the mutation. Finally, we pass our login function to the `LoginForm` component.\n\nTo create a better experience for our users, we want to persist the login between sessions. In order to do that, we need to save our login token to `localStorage`. Let's learn how we can use the `onCompleted` handler on `Mutation` to persist our login:\n\n<h3 id=\"apolloconsumer\">Expose Apollo Client with ApolloConsumer</h3>\n\nOne of the main functions of `react-apollo` is that it puts your `ApolloClient` instance on React's context. Sometimes, we need to access the `ApolloClient` instance to directly call a method that isn't exposed by the `react-apollo` helper components. The `ApolloConsumer` component can help us access the client.\n\n`ApolloConsumer` takes a render prop function as a child that is called with the client instance. Let's wrap our `Mutation` component with `ApolloConsumer` to expose the client. Next, we want to pass an `onCompleted` callback to `Mutation` that will be called once the mutation is complete with its return value. This callback is where we will save the login token to `localStorage`.\n\nIn our `onCompleted` handler, we also call `client.writeData` to write local data to the Apollo cache indicating that the user is logged in. This is an example of a **direct write** that we'll explore further in the next section on local state management.\n\n_src/pages/login.js_\n\n```js lines=3,4,7-10,22\nexport default function Login() {\n  return (\n    <ApolloConsumer>\n      {client => (\n        <Mutation\n          mutation={LOGIN_USER}\n          onCompleted={({ login }) => {\n            localStorage.setItem('token', login);\n            client.writeData({ data: { isLoggedIn: true } });\n          }}\n        >\n          {(login, { loading, error }) => {\n            // this loading state will probably never show, but it's helpful to\n            // have for testing\n            if (loading) return <Loading />;\n            if (error) return <p>An error occurred</p>;\n\n            return <LoginForm login={login} />;\n          }}\n        </Mutation>\n      )}\n    </ApolloConsumer>\n  );\n}\n```\n\n<h3 id=\"authenticate\">Attach authorization headers to the request</h3>\n\nWe're almost done completing our login feature! Before we do, we need to attach our token to the GraphQL request's headers so our server can authorize the user. To do this, navigate to `src/index.js` where we create our `ApolloClient` and replace the code below for the constructor:\n\n_src/index.js_\n\n```js lines=5,6\nconst client = new ApolloClient({\n  cache,\n  link: new HttpLink({\n    uri: 'http://localhost:4000/graphql',\n    headers: {\n      authorization: localStorage.getItem('token'),\n    },\n  }),\n});\n\ncache.writeData({\n  data: {\n    isLoggedIn: !!localStorage.getItem('token'),\n    cartItems: [],\n  },\n});\n```\n\nSpecifying the `headers` option on `HttpLink` allows us to read the token from `localStorage` and attach it to the request's headers each time a GraphQL operation is made.\n\nIn the next section, we'll add the `<Login>` form to the user interface. For that, we need to learn how Apollo allows us to manage local state in our app.\n","path":"/tutorial/mutations","filePath":"docs/source/tutorial/mutations.md"},{"title":"8. Manage local state","description":"How to store and query local data in the Apollo cache","content":"\nTime to accomplish: _15 Minutes_\n\nIn almost every app we build, we display a combination of remote data from our graph API and local data such as network status, form state, and more. What's awesome about Apollo Client is that it allows us to store local data inside the Apollo cache and query it alongside our remote data with GraphQL.\n\nWe recommend managing local state in the Apollo cache instead of bringing in another state management library like Redux so the Apollo cache can be a single source of truth.\n\nManaging local data with Apollo Client is very similar to how you've already managed remote data in this tutorial. You'll write a client schema and resolvers for your local data. You'll also learn to query it with GraphQL just by specifying the `@client` directive. Let's dive in!\n\n<h2 id=\"local-schema\">Write a local schema</h2>\n\nJust like how a schema is the first step toward defining our data model on the server, writing a local schema is the first step we take on the client.\n\nNavigate to `src/resolvers.js` and copy the following code to create your client schema (as well as blank client resolvers for later):\n\n_src/resolvers.js_\n\n```js\nimport gql from 'graphql-tag';\n\nexport const typeDefs = gql`\n  extend type Query {\n    isLoggedIn: Boolean!\n    cartItems: [ID!]!\n  }\n\n  extend type Launch {\n    isInCart: Boolean!\n  }\n\n  extend type Mutation {\n    addOrRemoveFromCart(id: ID!): [Launch]\n  }\n`;\n\nexport const resolvers = {};\n```\n\nTo build a client schema, we **extend** the types of our server schema and wrap it with the `gql` function. Using the extend keyword allows us to combine both schemas inside developer tooling like Apollo VSCode and Apollo DevTools.\n\nWe can also add local fields to server data by extending types from our server. Here, we're adding the `isInCart` local field to the `Launch` type we receive back from our graph API.\n\n<h2 id=\"store-initialization\">Initialize the store</h2>\n\nNow that we've created our client schema, let's learn how to initialize the store. Since queries execute as soon as the component mounts, it's important for us to warm the Apollo cache with some default state so those queries don't error out. We will need to write initial data to the cache for both `isLoggedIn` and `cartItems`:\n\nJump back to `src/index.js` and notice we had already added a `cache.writeData` call to prepare the cache in the last section. While we're here, make sure to also import the `typeDefs` and `resolvers` that we just created so we can use them later:\n\n_src/index.js_\n\n```js line=1,11-12,15-20\nimport { resolvers, typeDefs } from './resolvers';\n\nconst client = new ApolloClient({\n  cache,\n  link: new HttpLink({\n    uri: 'http://localhost:4000/graphql',\n    headers: {\n      authorization: localStorage.getItem('token'),\n    },\n  }),\n  typeDefs,\n  resolvers,\n});\n\ncache.writeData({\n  data: {\n    isLoggedIn: !!localStorage.getItem('token'),\n    cartItems: [],\n  },\n});\n```\n\nNow that we've added default state to the Apollo cache, let's learn how to query local data from within our React components.\n\n<h2 id=\"local-query\">Query local data</h2>\n\nQuerying local data from the Apollo cache is almost the same as querying remote data from a graph API. The only difference is that you add a `@client` directive to a local field to tell Apollo Client to pull it from the cache.\n\nLet's look at an example where we query the `isLoggedIn` field we wrote to the cache in the last mutation exercise.\n\n_src/index.js_\n\n```js line=8,17-19\nimport { Query, ApolloProvider } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport Pages from './pages';\nimport Login from './pages/login';\nimport injectStyles from './styles';\n\nconst IS_LOGGED_IN = gql`\n  query IsUserLoggedIn {\n    isLoggedIn @client\n  }\n`;\n\ninjectStyles();\nReactDOM.render(\n  <ApolloProvider client={client}>\n    <Query query={IS_LOGGED_IN}>\n      {({ data }) => (data.isLoggedIn ? <Pages /> : <Login />)}\n    </Query>\n  </ApolloProvider>,\n  document.getElementById('root'),\n);\n```\n\nFirst, we create our `IsUserLoggedIn` local query by adding the `@client` directive to the `isLoggedIn` field. Then, we render a `Query` component, pass our local query in, and specify a render prop function that renders either a login screen or the homepage depending if the user is logged in. Since cache reads are synchronous, we don't have to account for any loading state.\n\nLet's look at another example of a component that queries local state in `src/pages/cart.js`. Just like before, we create our query:\n\n_src/pages/cart.js_\n\n```js\nimport React, { Fragment } from 'react';\nimport { Query } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { Header, Loading } from '../components';\nimport { CartItem, BookTrips } from '../containers';\n\nexport const GET_CART_ITEMS = gql`\n  query GetCartItems {\n    cartItems @client\n  }\n`;\n```\n\nNext, we render our `Query` component and bind it to our `GetCartItems` query:\n\n_src/pages/cart.js_\n\n```js\nexport default function Cart() {\n  return (\n    <Query query={GET_CART_ITEMS}>\n      {({ data, loading, error }) => {\n        if (loading) return <Loading />;\n        if (error) return <p>ERROR: {error.message}</p>;\n        return (\n          <Fragment>\n            <Header>My Cart</Header>\n            {!data.cartItems || !data.cartItems.length ? (\n              <p data-testid=\"empty-message\">No items in your cart</p>\n            ) : (\n              <Fragment>\n                {data.cartItems.map(launchId => (\n                  <CartItem key={launchId} launchId={launchId} />\n                ))}\n                <BookTrips cartItems={data.cartItems} />\n              </Fragment>\n            )}\n          </Fragment>\n        );\n      }}\n    </Query>\n  );\n}\n```\n\nIt's important to note that you can mix local queries with remote queries in a single GraphQL document. Now that you're a pro at querying local data with GraphQL, let's learn how to add local fields to server data.\n\n<h3 id=\"virtual-fields\">Adding virtual fields to server data</h3>\n\nOne of the unique advantages of managing your local data with Apollo Client is that you can add **virtual fields** to data you receive back from your graph API. These fields only exist on the client and are useful for decorating server data with local state. In our example, we're going to add an `isInCart` virtual field to our `Launch` type.\n\nTo add a virtual field, first extend the type of the data you're adding the field to in your client schema. Here, we're extending the `Launch` type:\n\n_src/resolvers.js_\n\n```js\nimport gql from 'graphql-tag';\n\nexport const schema = gql`\n  extend type Launch {\n    isInCart: Boolean!\n  }\n`;\n```\n\nNext, specify a client resolver on the `Launch` type to tell Apollo Client how to resolve your virtual field:\n\n_src/resolvers.js_\n\n```js\nexport const resolvers = {\n  Launch: {\n    isInCart: (launch, _, { cache }) => {\n      const { cartItems } = cache.readQuery({ query: GET_CART_ITEMS });\n      return cartItems.includes(launch.id);\n    },\n  },\n};\n```\n\nWe're going to learn more about client resolvers in the section below. The important thing to note is that the resolver API on the client is the same as the resolver API on the server.\n\nNow, you're ready to query your virtual field on the launch detail page! Similar to the previous examples, just add your virtual field to a query and specify the `@client` directive.\n\n_src/pages/launch.js_\n\n```js line=4\nexport const GET_LAUNCH_DETAILS = gql`\n  query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      isInCart @client\n      site\n      rocket {\n        type\n      }\n      ...LaunchTile\n    }\n  }\n  ${LAUNCH_TILE_DATA}\n`;\n```\n\n<h2 id=\"local-mutation\">Update local data</h2>\n\nUp until now, we've focused on querying local data from the Apollo cache. Apollo Client also lets you update local data in the cache with either **direct cache writes** or **client resolvers**. Direct writes are typically used to write simple booleans or strings to the cache whereas client resolvers are for more complicated writes such as adding or removing data from a list.\n\n<h3 id=\"direct-writes\">Direct cache writes</h3>\n\nDirect cache writes are convenient when you want to write a simple field, like a boolean or a string, to the Apollo cache. We perform a direct write by calling `client.writeData()` and passing in an object with a data property that corresponds to the data we want to write to the cache. We've already seen an example of a direct write, when we called `client.writeData` in the `onCompleted` handler for the login `Mutation` component. Let's look at a similar example, where we copy the code below to create a logout button:\n\n_src/containers/logout-button.js_\n\n```js line=14\nimport React from 'react';\nimport styled from 'react-emotion';\nimport { ApolloConsumer } from 'react-apollo';\n\nimport { menuItemClassName } from '../components/menu-item';\nimport { ReactComponent as ExitIcon } from '../assets/icons/exit.svg';\n\nexport default function LogoutButton() {\n  return (\n    <ApolloConsumer>\n      {client => (\n        <StyledButton\n          onClick={() => {\n            client.writeData({ data: { isLoggedIn: false } });\n            localStorage.clear();\n          }}\n        >\n          <ExitIcon />\n          Logout\n        </StyledButton>\n      )}\n    </ApolloConsumer>\n  );\n}\n\nconst StyledButton = styled('button')(menuItemClassName, {\n  background: 'none',\n  border: 'none',\n  padding: 0,\n});\n```\n\nWhen we click the button, we perform a direct cache write by calling `client.writeData` and passing in a data object that sets the `isLoggedIn` boolean to false.\n\nWe can also perform direct writes within the `update` function of a `Mutation` component. The `update` function allows us to manually update the cache after a mutation occurs without refetching data. Let's look at an example in `src/containers/book-trips.js`:\n\n_src/containers/book-trips.js_\n\n```js line=30-32\nimport React from 'react';\nimport { Mutation } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport Button from '../components/button';\nimport { GET_LAUNCH } from './cart-item';\n\nconst BOOK_TRIPS = gql`\n  mutation BookTrips($launchIds: [ID]!) {\n    bookTrips(launchIds: $launchIds) {\n      success\n      message\n      launches {\n        id\n        isBooked\n      }\n    }\n  }\n`;\n\nexport default function BookTrips({ cartItems }) {\n  return (\n    <Mutation\n      mutation={BOOK_TRIPS}\n      variables={{ launchIds: cartItems }}\n      refetchQueries={cartItems.map(launchId => ({\n        query: GET_LAUNCH,\n        variables: { launchId },\n      }))}\n      update={cache => {\n        cache.writeData({ data: { cartItems: [] } });\n      }}\n    >\n      {(bookTrips, { data, loading, error }) =>\n        data && data.bookTrips && !data.bookTrips.success ? (\n          <p data-testid=\"message\">{data.bookTrips.message}</p>\n        ) : (\n          <Button onClick={bookTrips} data-testid=\"book-button\">\n            Book All\n          </Button>\n        )\n      }\n    </Mutation>\n  );\n}\n```\n\nIn this example, we're directly calling `cache.writeData` to reset the state of the `cartItems` after the `BookTrips` mutation is sent to the server. This direct write is performed inside of the update function, which is passed our Apollo Client instance.\n\n<h3 id=\"resolvers\">Local resolvers</h3>\n\nWe're not done yet! What if we wanted to perform a more complicated local data update such as adding or removing items from a list? For this situation, we'll use a local resolver. Local resolvers have the same function signature as remote resolvers (`(parent, args, context, info) => data`). The only difference is that the Apollo cache is already added to the context for you. Inside your resolver, you'll use the cache to read and write data.\n\nLet's write the local resolver for the `addOrRemoveFromCart` mutation. You should place this resolver underneath the `Launch` resolver we wrote earlier.\n\n_src/resolvers.js_\n\n```js\nexport const resolvers = {\n  Mutation: {\n    addOrRemoveFromCart: (_, { id }, { cache }) => {\n      const { cartItems } = cache.readQuery({ query: GET_CART_ITEMS });\n      const data = {\n        cartItems: cartItems.includes(id)\n          ? cartItems.filter(i => i !== id)\n          : [...cartItems, id],\n      };\n      cache.writeQuery({ query: GET_CART_ITEMS, data });\n      return data.cartItems;\n    },\n  },\n};\n```\n\nIn this resolver, we destructure the Apollo `cache` from the context in order to read the query that fetches cart items. Once we have our cart data, we either remove or add the cart item's `id` passed into the mutation to the list. Finally, we return the updated list from the mutation.\n\nLet's see how we call the `addOrRemoveFromCart` mutation in a component:\n\n_src/containers/action-button.js_\n\n```js\nimport gql from 'graphql-tag';\n\nconst TOGGLE_CART = gql`\n  mutation addOrRemoveFromCart($launchId: ID!) {\n    addOrRemoveFromCart(id: $launchId) @client\n  }\n`;\n```\n\nJust like before, the only thing we need to add to our mutation is a `@client` directive to tell Apollo to resolve this mutation from the cache instead of a remote server.\n\nNow that our local mutation is complete, let's build out the rest of the `ActionButton` component so we can finish building the cart:\n\n_src/containers/action-button.js_\n\n```js\nimport React from 'react';\nimport { Mutation } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { GET_LAUNCH_DETAILS } from '../pages/launch';\nimport Button from '../components/button';\n\nconst CANCEL_TRIP = gql`\n  mutation cancel($launchId: ID!) {\n    cancelTrip(launchId: $launchId) {\n      success\n      message\n      launches {\n        id\n        isBooked\n      }\n    }\n  }\n`;\n\nexport default function ActionButton({ isBooked, id, isInCart }) {\n  return (\n    <Mutation\n      mutation={isBooked ? CANCEL_TRIP : TOGGLE_CART}\n      variables={{ launchId: id }}\n      refetchQueries={[\n        {\n          query: GET_LAUNCH_DETAILS,\n          variables: { launchId: id },\n        },\n      ]}\n    >\n      {(mutate, { loading, error }) => {\n        if (loading) return <p>Loading...</p>;\n        if (error) return <p>An error occurred</p>;\n\n        return (\n          <div>\n            <Button\n              onClick={mutate}\n              isBooked={isBooked}\n              data-testid={'action-button'}\n            >\n              {isBooked\n                ? 'Cancel This Trip'\n                : isInCart\n                ? 'Remove from Cart'\n                : 'Add to Cart'}\n            </Button>\n          </div>\n        );\n      }}\n    </Mutation>\n  );\n}\n```\n\nIn this example, we're using the `isBooked` prop passed into the component to determine which mutation we should fire. Just like remote mutations, we can pass in our local mutations to the same `Mutation` component.\n\n---\n\nCongratulations! 🎉 You've officially made it to the end of the Apollo platform tutorial. In the final section, we're going to recap what we just learned and give you guidance on what you should learn next.\n","path":"/tutorial/local-state","filePath":"docs/source/tutorial/local-state.md"}]},{"title":"Platform","pages":[{"title":"Tracking your GraphQL schema","description":"A central hub for your GraphQL API","content":"\nApollo includes a schema registry that serves as a [central hub](https://principledgraphql.com/integrity#3-track-the-schema-in-a-registry) for tracking your GraphQL schema. Adopting a shared schema registry for your project has many benefits:\n\n- Unlike introspection, which provides a snapshot of a particular server's current schema, the registry serves as a global source of truth for the schema. In small projects this frees you from always needing a running server to access the schema. At scale, it avoids issues related to running multiple servers that may not always be in sync (eg, rolling updates).\n- Much like a source control system, Apollo's schema registry tracks a full history of a schema and how it changed over time. This is valuable for understanding and collaborating on a GraphQL API, especially as your team grows.\n- Having a registry allows you to disable introspection in production – a recommended best practice for good security.\n- Tools like the [Apollo VS Code extension](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo) can automatically fetch your schema from the registry and provide intellisense like field descriptions and deprecations directly in your editor.\n- Apollo's registry lets you track related _variants_ of a schema, like staging or alpha versions. It's helpful to have these schema definitions handy without having to juggle running servers that implement them.\n\n<h2 id=\"setup\">Using the Schema Registry</h2>\n\nTo get started using the schema registry, you'll need to make sure your repository is configured to be an Apollo project by:\n\n1. [Installing the Apollo CLI](#install-cli)\n1. [Creating a `.env` file in the root of your project with an `ENGINE_API_KEY`](#api-key)\n1. [Creating an `apollo.config.js` file at the root of your project and adding the right configuration](#apollo-config)\n\n#### CLI commands\n\nOnce you have that set up, you'll be ready to start connecting to the schema regsitry using the CLI:\n\n- `apollo service:push`&mdash; push a new schema to the registry.\n- `apollo service:check`&mdash; calculate a local schema diff and compare the changes against live traffic to validate if the changes are _safe_ or if they will _break_ live running queries.\n\n<h3 id=\"install-cli\">Install the Apollo CLI</h3>\n\nTo install the [`apollo` CLI](https://npm.im/apollo), ensure that `node` and `npm` are both installed, then run:\n\n```bash\nnpm install --global apollo\n```\n\n> **Note:** This guide will utilize the global installation method, but the `apollo` command can also be installed in a project's `devDependencies` and used via [`npm-scripts`](https://docs.npmjs.com/misc/scripts) or [`npx`](https://npm.im/npx).\n\n<h3 id=\"api-key\">Get your Engine API key</h3>\n\nTo get an API key, you will need to [log in to Engine](https://engine.apollographql.com) and create a new service by clicking the \"Add Service\" button. If you already have a service, get your API key by visiting your service's settings page. Once you have your API key, add it to your `.env` file like so:\n\n```\nENGINE_API_KEY=service:foobar:d1rzyrmanmrZXxTTQLxghX\n```\n\nThe Apollo CLI will be looking for your `.env` file because it uses your Engine API key to authenticate with the schema registry when it pushes your schema.\n\n> **Note:** Make sure your `.env` file is in the root of your project so the Apollo CLI knows where to find it. You can also export `ENGINE_API_KEY` as an environment variable.\n\n<h3 id=\"apollo-config\">Create an `apollo.config.js` file</h3>\n\nThe commands executed through the Apollo CLI will be looking for your Apollo config to inform their behavior. To set up schema registration, you'll need to configure a source that the CLI can fetch your schema from like so:\n\n```js\nmodule.exports = {\n  service: {\n    endpoint: {\n      url: \"http://localhost:4000\"\n    }\n    // OR\n    localSchemaFile: './path/to/schema.graphql'\n  }\n};\n```\n\nThe [Apollo config documentation](/docs/references/apollo-config.html#service-config) has more details and advanced configuration options for the `apollo.config.js` format.\n\n<h2 id=\"push\">Registering a schema</h2>\n\nNew versions of your schema are registered to Apollo by running the `apollo service:push` command from within your repository.\n\nThe CLI will know where to fetch your local schema from based on your `apollo.config.js` configuration. Every time you push a new version of your schema it will be logged to your graph's schema history.\n\nHere's what running `apollo service:push` will look like:\n\n```\n~$ apollo service:push\n  ✔ Loading Apollo Project\n  ✔ Uploading service to Engine\n\nid      schema        tag\n──────  ────────────  ───────\n190330  example-4218  current\n```\n\n### Hooking into CI\n\nTo get the full value out of Apollo, your graph's schema history should be as accurately represented in the registry as possible. We _highly recommend_ hooking `apollo service:push` into your repository's continuous delivery pipeline so your schema is updated in the registry on every deploy. This will ensure that you always get intellisense for your live-running schema in your VS Code extension, for example.\n\nHere is a sample continuous delivery configuration for pushing a schema to Apollo using CircleCI:\n\n```yaml line=13,29-31\nversion: 2\n\njobs:\n  build:\n    docker:\n      - image: circleci/node:8\n\n    steps:\n      - checkout\n\n      - run: npm install\n      # CircleCI needs global installs to be sudo\n      - run: sudo npm install --global apollo\n\n      # Start the GraphQL server.  If a different command is used to\n      # start the server, use it in place of `npm start` here.\n      - run:\n          name: Starting server\n          command: npm start\n          background: true\n\n      # make sure the server has enough time to start up before running\n      # commands against it\n      - run: sleep 5\n\n      # When running on the 'master' branch, push the latest version\n      # of the schema to Apollo Engine.\n      - run: |\n          if [ \"${CIRCLE_BRANCH}\" == \"master\" ]; then\n            apollo service:push --tag=master\n          fi\n```\n\n<h2 id=\"history\">Viewing schema change history</h2>\n\nChanges made to your graph's schema over time can be viewed in [Engine](https://engine.apollographql.com) by browsing to the History page for your graph. Each time you push a new version of your schema, it will appear in your graph's history along with a list of the changes introduced in that version.\n\n<img src=\"../images/schema-history.png\" width=\"100%\" alt=\"Schema history page in the Engine UI\">\n\n<h2 id=\"schema-tags\">Managing environments</h2>\n\nProduct cycles move fast and it's common for schemas to be slightly different across environments as changes make their way through your system. To support this, schemas pushed to the registry can be associated with specific _variants_ of your graph (also referred to _tags_).\n\nApollo supports tracking multiple _variants_ for every graph. A variant is just like a regular data graph. It has its own history of schemas, its own metadata store of metrics, and its own operation registry. Variants can be used to track ideas like staging environments, canaries, and deploys of experimental features destined for the production graph.\n\nTo get fully set up associating data sent to Apollo with _variant_ information, you'll need to [configure your CLI commands](#registry-tag) to send data with a `--tag` flag and [configure your Apollo Server](#metrics-tag) with a `schemaTag` option.\n\n<h3 id=\"registry-tag\">Registering schemas to a variant</h3>\n\nTo register your schema to a specific _variant_, simply add the `--tag=<VARIANT>` flag to your push command:\n\n```bash\napollo service:push --tag=beta\n```\n\n> **Note:** All schema pushes without a specified tag are registered under the default graph variant, `current`.\n\n<h3 id=\"metrics-tag\">Associating metrics with a variant</h3>\n\nThere are a few ways to associate metrics reported to [Engine](https://engine.apollographql.com) with a specific variant:\n\n1. The best way to associate metrics with a variant of your graph is to start your server with an environment variable named `ENGINE_SCHEMA_TAG` that contains the name of your variant. This will link metrics sent to Engine with the value of that environment variable.\n1. Alternatively, add the `schemaTag` option to your Apollo Server configuration (works for Apollo Server 2.2+):\n\n```js line=5\nconst server = new ApolloServer({\n  ...\n  engine: {\n    apiKey: \"<ENGINE_API_KEY>\",\n    schemaTag: \"beta\"\n  }\n});\n```\n\n> **Note:** It's important that metrics are associated with the same tag as `service:push` if you want to track isolated data across different variants like production and staging.\n\n<h2 id=\"benefits\">Tools that use the schema registry</h2>\n\nKeeping your schema up-to-date in Apollo's registry will ensure that you get the best experience from Apollo's tools that connect to the registry:\n\n- The [Apollo VS Code extension](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo) provides built-in linting on queries by validating against the schema in your registry. It also annotates fields with their descriptions and with performance indicators collected in Apollo's trace warehouse.\n- The [schema validation](./schema-validation.html) workflow protects your team from accidentally making breaking schema changes. It creates a diff between your local schema and the last schema pushed to the registry, and validates this diff against live traffic seen on your endpoint to warn you about problematic changes.\n- Your schema's full history and current usage can be seen in [Apollo Engine](https://engine.apollographql.com). The History page tracks changes made over time, and the Explorer page shows which clients and which queries are using each field in your schema.\n","path":"/platform/schema-registry","filePath":"docs/source/platform/schema-registry.md"},{"title":"Validating schema changes","description":"Check if schema changes are safe or breaking by comparing against live server traffic","content":"\nThere are many types of schema changes that can be potentially breaking to clients, like removing a field, if made without special consideration. For safety, some organizations take the approach of _never_ making these types of changes, but this leads to an ever-growing schema and reduced API flexibility over time. In reality, making these types of changes to a schema can be very safe as long as you have tools in place to ensure that no queries are broken in the process.\n\nApollo provides a tool to protect for exactly this scenario called **schema validation**.\n\n> **Note:** Schema validation is an Apollo Platform feature available on the [Team and Enterprise plans](https://www.apollographql.com/plans/) of [Apollo Engine](https://engine.apollographql.com).\n\n<h2 id=\"schema-validation\">How it works</h2>\n\nSchema validation is run through the Apollo CLI by executing the `apollo service:check` command. Apollo will generate a diff between your local schema and your most recently registered schema, then validate that the changes are safe by checking if any queries actively running against your graph will be affected.\n\nHere's how it works:\n\n1. You run `apollo service:check` locally or in CI. The proposed schema is sent to Engine's schema registry.\n1. Engine creates a diff between the local schema and the most recently published schema in the registry.\n1. Engine fetches a list of all operations sent to your graph in the last day (time window is [configurable](#cli-advanced)).\n1. Engine walks through the schema diff change-by-change and compares against the operation list to see if the changes will affect the behavior of any operations.\n1. Engine returns the schema diff and indicates any breaking changes found.\n1. The CLI prints the output of this check with a link to view more details in the Engine UI.\n\n<h3 id=\"algorithm\">Breaking change detection</h3>\n\nNot all schema changes are potentially breaking. Some changes, like adding a field, will always be safe and never cause unexpected behavior for active clients. Other changes, like removing a field or changing a return type, can potentially affect the behavior of clients making queries that use those fields. These are what we consider potentially breaking changes.\n\nIf schema validation detects that a proposed schema has a potentially breaking change, the `apollo service:check` command will return a non-0 exit code. Apollo schema validation will detect breaking changes according to the following rules:\n\n#### Removals\n\nEach of these change types removes a schema element. If an element of your graph is being actively used by an operation and it is removed, your GraphQL layer will start returning errors to the dependent operations.\n\n<ul>\n  <li id=\"FIELD_REMOVED\">\n    <code>FIELD_REMOVED</code>: Field used by at least one operation was removed\n  </li>\n  <li id=\"TYPE_REMOVED\">\n    <code>TYPE_REMOVED</code>: Type(scalar, object) used by at least one operation was removed\n  </li>\n  <li id=\"ARG_REMOVED\">\n    <code>ARG_REMOVED</code>: Argument was removed from a field used by at least one operation\n  </li>\n  <li id=\"TYPE_REMOVED_FROM_UNION\">\n    <code>TYPE_REMOVED_FROM_UNION</code>: Type was removed from a union used by at least one operation\n  </li>\n  <li id=\"INPUT_FIELD_REMOVED\">\n    <code>INPUT_FIELD_REMOVED</code>: Field removed from an input type referenced by an argument on a field used by at least one operation\n  </li>\n  <li id=\"VALUE_REMOVED_FROM_ENUM\">\n    <code>VALUE_REMOVED_FROM_ENUM</code>: A value removed from an enum used by at least one operation\n  </li>\n  <li id=\"TYPE_REMOVED_FROM_INTERFACE\">\n    <code>TYPE_REMOVED_FROM_INTERFACE</code>: An object removed from an interface used by at least one operation\n  </li>\n</ul>\n\n#### Required arguments\n\nEach of these changes adds a required input to a schema element. If an operation is actively using an element of your graph and doesn't update itself to add the new required input argument, the GraphQL layer will start returning an error to the operation.\n\n<ul>\n  <li id=\"REQUIRED_ARG_ADDED\">\n    <code>REQUIRED_ARG_ADDED</code>: Non-nullable argument added to field used by at least one operation\n  </li>\n  <li id=\"NON_NULL_INPUT_FIELD_ADDED\">\n    <code>NON_NULL_INPUT_FIELD_ADDED</code>: Non-null field added to an input object used by at least one operation\n  </li>\n</ul>\n\n#### In-place updates\n\nEach of these changes updates an existing schema element. If an operation is activley using an element of your graph and that element is updated, the operation could start receiving an error from the GraphQL layer or, in some cases, an unexpected result.\n\n> **Note:** In some cases, these changes are compatible with the client at runtime, such as a type rename or an object to interface conversion with the same fields. Schema validation still marks these breaking changes because validation does not have enough information to ensure safety and these changes deserve extra scrutiny, such as their impact on type generation.\n\n<ul>\n  <li id=\"FIELD_CHANGED_TYPE\">\n    <code>FIELD_CHANGED_TYPE</code>: Field used by at least one operation changed return type\n  </li>\n  <li id=\"INPUT_FIELD_CHANGED_TYPE\">\n    <code>INPUT_FIELD_CHANGED_TYPE</code>: Field in input object changed type and is referenced by argument on field used by at least one operation\n  </li>\n  <li id=\"TYPE_CHANGED_KIND\">\n    <code>TYPE_CHANGED_KIND</code>: Type used by at least one operation changed, ex: scalar to object or enum to union\n  </li>\n  <li id=\"ARG_CHANGED_TYPE\">\n    <code>ARG_CHANGED_TYPE</code>: Argument changed type on field used by at least one operation\n  </li>\n</ul>\n\n#### Type extensions\n\nThese changes add a type to an existing union or interface in your graph. If an operation is actively using an element of the union or interface, it could receive and unexpected result when updated depending on the fragment spreads requested.\n\n<ul>\n  <li id=\"TYPE_ADDED_TO_UNION\">\n    <code>TYPE_ADDED_TO_UNION</code>: Type added to a union used by at least one operation\n  </li>\n  <li id=\"TYPE_ADDED_TO_INTERFACE\">\n    <code>TYPE_ADDED_TO_INTERFACE</code>: Interface added to an object used by at least one operation\n  </li>\n</ul>\n\n#### Default arguments\n\nThese changes update the default value for an argument. If an operation is using an element of your graph and does not specify a value for this argument, the operation could experience unexpected results when the schema is updated if it was relying on the original default value.\n\n<ul>\n  <li id=\"ARG_DEFAULT_VALUE_CHANGE\">\n    <code>ARG_DEFAULT_VALUE_CHANGE</code>: Default value added or changed for argument on a field used by at least one operation\n  </li>\n</ul>\n\n#### Non-breaking changes\n\nThese are change types detected ny the `apollo service:check` command, but they are \"safe\" and will always be compatible with all exisitng client usage of the graph. They will not affect the behavior of any clients if deployed.\n\n<ul>\n  <li>Optional arguments</li>\n  <ul>\n    <li id=\"OPTIONAL_ARG_ADDED\"><code>OPTIONAL_ARG_ADDED</code> Nullable argument added to a field</li>\n    <li id=\"NULLABLE_FIELD_ADDED_TO_INPUT_OBJECT\"><code>NULLABLE_FIELD_ADDED_TO_INPUT_OBJECT</code> Nullable field added to an input object</li>\n  </ul>\n  <li>Additions</li>\n  <ul>\n    <li id=\"FIELD_ADDED\"><code>FIELD_ADDED</code> Field added to a type</li>\n    <li id=\"TYPE_ADDED\"><code>TYPE_ADDED</code> Type added to the schema</li>\n    <li id=\"VALUE_ADDED_TO_ENUM\"><code>VALUE_ADDED_TO_ENUM</code> Value added to an enum. If clients contain a switch case on the enum and do not include the `default`, this change could cause unexpected behavior</li>\n  </ul>\n  <li>Deprecations</li>\n  <ul>\n    <li id=\"FIELD_DEPRECATED\"><code>FIELD_DEPRECATED</code> Field deprecated</li>\n    <li id=\"FIELD_DEPRECATION_REMOVED\"><code>FIELD_DEPRECATION_REMOVED</code> Field no longer deprecated</li>\n    <li id=\"FIELD_DEPRECATED_REASON_CHANGE\"><code>FIELD_DEPRECATED_REASON_CHANGE</code> Reason for deprecation changed</li>\n    <li id=\"ENUM_DEPRECATED\"><code>ENUM_DEPRECATED</code> Enum deprecated</li>\n    <li id=\"ENUM_DEPRECATION_REMOVED\"><code>ENUM_DEPRECATION_REMOVED</code> Enum no longer deprecated</li>\n    <li id=\"ENUM_DEPRECATED_REASON_CHANGE\"><code>ENUM_DEPRECATED_REASON_CHANGE</code> Reason for enum deprecation changed</li>\n  </ul>\n</ul>\n\n### Validation response\n\nRunning a schema validation check is as simple as running `apollo service:check` on the command line from within a service repository\nthat is configured to be an Apollo project.\n\nRunning `apollo service:check` will output the diff of all schema changes found and highlight changes determined to be breaking. Here's an example:\n\n```console\n$ npx apollo service:check --tag=prod\n  ✔ Loading Apollo Project\n  ✔ Validated local schema against tag prod on service engine\n  ✔ Compared 8 schema changes against 110 operations over the last 24 hours\n  ✖ Found 3 breaking changes and 5 compatible changes\n    → breaking changes found\n\nFAIL    ARG_REMOVED                `ServiceMutation.checkSchema` arg `gitContext` was removed\nFAIL    FIELD_REMOVED              `Schema.fieldCount` was removed\nFAIL    FIELD_REMOVED              `Schema.typeCount` was removed\n\nPASS    FIELD_ADDED                `SchemaTag.schemaRepoID` was added\nPASS    FIELD_CHANGED_TYPE         `ServiceMutation.uploadPartialSchema` changed type from `UploadPartialSchemaResponse!` to `CompositionResult!`\nPASS    FIELD_DEPRECATION_REMOVED  `IntrospectionSchema.fieldCount` is no longer deprecated\nPASS    FIELD_DEPRECATION_REMOVED  `IntrospectionSchema.typeCount` is no longer deprecated\nPASS    TYPE_REMOVED               `UploadPartialSchemaResponse` removed\n\nView full details at: https://engine.apollographql.com/service/example-1234/check/<DETAILS>\n```\n\nEach change to the schema will be labeled with `PASS` or `FAIL` and a URL with full details on the changes and their impact on clients and operations will be generated. Following the URL will take you to Engine:\n\n<img src=\"../img/schema-validation/service-check-page.png\" width=\"100%\" alt=\"Service check page in the Engine UI\">\n\n> **Note:** If you have [installed schema validation checks on your GitHub PRs](#github), the \"Details\" link in your GitHub checks will take you to the same details link in this output.\n\nA failed `apollo service:check` command will exit with a non-0 exit code and fail CI checks. There are many cases where it is safe to make a potentially breaking change, as long as the change is made intentionally with an understanding of its impact.\n\nSince breaking changes are detected using live traffic, your service will _need active metrics_ for the change algorithm to detect failures. If there are no metrics associated with your service, _all changes will be labeled as a `PASS` as opposed to a `FAIL`_.\n\n<h2 id=\"setup\">Set up schema validation</h2>\n\nTo set up schema validation, you wlil need to be both actively sending traces and registering schemas to Apollo:\n\n1. [Set up trace reporting to Apollo Engine](/docs/references/setup-analytics)\n1. [Set up schema registration in your continuous delivery pipeline](/docs/platform/schema-registry.html)\n\nThen, you will need to configure your project for the `apollo service:check` command:\n\n1. [Set up a `.env` file with your `ENGINE_API_KEY`](/docs/platform/schema-registry.html#Get-your-Engine-API-key)\n1. [Set up an `apollo.config.js` file with a `service` configured](/docs/platform/schema-registry.html#Create-an-apollo-config-js-file)\n\n> **Note:** If you have set up one of Apollo's workflows previously, your project may already have its `.env` file and `apollo.config.js` file configured.\n\nOnce you've got these set up, running your schema check is as simple as running:\n\n```console\n$ npm install apollo\n$ npx apollo service:check\n```\n\nThe command can be placed in any continuous integration pipeline. To surface results, `apollo` emits an exit code and [integrates with GitHub statuses](#github). The time window of live traffic that the check command validates against can be [configured](#cli-advanced) to any range within your data retention window.\n\n> **Note:** The Apollo CLI will be looking in your Apollo config for a location from which to fetch your local schema and using your ENGINE_API_KEY to authenticate its requests with the Engine service.\n\n<h3 id=\"service-check-on-ci\">Run validation on each commit</h3>\n\nWe highly recommended that you add validation to your continuous integration workflow (e.g. Jenkins, CircleCI, etc.). In doing so, you can detect potential problems automatically and display the results of checks directly on pull requests.\n\nHere's a example of how to add a schema validation check to CircleCI:\n\n```yaml line=29\nversion: 2\n\njobs:\n  build:\n    docker:\n      - image: circleci/node:8\n\n    steps:\n      - checkout\n\n      - run: npm install\n\n      # Start the GraphQL server.  If a different command is used to\n      # start the server, use it in place of `npm start` here.\n      - run:\n          name: Starting server\n          command: npm start\n          background: true\n\n      # make sure the server has enough time to start up before running\n      # commands against it\n      - run: sleep 5\n\n      # This will authenticate using the `ENGINE_API_KEY` environment\n      # variable. Configure your endpoint's location in your Apollo config.\n      - run: npx apollo service:check\n```\n\n> **Note:** If you're using GitHub status checks, we recommend ignoring the exit code of the `apollo service:check` command so your continuous integration can complete without failing early. This can be done by appending `|| echo 'validation failed'` to the command call.\n\n<h3 id=\"github\">GitHub integration</h3>\n\n<div style=\"text-align:center\">\n\n![GitHub Status View](../img/schema-validation/github-check.png)\n\n</div>\n\nLike most tools, schema validation is best used when it is integrated directly into the rest of your workflow. If you're using GitHub, you can install the Apollo Engine GitHub app. This will enable Apollo's systems to send a webhook back to your project on each `apollo service:check`, providing built-in pass/fail status checks on your pull requests.\n\nTo install the Apollo Engine integration on GitHub, go to [https://github.com/apps/apollo-engine](https://github.com/apps/apollo-engine), click the `Configure` button, and select the appropriate GitHub profile or organization.\n\n### Posting a comment to your PRs\n\nFor teams using GitHub Enterprise, Bitbucket, and other source control tools, we recommend setting up your CI to post a comment on your PRs with the results of schema validation. Surfacing schema diffs and breaking changes directly in your PR will speed up your review workflow by saving you the time of searching your CI logs to check why validation didn't pass.\n\nThe CLI supports passing a `--markdown` flag to `apollo service:check`, which outputs the results of schema validation in a markdown format specifically. This markdown can be piped directly into a comment to your source control tool, like in [this example of posting a comment with the results of schema validation to GitHub](https://gist.github.com/daniman/e53d0589d18b778878bd8ef32d2e793c).\n\nThe output of `apollo service:check --markdown` looks like this:\n\n```md\n### Apollo Service Check\n\n🔄 Validated your local schema against schema tag `staging` on service `engine`.\n🔢 Compared **18 schema changes** against **100 operations** seen over the **last 24 hours**.\n❌ Found **7 breaking changes** that would affect **3 operations** across **2 clients**\n\n🔗 [View your service check details](https://engine.apollographql.com/service/engine/checks?...).\n```\n\n<h3 id=\"multiple-environments\">Multiple environments</h3>\n\nProduct cycles move fast and it's common for schemas to be slightly different across environments as changes make their way through your system. To support this, schemas pushed to the registry can be associated with specific _variants_ of your graph (also referred to tags).\n\nVariants mostly commonly represent environments and can also indicate branches or future schemas. Passing the `--tag=<VARIANT>` flag to `apollo service:check` specifies which schema variant to compara against, such as `prod` or `staging`. It's common to run checks against multple different graph variants in the same continuous integration pipeline to ensure that all important deployments are accounted for. Running `service:check` against multiple variants will result in status checks similar to:\n\n<div style=\"text-align:center\">\n\n![multiple service checks](../img/schema-validation/multi-github-check.png)\n\n</div>\n\n<h2 id=\"cli-advanced\">Adjusting validation parameters</h2>\n\nDepending on the requirements of your application, you may want to configure the timeframe to validate operations against. You can do so by providing a `validationPeriod` flag to the CLI. The timeframe will always end at \"now\", and go back in time by the amount specified.\n\n```bash\napollo service:check --validationPeriod=P2W\n```\n\n> **Note:** Valid durations are represented in [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601#Durations). It can also be provided as a number in seconds, i.e. 86400 for a single day.\n\nTwo other parameters for customizing the results of `service:check` are threshold values. For example, you may wish to drop support for an old version of an app in order to remove some deprecated fields. Using these parameters, you can decide what amount of breakage is acceptable before shipping any breaking changes.\n\n- `queryCountThreshold` - This flag will only validate the schema against operations that have been executed at least the specified number of times within the provided duration.\n- `queryCountThresholdPercentage` - Similar to `queryCountThreshold`, but expressed as a percentage of all operation volume.\n\n> **Note:** these flags are compatible with each other. In the case that both are provided, an operation must meet or exceed both thresholds.\n\nHere's an example of how to run a `service:check` with custom thresholds set:\n\n```bash\nnpx apollo service:check \\\n# Validate the schema against operations that have run in the last 5 days\n--validationPeriod=P5D \\\n# Only validate against operations that have run at least 5 times during the 5 day duration\n--queryCountThreshold=5 \\\n# Only validate against operations that account for at least 3% of total operation volume\n--queryCountThresholdPercentage=3\n```\n\nIf you have any requests for other filtering or threshold mechanisms, please get in touch with us on the [apollo-tooling](https://github.com/apollographql/apollo-tooling/) repository.\n","path":"/platform/schema-validation","filePath":"docs/source/platform/schema-validation.md"},{"title":"Identifying clients","description":"Know who is using your graph and what exactly they're using","content":"\nUsing GraphQL, clients describe exactly the data they want through the fields they put in their requests. This gives us the ability to precisely connect which clients, and which queries from those clients, are using exactly which fields in our schema &mdash; an insight that's immensely valuable as GraphQL development scales within an organization.\n\nApollo provides a client identification and tracking system, which allows you to answer questions like _\"which query is using this field?\"_ and _\"which versions of my iOS app are running this query?\"_. It segments usage data by **client name and version** and allows for **field-level understanding** of how consumers are interacting with your graph in real-time.\n\nLike any API, your graph will end up with many consumers with different frequencies, subselections, and permissions as it grows over time. Apollo allows all reported data to be tagged with client information so it can be filtered and analyzed across different sets of clients and stacks.\n\nHere's an example of client identity reporting in Engine:\n\n![client overview](../img/client-awareness/overview.png)\n\n## Setup\n\nApollo Server 2.2.3+ will look for specific the request headers, `apollographql-client-name` and `apollographql-client-version`, by default. If present, Apollo Server will extract them and make sure the data for that request is reported to Apollo's systems with the correct client and version tag.\n\nWith Apollo Client 2.4.6+, simply passing the `name` and `version` options in your `ApolloClient` constructor will automatically add these headers to every request. Setting up client identity reporting is as simple as adding configuration to Apollo Client:\n\n```js line=8-9\nimport { ApolloClient } from 'apollo-client';\nimport { HttpLink } from 'apollo-link-http';\n\nconst client = new ApolloClient({\n  link: new HttpLink({\n    uri: 'http://localhost:4000/graphql'\n  }),\n  name: 'insert your client name',\n  version: 'insert your client version'\n});\n```\n\nIf you are not using Apollo Server and would like to gain client awareness,\nplease reach out to opensource [at] apollographql.com to work with us to add\nsupport to your server language of choice.\n\n## Use Cases\n\n### Isolating Clients\n\nFiltering queries by client enables isolation of issues that affect a portion\nof all clients. In the opposite sense, if a client becomes problematic, such as\nrequesting expensive fields or using deprecated fields, the Apollo Platform\nenables tracking down the faulty client to start solving the issue with the\nowner. When changing, replacing, or deprecating a field in the API, the client\nmetadata enables quickly identifying the client-side changes that need to\noccur to completely remove the field.\n\n![client field](../img/client-awareness/field-usage.png)\n\n### Cutover\n\nSimilarly to deprecation, adding fields to your graph often means that clients will also change. These modifications can be done incrementally or discretely during a cutover period. The cutover period and time immediately following change the utilization of the graph drastically and can expose some unexpected behavior. Filtering by client version enables monitoring the health of a release in real-time. The following demonstrates a cutover from one backend to another.\n\n![druid cutover](../img/client-awareness/cutover.png)\n\n## Advanced setup\n\n### Client\n\nThe requester is responsible for setting HTTP headers on its requests in a way the server will understand. As noted in \"setup\", Apollo Client and Server will handle this automatically. For advanced cases, rather than setting the `name` and `version` on `ApolloClient`, `headers` can be set on the `HttpLink` directly.\n\n```js line=8-16\nimport { ApolloClient } from 'apollo-client';\nimport { HttpLink } from 'apollo-link-http';\nimport { ApolloLink } from 'apollo-link';\n\nconst client = new ApolloClient({\n  link: new HttpLink({\n    uri: 'http://localhost:4000/graphql',\n    headers: {\n      'client-name-for-advanced-use-cases': 'Web',\n      'client-version-for-advanced-use-cases': '1'\n    }\n  })\n});\n```\n\n### Server\n\nThe server is responsible for collecting and assigning the client information\nto a request. To send client-tagged metrics to Apollo, pass a\n`generateClientInfo` function into the `ApolloServer` constructor. The\nfollowing example checks the headers and provides a fallback:\n\n```js line=8-22\nconst { ApolloServer } = require('apollo-server');\n\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  engine: {\n    apiKey: 'YOUR API KEY HERE',\n    generateClientInfo: ({ request }) => {\n      // The default approach suggested in \"Setup\", which\n      // uses headers provided by Apollo Client, should work\n      // for most use cases, but advanced cases can use\n      // their own logic for determining the client name\n      // and version and return them from this function.\n      const { clientName, clientVersion } = userSuppliedLogic(request);\n      return {\n        clientName,\n        clientVersion\n      };\n    }\n  }\n});\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀  Server ready at ${url}`);\n});\n```\n","path":"/platform/client-awareness","filePath":"docs/source/platform/client-awareness.md"},{"title":"Operation registry","description":"How to secure your graph with operation safelisting","content":"\n## Overview\n\n> The operation registry is an Apollo Platform feature available on the [_Team_ and _Enterprise_ plans](https://www.apollographql.com/plans/). To get started with the Apollo Platform, begin with [the documentation](https://www.apollographql.com/docs/).\n\nAny API requires security and confidence prior to going to production. During development, GraphQL offers front-end engineers the ability to explore all the data available to them and fetch exactly what they need for the components they're building. However, in production, it can be unnecessary and undesirable to provide this flexibility.\n\nThe Apollo Operation Registry allows organizations to:\n\n- Provide demand control for their production GraphQL APIs.\n- Permit the exact operations necessary for their client applications.\n- Eliminate the risk of unexpected, and possibly costly, operations being executed against their graph.\n\nOperations defined within client applications are automatically extracted and uploaded to Apollo Engine using the Apollo CLI. Apollo Server fetches a manifest of these operations from Apollo Engine and forbids execution of operations which were not registered from the client bundle.\n\n## Getting started\n\n### Prerequisites\n\n- Apollo Server 2.2.x (or newer).\n  - To get started with Apollo Server, visit [its documentation](/docs/apollo-server/).\n- A client application which utilizes `gql` tagged template literals for its operations or, alternatively, stores operations in `.graphql` files.\n- An Apollo Engine API key.\n  - To obtain an API key, visit [Apollo Engine](https://engine.apollographql.com) and create a service.\n\n### Limitations\n\n- Subscriptions within Apollo Server should be disabled. For more information, see the instructions below.\n- Only the default schema tag (`current`) is supported.\n\n  To use the operation registry with schema tags, the schema which necessitates demand control should also be registered to the default (`current`) tag for the same service. For example, if a service is using a `prod` schema tag and publishing the schema with `apollo service:push --tag=prod`, the same schema should also be pushed to the default tag with `apollo service:push --tag=current`.\n\nPlease contact the Apollo sales team if you require a solution to any of these limitations.\n\n### Installation steps\n\n> Make sure you've met the requirements for _Prerequisites_ above and understand the current _Limitations_.\n\nThese installation steps require access to both the client and server codebases to perform the following tasks:\n\n- The `apollo` CLI is used to search the client codebase for GraphQL operations and upload them to Apollo Engine.\n- Apollo Server is then configured with a plugin which fetches the manifest from Apollo Server and enforces safe-listing using that manifest.\n\nThe following steps will walk through the steps necessary for both the client and server codebases.\n\n**1. Install the `apollo` command line tool as a development dependency of your client application:**\n\n```\nnpm install apollo --save-dev\n```\n\n> Yarn users should run `yarn add apollo --dev`.\n\n**2. Push your schema to the Apollo schema registry:**\n\n> If this server's schema has already been registered using `apollo service:push`, you can skip this step. For additional options and details, see the [documentation for the schema registry](./schema-registry.html).\n\nFirst, make sure Apollo Server is running and that introspection is enabled (it is often disabled in production).\n\nNext, using the following command as a reference, replace the `<ENGINE_API_KEY>` with the Apollo Engine API key from the appropriate service and specify the correct server endpoint with the `--endpoint` flag:\n\n```\nnpx apollo service:push               \\\n    --key <ENGINE_API_KEY>            \\\n    --endpoint https://server/graphql\n```\n\nWhen successful, this command should return output similar to the following:\n\n```\n✔ Loading Apollo config\n✔ Fetching current schema\n✔ Publishing <service> to Apollo Engine\n\nid      schema        tag\n------  ------------- -------\nabc123  <service>     current\n```\n\n> If you encounter any errors, refer to the _**Troubleshooting**_ section below.\n\n**3. Register operations from the client bundle.**\n\nNow we'll use `apollo client:push` to locate operations within the client codebase and upload a manifest of those operations to Apollo operation registry. Once Apollo Server has been configured to respect the operation registry, only operations which have been included in the manifest will be permitted.\n\nThe `apollo client:push` command:\n\n- Supports multiple client bundles. Each bundle is identified by a `clientName` (e.g. `react-web`) and `clientVersion`.\n- Supports JavaScript, TypeScript and `.graphql` files.\n- Accepts a list of files as a glob (e.g. `src/**/*.ts`) to search for GraphQL operations.\n- By default, includes the `__typename` fields which are added by Apollo Client at runtime.\n\nTo register operations, use the following command as a reference, taking care to replace the `<ENGINE_API_KEY>` with the appropriate Apollo Engine API key, specifying a unique name for this application with `<CLIENT_IDENTIFIER>`, and indicating the correct glob of files to search:\n\n```\nnpx apollo client:push \\\n    --key <ENGINE_API_KEY> \\\n    --clientName <CLIENT_IDENTIFIER> \\\n    --clientVersion <CLIENT_VERSION> \\\n    --includes=\"src/**/*.{ts,js,graphql}\"\n```\n\n> _Note:_ Operations that are stored in the registry are legal for _all_ clients. The client name and client version are collected as metadata to make debugging easier and provide more insights.\n\nWhen succesfull, the output from this command should look similar to the following:\n\n```\n✔ Loading Apollo project\n✔ Pushing client to Engine service <service>\n```\n\nCurrently, once an operation is registered it will remain registered indefinitely. For production operation registration, it's recommended that operations be registered from a deployment pipeline step rather than manually.\n\nIf you encounter any errors, check the _**Troubleshooting**_ section below.\n\n**4. Disable subscription support on Apollo Server**\n\nSubscription support is enabled by default in Apollo Server 2.x and provided by a separate server which does not utilize Apollo Server 2.x's primary request pipeline. Therefore, the operation registry plugin (and any plugin) is unable to be invoked during a request which comes into the subscription server and enforcement of operation safelisting is not possible. **For proper enforcement of operation safelisting, subscriptions should be disabled.**\n\nIn the future, the subscription support will have its request pipeline unified with that of the main request pipeline, thus enabling plugin support and permitting the the operation registry to work with subscriptions in the same way that it works with regular GraphQL requests.\n\nTo disable subscriptions support on Apollo Server 2.x, a `subscriptions: false` setting should be included on the instantiation of Apollo Server, as follows:\n\n```js line=5-6\nconst server = new ApolloServer({\n  // Existing configuration\n  typeDefs,\n  resolvers,\n  // Ensure that subscriptions are disabled.\n  subscriptions: false\n  // ...\n});\n```\n\n**5. Enable demand control by adding the operation registry to Apollo Server.**\n\nTo enable the operation registry within Apollo Server, it's necessary to install and enable the `apollo-server-plugin-operation-registry` plugin and ensure Apollo Server is configured to communicate with Apollo Engine.\n\nFirst, add the appropriate plugin to the Apollo Server's `package.json`:\n\n```\nnpm install apollo-server-plugin-operation-registry\n```\n\n> Yarn users should run: `yarn add apollo-server-plugin-operation-registry`.\n\nNext, the plugin must be enabled. This requires adding the appropriate module to the `plugins` parameter to the Apollo Server options:\n\n```js line=8-12\nconst server = new ApolloServer({\n  // Existing configuration\n  typeDefs,\n  resolvers,\n  subscriptions: false,\n  // ...\n  // New configuration\n  plugins: [\n    require('apollo-server-plugin-operation-registry')({\n      forbidUnregisteredOperations: true\n    })\n  ]\n});\n```\n\n**6. Start Apollo Server with Apollo Engine enabled**\n\nIf the server was already configured to use Apollo Engine, no additional changes are necessary, but it's important to make sure that the server is configured to use the same service as the operations were registered with in step 3.\n\nIf the server was not previously configured with Apollo Engine, be sure to start the server with the `ENGINE_API_KEY` variable set to the appropriate API key. For example:\n\n```\nENGINE_API_KEY=<ENGINE_API_KEY> npm start\n```\n\nAlternatively, the API key can be specified with the `engine` parameter on the Apollo Server constructor options:\n\n```js line=3\nconst server = new ApolloServer({\n  // ...\n  engine: '<ENGINE_API_KEY>'\n  // ...\n});\n```\n\nFor security, it's recommended to pass the Engine API key as an environment variable so it will not be checked into version control (VCS).\n\n**7. Verification**\n\nWith the operation registry enabled, _only_ operations which have been registered will be permitted.\n\nTo confirm that everything is configured properly, try executing an operation against the server which was **not** registered from the client bundle in step 3.\n\nFor example, using `curl` this could be done with a command similar to:\n\n```\ncurl 'http://server/graphql/' \\\n    -H 'Content-Type: application/json' \\\n    --data-binary '{\"query\":\"query { likes{title} }\"}'\n```\n\nIf the server is configured properly, it should return:\n\n```\nExecution forbidden\n```\n\nFinally, to confirm that the server will allow permitted operations, try running an operation from the client.\n\n## Configuration\n\n### Selective enforcement\n\nIn some cases, deployments may want to selectively enable the behavior of `forbidUnregisteredOperations` depending on environmental conditions (e.g. based on headers).\n\nTo selectively enable operation safe-listing, the `forbidUnregisteredOperations` setting supports a [predicate function](https://en.wikipedia.org/wiki/Predicate_(mathematical_logic) which receives the request context and can return `true` or `false` to indicate whether enforcement is enabled or disabled respectively.\n\n> In the example below, the `context` is the shared request context which can be modified per-request by plugins or using the [`context`](https://www.apollographql.com/docs/apollo-server/api/apollo-server.html#constructor-options-lt-ApolloServer-gt) function on the `ApolloServer` constructor. The `headers` are the HTTP headers of the request which are accessed in the same way as the [Fetch API `Headers` interface](https://developer.mozilla.org/en-US/docs/Web/API/Headers) (e.g. `get(...)`, `has(...)`, etc.).\n\nFor example, to enforce the operation registry safe-listing while skipping enforcement for any request in which the `Let-me-pass` header was present with a value of `Pretty please?`, the following configuration could be used:\n\n```js line=12-27\nconst server = new ApolloServer({\n  // Existing configuration\n  typeDefs,\n  resolvers,\n  subscriptions: false,\n  engine: '<ENGINE_API_KEY>',\n  plugins: [\n    require('apollo-server-plugin-operation-registry')({\n      // De-structure the object to get the HTTP `headers` and the GraphQL\n      // request `context`.  Additional validation is possible, but this\n      // function must be synchronous.  For more details, see the note below.\n      forbidUnregisteredOperations({\n        context, // Destructure the shared request `context`.\n        request: {\n          http: { headers } // Destructure the `headers` class.\n        }\n      }) {\n        // If a magic header is in place, allow any unregistered operation.\n        if (headers.get('Let-me-pass') === 'Pretty please?') {\n          return false;\n        }\n\n        // Enforce operation safe-listing on all other users.\n        return true;\n      }\n    })\n  ]\n});\n```\n\n> _Note:_ The `forbidUnregisteredOperations` callback must be synchronous. If it is necessary to make an `async` request (e.g. a database inquiry) to make a determination about access, such a lookup should occur within the [`context` function](https://www.apollographql.com/docs/apollo-server/api/apollo-server.html#constructor-options-lt-ApolloServer-gt) on the `ApolloServer` constructor (or any life-cycle event which has access to `context`) and the result will be available on the `context` of `forbidUnregisteredOperations`.\n\n## Testing the plugin\n\nWe recommend testing the behavior of the plugin, as well as your `forbidUnregisteredOperations` function, before actually forbidding operation execution in production. To do so, you can use the `dryRun` option, which will log information about the operation in lieu of actually forbidding anything.\n\n```js line=7\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  plugins: [\n    require(\"apollo-server-plugin-operation-registry\")({\n      forbidUnregisteredOperations: true,\n      dryRun: true\n    });\n  ],\n});\n```\n\n## Troubleshooting\n\n#### The server indicates `Access denied.` (or `AccessDenied`) when fetching the manifest\n\nWhen the server cannot fetch the manifest, the message may indicate indicate that access is denied:\n\n```xml\nCould not fetch manifest\n<?xml version='1.0' encoding='UTF-8'?>\n<Error>\n   <Code>AccessDenied</Code>\n   <Message>Access denied.</Message>\n   <Details>Anonymous caller does not have storage.objects.get access (...snipped...)</Details>\n</Error>\n```\n\nThis can occur if the schema hasn't been published since the operation registry plugin was enabled. You can publish the schema using the `apollo service:push` command. When receiving this message on a service which has already had its schema pushed, the `apollo client:push` command can be used. Check the above documentation for more information on how to use those commands.\n\n#### Operations aren't being forbidden or operations which should be permitted are not allowed\n\nThe first step in debugging the operation registry behavior is to enable debugging. This can be done by enabling the `debug` setting on the plugin within the Apollo Server constructor options:\n\n```js line=7\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  plugins: [\n    require(\"apollo-server-plugin-operation-registry\")({\n      // ... other, existing options ...\n      debug: true,\n    });\n  ],\n});\n```\n\nWhen the server is started with debugging enabled, additional information will be displayed at server startup which can be useful in determining the source of the problem. For example:\n\n```\nChecking for manifest changes at https://...\n🚀 app running at http://localhost:4000/\nIncoming manifest ADDs: ba4573fca2e1491fd54b9f3984...\nIncoming manifest ADDs: 32a21510374c3c9ad25e064240...\nIncoming manifest ADDs: c60ac6dfe19ba70dd9d6a29a27...\n```\n\nBy clicking on the URL listed in the `Checking for manifest changes at` message, it will be possible to see the full contents of the manifest and see the list of permitted operations. This information is not publicly available and this URL should not be shared.\n\n#### Schema registration\n\nIf a problem occurs during the `apollo service:push` command, make sure that the running Apollo Server can be accessed from the machine where the command is being executed.\n\nAdditionally, make sure that introspection is enabled on the server since introspection details are used to obtain and publish the schema.\n","path":"/platform/operation-registry","filePath":"docs/source/platform/operation-registry.md"},{"title":"Connecting Apollo to your editor","description":"How to get the most out of your editor with Apollo","content":"\nGraphQL has the potential to create incredible developer experiences, thanks to its strongly typed schema and query language. The Apollo platform brings these possibilities to life by enhancing your editor with rich metadata from your graph API. Currently only [Visual Studio Code](https://code.visualstudio.com/) (VS Code) is supported, but more are coming soon.\n\n<img src=\"../images/editors/jump-to-def.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"Using jump to definition on a fragment\">\n\n<h2 id=\"vscode\">Apollo VS Code</h2>\n\nThe [VS Code extension](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo) for Apollo brings an all-in-one tooling experience for developing apps with Apollo.\n\n- Add [syntax highlighting](#syntax) for GraphQL files and gql templates inside JavaScript files\n- Get instant feedback and [intelligent autocomplete](#autocomplete) for fields, arguments, types, and variables as you write queries\n- Manage client side schema alongside remote schema\n- See [performance information](#performance-insights) inline with your query definitions\n- Validate field and argument usage in operations\n- [Navigate projects more easily](#navigating-projects) with jump-to and peek-at definitions\n- Manage [client-only](#client-only-schemas) schemas\n- [Switch schema tags](#commands) to work with schemas running on different environments\n\n<h2 id=\"getting-started\">Getting started</h2>\n\nTo get all of the benefits of the VS Code experience, it's best to link the schema that is being developed against **before** installing the extension. The best way to do that is by [publishing a schema](./schema-registry.html#publish) to the Apollo schema registry. Once that is done, two steps are needed:\n\n1. Create an `apollo.config.js` at the root of the project\n2. Copy an API key from the Engine dashboard of the published service\n\n<h3 id=\"apollo-config\">Setting up an Apollo config</h3>\n\nIn order for the VS Code plugin to know how to find the schema, it needs to be linked to either a published schema or a local one. To link a project to a published schema, edit the `apollo.config.js` file to look like this:\n\n```js\nmodule.exports = {\n  client: {\n    service: 'my-graphql-app'\n  }\n};\n```\n\nThe `service` name here is the ID of the graph you've created in [Engine](https://engine.apollographql.com).\n\n> **Note:** The ID of your graph can be found in its URL in Engine. We use the ID so you can change your graph's name freely without having to update this. This will be easier to manage in the future.\n\n<h3 id=\"api-key\">Setting up an API key</h3>\n\nTo authenticate with Engine to pull down the schema, create a file next to the `apollo.config.js` called `.env`. This should be an untraced file (i.e. don't push it to GitHub). Go to the settings page of your graph in Engine to get the API key.\n\n> **Note:** It is best practice to create a new API key for each member of the team and name the key so its easy to find and revoke if needed. This will be easier to manage in the future.\n\nAfter the key is found, add the following line to the `.env` file:\n\n```bash\nENGINE_API_KEY=<enter copied key here>\n```\n\nAfter this is done, VS Code can be reloaded and the Apollo integration will connect to Engine to provide autocomplete, validation, and more.\n\n<h3 id=\"local-schemas\">Local schemas</h3>\n\nSometimes it may make sense to link the editor to a locally running version of a schema to try out new designs that are in active development. To do this, the `apollo.config.js` file can be linked to a local service definition:\n\n```js\nmodule.exports = {\n  client: {\n    service: {\n      name: 'my-graphql-app',\n      url: 'http://localhost:4000/graphql'\n    }\n  }\n};\n```\n\nLinking to the local schema won't provide all features such as switching schema tags and performance metrics. See [the Apollo config docs](https://www.apollographql.com/docs/references/apollo-config) for more details on configuration options.\n\n<h3 id=\"client-only-schemas\">Client-only schemas</h3>\n\nOne of the best features of the VS Code extension is the automatic merging of remote schemas and local ones when using integrated state management with Apollo Client. This happens automatically whenever schema definitions are found within a client project. By default, the VS Code extension will look for all files under `./src` to find both the operations and schema definitions for building a complete schema for the application.\n\nClient side schema definitions can be spread throughout the client app project and will be merged together to create one single schema. The default behavior can be controlled by adding specifictions to the `apollo.config.js`:\n\n```js\nmodule.exports = {\n  client: {\n    service: \"my-graphql-app\"\n    includes: [\"./src/**/*.js\"],\n    excludes: [\"**/__tests__/**\"]\n  }\n}\n```\n\n<h3 id=\"get-the-extension\">Get the extension</h3>\n\nOnce you have a config set up and a schema published, [install the Apollo GraphQL extension](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo), then try opening a file containing a GraphQL operation.\n\nWhen a file open, clicking the status bar icon will open the output window and print stats about the project associated with that file. This is helpful when confirming the project is setup properly.\n\n<img src=\"../images/editors/stats.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"Clicking the status bar icon to open the output pane\">\n\n<h2 id=\"features\">Features</h2>\n\nApollo for VS Code brings many helpful features for working on a GraphQL project.\n\n<h3 id=\"autocomplete\">Intelligent autocomplete</h3>\n\nOnce configured, editors have full knowledge of the schema clients are running operations against, including client-only schemas (for things like local state mutations). Because of this, editors have the ability to autocomplete fields and arguments as you type.\n\n<img src=\"../images/editors/autocomplete.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"vscode completing a field when typing\">\n\n<h3 id=\"errors-and-warnings\">Inline errors and warnings</h3>\n\nEditors can use local or published schemas to validate operations before running them. **Syntax errors**, **invalid fields or arguments**, and even **deprecated fields** instantly appear as errors or warnings right in your editor, ensuring all developers are working with the most up-to-date production schemas.\n\n<img src=\"../images/editors/warnings-and-errors.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"tooltip showing a field deprecation warning and error\">\n\n<h3 id=\"field-type-info\">Inline field type information</h3>\n\nBecause of GraphQL's strongly-typed schema, editors not only know about which fields and arguments are valid, but also what types are expected. Hover over any type in a valid GraphQL operation to see what type that field returns and whether or not it can be null.\n\n<img src=\"../images/editors/type-info.png\" width=\"80%\" style=\"margin: 5%\" alt=\"a tooltip showing a Boolean type for a field\">\n\n<h3 id=\"performance-insights\">Performance insights</h3>\n\nGraphQL's flexibility can make it difficult to predict the cost of an operation. Without insight into how expensive an operation is, developers can accidentally write queries that place strain on their graph API's underlying backends. Thanks to the Apollo platform's integration with VS Code and our trace warehouse, teams can avoid these performance issues altogether by instantly seeing the cost of a query right in their editor.\n\nTo turn on tracing for your GraphQL server, please visit our [guide](./setup-analytics.html).\n\nThe VS Code extension will show inline performance diagnostics when connected to a service with reported metrics in Engine. As operations are typed, any fields that take longer than 1ms to respond will be annoated to the right of the field inline! This gives team members a picture of how long the operation will take as more and more fields are added to operations or fragments.\n\n<img src=\"../images/editors/perf-annotation.png\" width=\"80%\" style=\"margin: 5%\" alt=\"Performance annotation next to a field\">\n\n<h3 id=\"syntax\">Syntax highlighting</h3>\n\nApollo's editor extension provides syntax highlighting for all things GraphQL, including schema definitions in `.graphql` files, complex queries in TypeScript, and even client-only schema extensions. Syntax highlighting for GraphQL works out-of-the-box for `.graphql`, `.gql`, `.js` and `.ts` file types.\n\n<h3 id=\"navigating-projects\">Navigating projects</h3>\n\nNavigating large codebases can be difficult, but the Apollo GraphQL extension makes this easier. Right-clicking on any field in operations or schemas gives you the ability to jump to (or peek at) definitions, as well as find any other references to that field in your project.\n\n<img src=\"../images/editors/jump-to-def.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"Using jump to definition on a fragment\">\n\n<h3 id=\"commands\">Schema variant switching</h3>\n\nApollo supports publishing multiple versions ([variants](http://localhost:8000/platform/schema-registry#schema-tags)) of a schema. This is useful for developing on a future development schema and preparing your clients to conform to that schema. To switch between schema variants, open the Command Palette (`cmd + shift + p` on mac), search \"Apollo\" and choose the \"Apollo: Select Schema Tag\" option.\n\n<h2 id=\"troubleshooting\">Troubleshooting</h2>\n\nThe most common errors are configuration errors, like a missing `.env` file or incorrect service information in the `apollo.config.js` file. Please see [the Apollo config docs](https://www.apollographql.com/docs/references/apollo-config) for more configuration guidance.\n\nOther errors may be caused from an old version of a published schema. To reload a schema, open the Command Palette (`cmd + shift + p` on mac), search \"Apollo\" and choose the \"Apollo: Reload Schema\" option.\n\nSometimes errors will show up as a notification at the bottom of your editor. Other, less critical, messages may be shown in the output pane of the editor. To open the output pane and get diagnostic information about the extension and the current service loaded (if working with a client project), just click the \"Apollo GraphQL\" icon in the status bar at the bottom.\n\n<img src=\"../images/editors/stats.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"Clicking the status bar icon to open the output pane\">\n\nIf problems persist or the error messages are unhelpful, an [issue](https://github.com/apollographql/apollo-tooling/issues) can be opened on the `apollo-tooling` repository.\n","path":"/platform/editor-plugins","filePath":"docs/source/platform/editor-plugins.md"},{"title":"Analyzing performance","description":"Tracking your graph's performance at the field level","content":"\nApollo includes a performance monitoring system which, through a single line of configuration, brings insights about the queries being executed against your graph, the fields being used in your graph, the clients making requests against your graph, how long your requests are taking, and more.\n\nFrom that information it is possible to track down slow or frequently erroring resolvers, clients using deprecated fields, queries from native apps that need to be supported indefinitely, resolvers that are executing in series instead of in parallel, for example.\n\n#### How it works\n\nWith [one line of configuration](/docs/references/setup-analytics), Apollo Server will start recording traces of every request it receives and sending summaries of that performance data to Engine. Engine aggregates and summarizes those traces to provide segmented, filterable insights about your graph's usage.\n\n<h2 id=\"trace\">Traces</h2>\n\nWith the metrics reporting set up, you'll be able to see traces of your operations in [Engine](https://engine.apollographql.com). Execution of a GraphQL request happens layer by layer, and each field in the query calls a function in your server called a resolver. The [_trace_ view in Engine](https://blog.apollographql.com/the-new-trace-view-in-apollo-engine-566b25bdfdb0) allows you to look at a detailed breakdown of the execution for individual operations, with timing shown for every resolver.\n\n![Trace view](../img/trace.png)\n\n<h3 id=\"critical-path\">Critical path</h3>\n\nWhen a trace is opened, some resolvers are collapsed and others are expanded. This is Engine automatically expanding resolvers on the \"critical path\" of the query. The critical path is the set of fields and resolvers that makes the longest sequence in the query. If you are trying to speed up your query's execution, this is the set of fields you should be looking at first.\n\n<h3 id=\"sampled-traces\">Trace inspector</h3>\n\nEvery trace stored in Engine records the request's resolver timings, variables, and HTTP headers. This is particularly useful when debugging and the detailed information about the trace can be found by opening up the _trace inspector_:\n\n![Trace Inspector](../img/trace-inspector.png)\n\n<h3 id=\"tracking-subs\">A note on GraphQL subscriptions</h3>\n\nEngine does not currently track statistics or traces for subscriptions. The proxy does, however, support the transparent pass-through of subscription requests and responses.\n\n<h2 id=\"operation-signatures\">Operation signatures</h2>\n\nEngine groups operations that select the same fields together, treating different queries distinctly even if they share the same name. Not every query string can be taken as-is for grouping though, because some queries inline their variables. For these cases, Engine has a _signature_ algorithm to normalize inline variables so that queries of the same shape can still be grouped together.\n\n<h3 id=\"transformations\">Signature algorithm</h3>\n\nThe current signature algorithm performs the following transformations when generating a signature. (Future improvements to Engine will allow users to customize the signature algorithm.)\n\n- Input argument values are mapped according to the following rules:\n  - `Variable`, `BooleanValue`, and `EnumValue` preserved\n  - `IntValue` and `FloatValue` replaced by `0`\n  - `StringValue` replaced by `\"\"`\n  - `ListValue` replaced by `[]`\n  - `ObjectValue` replaced by `{}`\n- [Ignored tokens](http://facebook.github.io/graphql/draft/#sec-Source-Text.Ignored-Tokens) are removed, including redundant `WhiteSpace`. Single spaces are only preserved when required for parsing the request.\n- Only the `OperationDefinition` corresponding to the requested operation and reachable `FragmentDefinition`s are included.\n  The operation appears first. Fragment definitions appear in order of first reachability when traversing spread-first, depth-second.\n- `Alias`es are removed.\n- In `SelectionSet`, fields appear before fragment spreads, fragment spreads appear before inline fragments.\n- Otherwise, elements are sorted by name alphanumerically, including `Argument` and `Directive`.\n- Otherwise, elements are kept in order. For example in `{north:neigh(dir:NORTH) east:neigh(dir:EAST)}`, `EAST` should always appear after `NORTH`.\n\nFor example:\n\n```\nquery Foo {\n  user(id : \"hello\") {\n    ... Baz\n    timezone\n    aliased: name\n  }\n}\nfragment Baz on User {\n  dob\n}\n```\n\nbecomes\n\n```\nquery Foo{user(id:\"\"){name timezone...Baz}}fragment Baz on User{dob}\n```\n\nSee the reference implementation of [query signatures](https://github.com/apollographql/apollo-tooling/blob/7e1f62a8635466e653d52064745bf8c66bb7dd10/packages/apollo-graphql/src/operationId.ts#L60) for more information.\n\n<h3 id=\"signatures-sensitive-data\">Signatures and sensitive data</h3>\n\nThe signature algorithm is primarily designed to make it possible to treat operations that differ only in trivial ways as the same operation. It also happens that removing the content of string literals appears to achieve greater data privacy within Engine, but this is not the primary goal. In fact, Engine also sends the full raw query along with traces (though it does not currently expose them in the user interface), so relying on the signature to ensure sensitive data never hits Engine's servers is inappropriate.\n\nFuture versions of Engine are likely to change this default algorithm to leave string literals alone, though it will still be easy to configure your server to remove string literals like in the current implementation. We also intend to stop sending the full raw query in future versions of Engine, so that the signature algorithm really can be used to avoid sending sensitive data in queries to Engine.\n\nBut where possible, we strongly advise that you keep sensitive data in GraphQL variables instead of in literal arguments in the query body, as you can more easily control which variables should be stripped out of the Engine reporting pathway for privacy purposes. See [data privacy](../data-privacy.html) for further detail on how this works.\n\n## Error tracking\n\nMetrics reporting to Engine comes with built-in error tracking for basic GraphQL errors. Engine will be able to classify errors by **error type**, **class**, and **message**.\n\n![Errors](../img/error.png)\n\nThe errors tab in Engine's metrics layer automatically shows errors aggregated across your service, and this can be filtered to errors for a specific operation using the filter panel. Each operation can have multiple requests that return errors and will list these. Each error listed that has one trace can have multiple errors under each resolver. Clicking into the trace for a request with errors will take you to details of that error instance.\n","path":"/platform/performance","filePath":"docs/source/platform/performance.md"},{"title":"Integrate with third party services","description":"Integrate Apollo tools with the existing parts of your workflow","content":"\nOne of our fundamental beliefs is that our Apollo workflows should hook into and enhance the workflows you're already using. As such, we've built a number of integrations into third-party services that are common in the developer world:\n\n1. [**GitHub**](#github) &mdash; Ensure the safe evolution of your graph by adding schema change validation directly to your continuous integration and GitHub checks.\n1. [**Slack**](#slack) &mdash; Get a daily summary of key information from your server, including the overall request rate, error rate, and performance latency. Set up notifications for noteworthy events in your service, like increases in errors or particularly slow response times for important queries.\n1. [**Datadog**](#datadog) &mdash; Forward the key metrics and performance data available from Engine to Datadog as well.\n\n<h2 id=\"github\">GitHub</h2>\n\nBuilding tools to help you safely collaborate on the evolution of your graph is one of our biggest focuses at Apollo. To make [schema change validation](/docs/platform/schema-validation.html) as easy to set up as possible, we've built an Apollo app for GitHub that provides status checks on pull requests when schema changes are proposed.\n\n![GitHub Status View](../img/schema-validation/github-check.png)\n\n<h3 id=\"install-github\">Install the GitHub application</h3>\n\nGo to [https://github.com/apps/apollo-engine](https://github.com/apps/apollo-engine) and click the `Configure` button to install the Apollo Engine integration on the GitHub profile or organization that you want to set up checks for.\n\n<h3 id=\"check-schema-on-ci\">Run validation on each commit</h3>\n\nNext, make sure your CI has a step to run the schema validation command. This is accomplished by adding the `apollo schema:check` command directly as a step in your CI. For CircleCI it could look something like this:\n\n```yaml line=13,29,33-36\nversion: 2\n\njobs:\n  build:\n    docker:\n      - image: circleci/node:8\n\n    steps:\n      - checkout\n\n      - run: npm install\n      # CircleCI needs global installs to be sudo\n      - run: sudo npm install --global apollo\n\n      # Start the GraphQL server.  If a different command is used to\n      # start the server, use it in place of `npm start` here.\n      - run:\n          name: Starting server\n          command: npm start\n          background: true\n\n      # make sure the server has enough time to start up before running\n      # commands against it\n      - run: sleep 5\n\n      # This will authenticate using the `ENGINE_API_KEY` environment\n      # variable. If the GraphQL server is available elsewhere than\n      # http://localhost:4000/graphql, set it with `--endpoint=<URL>`.\n      - run: apollo service:check\n\n      # When running on the 'master' branch, publish the latest version\n      # of the schema to Apollo Engine.\n      - run: |\n          if [ \"${CIRCLE_BRANCH}\" == \"master\" ]; then\n            apollo service:push\n          fi\n```\n\n> **Note:** Your `apollo service:check` command needs a source to from which to fetch your schema. This is most commonly provided as a URL to a running server (with introspection enabled), but can also be provided as a path to a file with your schema in it. See [Using the Schema Registry](/docs/platform/schema-registry.html#setup) setup for other options.\n\nThe `apollo schema:check` command checks for differences in your schema between what's on your current branch and the last version you uploaded to Engine. If you've removed or changed any types or fields, it will validate that those changes won't break any of the queries that your clients have made recently. If your changes do break any queries, the check will fail.\n\nBecause you installed the Engine app on GitHub, the check you've added will show up as a line in your GitHub checks list. If there are changes in your schema you'll be able to review them by clicking the \"Details\" link. By enabling schema validation in your continuous integration workflow (eg. CircleCI, etc.), you're alerting developers of any potential problems directly in their pull requests, thereby giving them critical feedback where it's most useful.\n\n<h2 id=\"slack\">Slack</h2>\n\nOur Apollo Slack integration brings your server's performance metrics and analytics data from Apollo Engine directly to your team's Slack workspace so you can be notified of potential issues proactively. The integration does two main things:\n\n1. Send a [**daily snapshot**](#slack-reports) of the request rate, error rate, and performance latency of your graph.\n1. Send [**notifications**](#slack-notifications) that are triggered on thresholds like error percentage and performance latency.\n\n<h3 id=\"setup-slack\">Configure the integration</h3>\n\nThe Apollo Slack integration is set up and configured through the Engine UI. If you do not yet have account, [**follow this guide**](/docs/apollo-server/features/metrics.html#Apollo-Engine) to get started connecting your server to Engine.\n\nIf you already have an Engine account, [**log in**](https://engine.apollographql.com) and ––\n\n1. Select the service you want to turn on Slack notifications for.\n1. Visit the \"Integrations\" tab in the left nav.\n1. You'll notice a \"Reporting Channels\" section at the bottom of this page. Click the \"Add channel\" button and follow the steps in the Engine UI to get a webhook from Slack.\n\nOnce you've configured your Slack channel you'll be able to turn on daily reports snapshotting and configure notifications in the \"General\" and \"Performance Alerts\" sections.\n\n![The Integrations tab in Engine](../img/integrations/integrations-tab.png)\n\n<h3 id=\"slack-reports\">Daily reports</h3>\n\nDaily reports from Engine are sent out around 9am in whichever timezone you configure them to be in. You turn them on in the \"Integrations\" tab as shown above. The reports have a set format that gives a birds-eye view of what your GraphQL API delivered in the previous day:\n\n![Engine slack report](../img/integrations/slack-report.png)\n\n#### Using the report\n\nWe've constructed the report provided to give you an actionable summary of what's happened in your API in the last 24 hours. Here’s how you can use it to identify issues:\n\n1.  **Request rate:** This shows you how many queries are hitting your server every minute, along with a list of the most popular operations. If you see a huge dip in this and it's usually a busy time for your app, it might mean that queries aren’t able to reach your server, or some client is down.\n2.  **p95 service time:** This shows you how long queries are taking to execute. We selected p95 since it’s the best overall representation of how your users are experiencing your app. You can use this to identify that your API is overloaded and users are seeing long loading delays, or to find out which queries are taking the longest to run. This is usually directly connected to UI performance, so a 500ms query probably means some part of your UI is taking that long to display.\n3.  **Error percentage:** This will show you how many of your GraphQL requests end up with an error result. Spikes in errors might be the result of some underlying backend malfunctioning. You can also see which of your operations are most error-prone.\n\n<h3 id=\"slack-notifications\">Notifications</h3>\n\nIn Engine you can configure notifications that are triggered on the performance data of your graph, like error percentages and request latencies. This is particularly useful for detecting anomalies, especially around releases. Notifications can be configured to monitor the following metrics for either your entire GraphQL service or individual operations:\n\n- **Request rate:**  requests per minute\n- **Request duration:** p50/p95/p99 service time\n- **Error rate:** errors per minute\n- **Error percentage:** the number of requests with errors, divided by total\n  requests\n\nThe triggers you set up are evaluated on a rolling five minute window. For example, you can configure a notification to trigger when an operation's error rate exceeds 5%. In production, if 6 out of 100 requests result in an error during the last five minutes, the alert will trigger with an error rate of 6%. Once the error rate falls back below 5% your notification will resolve. Here's an example of what the notification looks like:\n\n![Slack Alert](../img/integrations/slack-notification.png)\n\n<h2 id=\"datadog\">Datadog</h2>\n\nThe Apollo Datadog integration allows you to forward all the performance metrics and analytics data that's available to you in Engine to Datadog as well. This is particularly convenient for teams already relying on Datadog for their monitoring, and of the best perks is that Datadog has advanced filtering features that alerts can be set on, and teams can set those alerts based on their GraphQL metrics data from Engine through Datadog.\n\nThe Datadog metrics forwarded by Engine are:\n\n- `apollo.engine.operations.count`: the number of GraphQL operations that were executed. This includes queries, mutations, and operations that resulted in an error.\n- `apollo.engine.operations.error_count`: the number of GraphQL operations that resulted in an error. This includes GraphQL execution errors, and HTTP errors if Engine failed to connect to your server.\n- `apollo.engine.operations.cache_hit_count`: the number of GraphQL queries whose result was served from Apollo Engine's full query cache.\n- A histogram of GraphQL operation response times, measured in milliseconds. Due to Engine's aggregation method (logarithmic binning), these values are accurate to +/- 5%:\n  - `apollo.engine.operations.latency.min`\n  - `apollo.engine.operations.latency.median`\n  - `apollo.engine.operations.latency.95percentile`\n  - `apollo.engine.operations.latency.99percentile`\n  - `apollo.engine.operations.latency.max`\n  - `apollo.engine.operations.latency.avg`\n\nAll of Engine's new Datadog metrics are tagged with the GraphQL operation name, as `operation:<query-name>`. Unique query signatures with the same operation name are merged, and queries without an operation name are ignored.\nAll of the metrics are also tagged with the Engine graph ID, `service:<graph-id>`, so multiple graphs from Engine can send data to the same Datadog account.\n\nEngine sends metrics to Datadog in 60 second intervals. Data is forwarded with a 60 second delay to allow for reports to be collected, even in the case of temporary network failures.\n\nIf you're reporting metrics to Engine through the Engine proxy, Datadog will merge you statistics across multiple instances of the proxy (per-host metrics are not available). Just like in the Engine UI, each operation inside a query batch is counted individually.\n\n#### Setup\n\nGetting set up with Engine's Datadog integration is as simple as providing a Datadog API key to Engine. There's no further configuration required! You will need to have an account with administrator access to Datadog to acquire that API key.\n\n1.  Go to The [Datadog integrations page](https://app.datadoghq.com/account/settings) and search for \"Apollo Engine\".\n2.  Click the \"+Available\" button and go the the _Configuration_ tab. Copy the API key from the \"Configuration\" tab, click \"Install Integration\" at the bottom, and go to the [service](https://engine.apollographql.com) you'd like to enable Datadog Metric Forwarding for.\n3.  In the settings for the service, scroll to \"Integrations\", and toggle Datadog to ON. When prompted, paste in the API key.\n4.  Go to your Datadog metric explorer and start to see the metrics flow in! Please allow up to five minutes for metrics to be visible.\n\nNavigate to the Apollo Engine Integration in Datadog\n\n![IntegrationTile](../img/datadog/integration-tile.png)\n\nGet the API Key from the Configuration tab before clicking \"Install Integration\":\n\n![ApiKey](../img/datadog/api-key.png)\n\nOnce you've turned on the integration in Datadog, visit the \"Integrations\" tab in your Engine account and turn on the toggle for Datadog.\n\n#### Metrics exploration\n\nOnce you have Datadog forwarding set up, you will start seeing Engine metrics forwarded to your Datadog account within a few minutes. Navigate to the [Datadog metric explorer](http://app.datadoghq.com/metric/explorer?exp_metric=apollo.engine.operations.count&exp_group=service&exp_agg=avg&exp_row_type=metric) to see data from your GraphQL service flowing in.\n\nEach of the metrics reported is [tagged](https://www.datadoghq.com/blog/the-power-of-tagged-metrics/) with the graph ID (`service:<graph-id>`) it is reporting for and the operation name (`operation:<query-name>`), both of which are normalized by Datadog naming requirements (letters are all lower-case and illegal symbols are converted to underscores). This tagging makes it easier to see data at whatever level of granularity you might want.\n\nIf you want to aggregate across all operations or zoom in to a particular operation, it's simply a tag-filtering. Similarly, if you want to compare metrics across staging and production environment, it should be as simple as generating one graph per environment.\n\n**Example**: Suppose you want to see the 95th percentile averaged across all operations for a staging and a production service.\n\n_In the metric explorer, select `apollo.engine.operations.latency.95percentile` and then choose service where it says “one graph per” and select the two services you'd like to compare. At Apollo, we monitor Engine with Engine on our production and staging environments, so this graph for us looks like the following_:\n\n![Compare p95](../img/datadog/datadog.png)\n\n_To perform more advanced manipulation of metrics, open up the [Metrics notebook](https://app.datadoghq.com/notebook)._\n\n#### Monitoring with Datadog\n\nAll of the metrics reported to Datadog can be notified on directly through Engine via the Notifications feature, but Datadog can be a powerful partner in enabling more complex alerts.\n\n**Example**: Suppose you have a query that is run against your GraphQL server with a much higher volume in the morning than in the afternoon. You want to enable monitoring on that query's latency and error rates, but if the query volume is very low, you have a higher tolerance for latency and one error will skew the error rate and make the monitor too noisy.\n\n_You can use Datadog's [composite monitoring](https://docs.datadoghq.com/monitors/monitor_types/composite/) to enable more complex alerting. You need to start by creating a monitor for each condition you want to track and then combining them in a composite monitor, as explained in the [Datadog documentation](https://docs.datadoghq.com/monitors/monitor_types/composite/)._\n","path":"/platform/integrations","filePath":"docs/source/platform/integrations.md"}]},{"title":"Resources","pages":[{"path":"https://www.principledgraphql.com","title":"Principled GraphQL","anchor":true},{"title":"GraphQL Glossary","description":"A comprehensive list of important GraphQL words and acronyms","content":"\nWhen you start diving into the GraphQL ecosystem, you'll probably encounter some unfamiliar terms and phrases along the way. To help you on your journey, we've defined some of the most common GraphQL vocabulary here in this handy cheat sheet.\n\n<h2 id=\"Apollo\">Apollo</h2>\n\nAn open-source implementation of GraphQL that helps you manage data between the cloud and your UI. The Apollo platform is pluggable into your existing architecture and features production-ready tooling that helps you scale GraphQL across your organization ([Server](https://www.apollographql.com/docs/apollo-server/getting-started.html), [Client](https://www.apollographql.com/docs/react/), and [Engine](https://www.apollographql.com/docs/engine/)).\n\n<h2 id=\"automatic-persisted-queries\">Automatic Persisted Queries (APQ) </h2>\n\nA technique for improving GraphQL network performance with zero build-time configuration by reducing request size over the wire. A smaller signature reduces bandwidth utilization and speeds up client loading times. Apollo Server allows implementation of [Automatic Persisted Queries (APQ)](https://www.apollographql.com/docs/guides/performance.html#automatic-persisted-queries).\n\n<h2 id=\"argument\">Argument</h2>\n\nA set of key-value pairs attached to a specific field. Arguments can be literal values or variables.\n\n```js\n{\n  human(id: \"200\") {\n    weight(unit: \"pounds\")\n    height\n  }\n}\n```\n\n`id` is an argument to human in the query above.\n\n<h2 id=\"alias\">Alias</h2>\n\nAn alternative name given to the result of a field to avoid conflicts during data fetching.\n\n```js\n{\n  admins: users(role: \"admin\") {\n    id\n    firstname\n    lastname\n  }\n  managers: users(role: \"manager\") {\n    id\n    firstname\n    lastname\n  }\n}\n```\n\n`admins` and `managers` are aliases in the example query above.\n\n<h2 id=\"data-source\">Data Source</h2>\n\nA new pattern for fetching data from a particular service, with built-in support for caching, deduplication, and error handling. When deploying GraphQL as a layer between your apps and existing APIs and services, [Data sources](https://www.apollographql.com/docs/apollo-server/v2/features/data-sources.html) provide the best experience for fetching and caching data from REST endpoints.\n\n<h2 id=\"deferred-query\">Deferred query</h2>\n\nA query that has certain fields tagged with the [`@defer` directive](https://www.apollographql.com/docs/react/features/defer-support.html), so that fields that take a long time to resolve do not need to slow down the entire query.\n\n```js\nquery NewsFeed {\n  newsFeed {\n    stories {\n      text\n      comments @defer {\n        text\n      }\n    }\n  }\n}\n```\n\n<h2 id=\"directive\">Directive</h2>\n\nA declaration prefixed with an `@` character that encapsulates programming logic for query execution on the client or server. There are built-in directives such as `@skip` or `@include`, and [custom directives](https://www.apollographql.com/docs/graphql-tools/schema-directives.html). Directives can be used for features such as authentication, incremental data loading, etc.\n\n```js\ntype User @auth {\n  name: String!\n  banned: Boolean @auth!\n}\n```\n\n<h2 id=\"docstring\">Docstring</h2>\n\nIt is used for providing descriptions of types, fields and arguments. Docstrings show up in the documentation panel inside GraphQL playground and GraphiQL.\n\n```js\n\"\"\"\nDescription for the User\n\"\"\"\ntype User {\n  \"\"\"\n  Description for first Name\n  \"\"\"\n  firstName: String!\n\n  age(\n    \"\"\"\n    Must be an integer\n    \"\"\"\n    arg: Int\n  )\n}\n```\n\n<h2 id=\"document\">Document</h2>\n\nA file or request string that contains one or multiple definitions of a GraphQL type system and can be interpreted by a GraphQL execution engine.\n\n<h2 id=\"extensions\">Extensions</h2>\n\nSpecial fields in the GraphQL response that allow you to attach extra metadata. [Apollo tracing](https://github.com/apollographql/apollo-server/tree/master/packages/apollo-tracing) is an example of an extension.\n\n<h2 id=\"field\">Field</h2>\n\nA unit of data you are asking for in a Schema, which ends up as a field in your JSON response data.\n\n```js\ntype Author {\n  id: Int!\n  firstName: String\n  lastName: String\n}\n```\n\n`id`, `firstName`, and `lastName` are fields in the Author type above.\n\n<h2 id=\"fragment\">Fragment</h2>\n\nA selection set that can be reused in multiple query operations. A [GraphQL fragment](https://www.apollographql.com/docs/react/advanced/fragments.html) is a shared piece of query logic.\n\n```js\nfragment UserData on User {\n  id: ID!\n  firstName: String!\n  lastName: String!\n}\n\nquery getUsers {\n  allUsers {\n    ...UserData\n  }\n}\n```\n\n<h2 id=\"gql-function\">gql function</h2>\n\nA [JavaScript template literal tag](https://github.com/apollographql/graphql-tag) that parses GraphQL queries into an abstract syntax tree (AST).\n\n```js\nconst typeDefs = gql`\n  type File {\n    filename: String!\n    mimetype: String!\n    encoding: String!\n  }\n`;\n```\n\n<h2 id=\"graphql-playground\">GraphQL Playground</h2>\n\nAn in-browser IDE for GraphQL development and workflow. Added benefits exist such as theme change, automatic schema reloading, HTTP headers configuration, query history and GraphQL subscription support. In addition, it comes [out-of-the-box in Apollo Server 2](https://www.apollographql.com/docs/apollo-server/features/graphql-playground.html).\n\n<h2 id=\"graphql-service\">GraphQL Service</h2>\n\nThe server that contains a GraphQL schema and the ability to run it. Services have runtime information, and through features of the Apollo Platform they can send metrics and maintain a history of the schemas that have been run on that service in the past.\n\n<h2 id=\"graphiql\">GraphiQL</h2>\n\nAn in-browser IDE for GraphQL development.\n\n<h2 id=\"introspection\">Introspection</h2>\n\nA technique to provide detailed information about a GraphQL API's schema. Types and fields used in introspection are prefixed with \"\\_\\_\" two underscores.\n\n```js\n{\n  __schema {\n    types {\n      name\n    }\n  }\n}\n```\n\n<h2 id=\"mutation\">Mutation</h2>\n\nAn operation for creating, modifying and destroying data.\n\n```js\nmutation AddTodo($type: String!) {\n  addTodo(type: $type) {\n    id\n    type\n  }\n}\n```\n\n<h2 id=\"normalization\">Normalization</h2>\n\nA technique for transforming the response of a query operation before saving it to the store by [Apollo Client's `InMemoryCache`](https://www.apollographql.com/docs/react/advanced/caching.html#normalization). The result is split into individual objects, creating a unique identifier for each object, and storing those objects in a flattened data structure.\n\n```js\nimport { InMemoryCache, defaultDataIdFromObject } from 'apollo-cache-inmemory';\n\nconst cache = new InMemoryCache({\n  dataIdFromObject: object => {\n    switch (object.__typename) {\n      case 'foo':\n        return object.key; // use `key` as the primary key\n      case 'bar':\n        return `bar:${object.blah}`; // use `bar` prefix and `blah` as the primary key\n      default:\n        return defaultDataIdFromObject(object); // fall back to default handling\n    }\n  }\n});\n```\n\n<h2 id=\"object-type\">Object Type</h2>\n\nA type in a GraphQL schema that has fields.\n\n```js\ntype User {\n   name: String!\n}\n```\n\n`User` is an Object type in the example above.\n\n<h2 id=\"operation\">Operation</h2>\n\nA single query, mutation, or subscription that can be interpreted by a GraphQL execution engine.\n\n<h2 id=\"operation-name\">Operation name</h2>\n\nA name for a single query, mutation, or subscription. Identifying a query or mutation by name is very useful for logging and debugging when something goes wrong in a GraphQL server.\n\n```js\nmutation AddTodo($type: String!) {\n  addTodo(type: $type) {\n    id\n    type\n  }\n}\n\nquery getHuman {\n  human(id: \"200\") {\n    weight(unit: \"pounds\")\n    height\n  }\n}\n```\n\n`AddTodo` and `getHuman` are names for the mutation and query operation respectively.\n\n<h2 id=\"partial-query-caching\">Partial query caching</h2>\n\nA technique for caching inputs to GraphQL queries. This type of caching ensures that if the query is slightly different but with the same inputs, those inputs can simply be retrieved from the cache instead of fetching data again from the backend. It is implemented in Apollo Server 2 as [Data Source](https://www.apollographql.com/docs/apollo-server/features/data-sources.html) caching.\n\n<h2 id=\"query\">Query</h2>\n\nA read-only fetch operation to request data from a GraphQL service.\n\n<h2 id=\"query-colocation\">Query colocation</h2>\n\nA practice of placing a GraphQL query in the same location as the app component's view logic. Query co-location makes it easier to facilitate a smooth UI and chore of data retrieval. Jumping directly to the query and keeping the component in sync with its data dependencies is a pleasure.\n\n```js\nconst GET_DOG_PHOTO = gql`\n  query dog($breed: String!) {\n    dog(breed: $breed) {\n      id\n      displayImage\n    }\n  }\n`;\n\nexport const queryComponent = ({ breed }) => (\n  <Query query={GET_DOG_PHOTO} variables={{ breed }}>\n    {({ loading, error, data }) => {\n      if (loading) return null;\n      if (error) return 'Error!';\n      return <img src={data.dog.displayImage} />;\n    }}\n  </Query>\n);\n```\n\n<h2 id=\"query-whitelisting\">Query whitelisting</h2>\n\nA technique for preventing unwanted attacks by maintaining a list of approved queries that are allowed in your application. Any query not present in the list that is run against the server will not be allowed. [Automatic Persisted Queries](../guides/performance.html#automatic-persisted-queries) is a feature of Apollo Server 2 that enables query whitelisting and persisted queries.\n\n<h2 id=\"resolver\">Resolver</h2>\n\nA function that connects schema fields and types to various backends. Resolvers provide the instructions for turning a GraphQL operation into data. It can retrieve data from or write data to anywhere, including a SQL, No-SQL, or graph database, a micro-service, and a REST API. Resolvers can also return strings, ints, null, and other primitives.\n\n```js\n...\nconst resolvers = {\n  Query: {\n    author(root, args, context, info) {\n      return find(authors, { id: args.id });\n    },\n  },\n  Author: {\n    books(author) {\n      return filter(books, { author: author.name });\n    },\n  },\n};\n```\n\n<h2 id=\"schema\">Schema</h2>\n\nA GraphQL [schema](https://www.apollographql.com/docs/apollo-server/essentials/schema.html) is at the center of any GraphQL server implementation and describes the functionality available to the clients which connect to it.\n\n<h2 id=\"schema-definition-language\">Schema Definition Language (SDL)</h2>\n\nThe syntax for writing GraphQL Schemas. It is otherwise known as Interface Definition Language. It is the lingua franca shared by all for building GraphQL APIs regardless of the programming language chosen.\n\n```js\ntype Author {\n  id: Int!\n  firstName: String\n  lastName: String\n  posts: [Post]\n}\ntype Post {\n  id: Int!\n  title: String\n  author: Author\n  votes: Int\n}\ntype Query {\n  posts: [Post]\n  author(id: Int!): Author\n}\n```\n\n<h2 id=\"schema-first-development\">Schema first development</h2>\n\nA [development approach](https://www.apollographql.com/docs/fundamentals/tips.html#schema) for designing and building modern UIs that involves the frontend and backend teams agreeing on a Schema first, which serves as a contract between the UI and the backend before any API engineering happens.\n\n<h2 id=\"schema-registry\">Schema registry</h2>\n\nA central source of truth for your schema in Apollo Engine. It enables schema registration, schema validation, tracking of detailed schema changes e.g. types added, fields added, fields deprecated and looking up previous versions of schema.\n\n<h2 id=\"schema-versioning\">Schema versioning</h2>\n\nRefers to the need to evolve a schema over time. As a schema evolves, there is a potential for introducing breaking changes to clients. The Apollo CLI assists schema evolution by validating schema changes and checking for breaking changes using Apollo Engine. Read more in our article about [schema change validation](https://www.apollographql.com/docs/platform/schema-validation#versioning).\n\n<h2 id=\"schema-stitching\">Schema stitching</h2>\n\nThe process of merging [different schemas into one GraphQL schema](./docs/graphql-tools/schema-stitching.html). These schemas can be local, remote, or from third-party services. In a microservice-style deployment model, where your data exists across multiple APIs, schema stitching makes it possible to combine all of them into one schema that can be queried for all the data at once.\n\n<h2 id=\"subscription\">Subscription</h2>\n\nA real-time GraphQL operation. A [Subscription](https://www.apollographql.com/docs/apollo-server/features/subscriptions.html) is defined in a schema along with queries and mutations.\n\n```js\ntype Subscription {\n  commentAdded(repoFullName: String!): Comment\n}\n...\nsubscription onCommentAdded($repoFullName: String!){\n  commentAdded(repoFullName: $repoFullName){\n    id\n    content\n  }\n}\n```\n\n<h2 id=\"scalar-type\">Scalar Type</h2>\n\nA type that qualifies the data a GraphQL field resolves. GraphQL ships with some scalar types out of the box; **Int**, **Float**, **String**, **Boolean** and **ID**. However, a [custom scalar](https://www.apollographql.com/docs/graphql-tools/scalars.html#custom-scalars) type such as **Date** can be specified in a GraphQL service implementation.\n\n<h2 id=\"type-system\">Type System</h2>\n\nA collection of types which characterizes the set of data that can be validated, queried, and executed on a GraphQL API.\n\n<h2 id=\"variable\">Variable</h2>\n\nA value that can be passed to an operation. Variables can be used to fill arguments, or be passed to directives.\n\n```graphql\nquery GetUser($userId: ID!) {\n  user(id: $userId) {\n    firstName\n  }\n}\n```\n\nIn the query above, `userId` is a variable. The variable and its type is declared in the operation signature, signified by a `$`. The type of the variable here is a required `ID`. It's important to note that variable types must match the type of the arguments that they fill.\n\nThe `userId` variable would be passed to the operation by `apollo-client` like this:\n\n```js\nclient.query({ query: getUserQuery, variables: { userId: 1 } });\n```\n\nIn `react-apollo` it would be passed like this:\n\n```jsx\n<Query query={getUserQuery} variables={{ userId: 1 }}>\n  {' '}\n  ...{' '}\n</Query>\n```\n\n<h2 id=\"whole-response-caching\">Whole response caching</h2>\n\nA technique used to cache entire results of GraphQL queries. This process improves performance by preventing the fetching of the same results from the server if it has been obtained before. Read more about GraphQL query caching in our [guide for caching with Apollo Server](https://www.apollographql.com/docs/apollo-server/features/caching).\n","path":"/resources/graphql-glossary","filePath":"docs/source/resources/graphql-glossary.md"},{"title":"Frequently Asked Questions","description":"Common questions asked at each stage of GraphQL adoption","content":"\nEveryone has questions about how to properly set up a GraphQL schema, but not all questions are alike. In different stages of development, different things matter. This guide answers questions that people commonly have at every step along the journey to GraphQL in production.\n\n## Learning GraphQL\n\nYou are just beginning to learn GraphQL. You're learning about syntax, running queries, schemas, and how to connect your existing services to your GraphQL layer.\n\n#### What is GraphQL?\n\nGraphQL is a language for querying data. With GraphQL, your existing services describe the data that they have, and clients describe the data they need. This is possible because of a strongly-typed [schema](http://graphql.github.io/learn/schema/) (type definitions).\n\n#### Why use GraphQL?\n\nGraphQL can make a difference in nearly every area of development: from improving developer experience with quality tooling to improving client performance by reducing bundle sizes. Read more about the benefits of GraphQL [here](../fundamentals/benefits.html).\n\n#### Where can I learn GraphQL?\n\nThere are a number of resources available to learn GraphQL. If you're looking to get started learning the basics, check out [GraphQL.org](https://graphql.org).\n\nThe simplest way to get started with implementing GraphQL is with the Apollo platform. The Apollo platform includes all the tools needed to get started, including a production-ready GraphQL server (`apollo-server`), a fully-featured schema management and monitoring tool, Apollo Engine, and a client that manages local and remote data in your apps (`apollo-client`).\n\nTo get started, read the getting started guides for [`apollo-server`](https://www.apollographql.com/docs/apollo-server/getting-started.html), [Apollo Engine](https://engine.apollographql.com), and [`react-apollo`](https://www.apollographql.com/docs/react/essentials/get-started.html) (the react integration for apollo-client).\n\nThis site and the [Apollo blog](https://blog.apollographql.com) are also great places to learn and keep up with the latest developments in GraphQL and Apollo.\n\n#### How can I host my schema online?\n\nA great tool for learning and building small projects is [Glitch](https://glitch.com). Glitch allows development of a schema in the browser, and even supports cloning from and pushing to GitHub. Glitch provides a public endpoint that projects can query against. To get started with building a GraphQL schema, try using and remixing the [Apollo Launchpad](https://glitch.com/~apollo-launchpad) project.\n\nGraphQL schemas written with `apollo-server` can be deployed anywhere that other Node.js projects can be deployed. `apollo-server` even has variants to support serverless deployment with AWS Lambda.\n\nThere are deployment guides currently written for [Heroku](https://www.apollographql.com/docs/apollo-server/deployment/heroku.html), [Lambda](https://www.apollographql.com/docs/apollo-server/deployment/lambda.html), and [Now](https://www.apollographql.com/docs/apollo-server/deployment/now.html).\n\n#### How do I connect my client app to my schema?\n\nThe Apollo platform has tools available to connect almost any kind of client to your schema: [Apollo Client](https://www.apollographql.com/docs/react/) for JavaScript clients,\n[Apollo iOS](https://www.apollographql.com/docs/ios/) for native iOS clients, and [Apollo Android](https://github.com/apollographql/apollo-android) for native Android clients.\n\nFor Apollo Client projects, there are also many view-layer integrations, to make querying GraphQL schemas easier in [React](https://www.apollographql.com/docs/react/essentials/get-started.html), [Vue](https://github.com/Akryum/vue-apollo), and [Angular](https://www.apollographql.com/docs/angular/).\n\n## Building a proof of concept\n\nYou understand how GraphQL works and what benefits it offers. You are trying to create a proof of concept for your projects or company to test GraphQL's viability in production.\n\n#### Should I use Node.js for schema development?\n\nThere are GraphQL server tools available for most popular languages, but we recommend using [apollo-server](https://www.apollographql.com/server) (Node.js) because of the ecosystem of tools developed for GraphQL in JavaScript. Node servers can also be run nearly anywhere, including on the edge.\n\n#### How do I wrap existing APIs?\n\nOne of the best things about GraphQL is that it works excellently with existing APIs. It's possible to connect any number of existing services to your schema.\n\nThe most common source is a REST API. The [`RESTDataSource`](https://www.apollographql.com/docs/apollo-server/features/data-sources.html) is a tool that integrates with `apollo-server` to simplify fetching and caching for existing REST APIs.\n\nOther DataSources are under development, but even without the `DataSource` API, it's possible to connect any backend to a schema. [Resolvers](https://www.apollographql.com/docs/apollo-server/essentials/data.html) can do anything, including fetch data from an SDK or ORM.\n\n#### How do I design the schema?\n\nSchemas should be designed with the needs of the client in mind. Rather than modeling queries and types after the underlying services, they should be designed to make querying as easy as possible. GraphQL's resolver structure makes it possible to allow this flexibility without many performance consequences. For more, read the [schema design guide](../guides/schema-design.html).\n\n#### How do I discover and reproduce errors?\n\nAs with any service, it's important to track errors and their causes. There are many kinds of errors that can occur with a GraphQL Schema. Some of these include service errors, where the schema can't access underlying services, and user errors, where a user enters invalid information in a query or mutation.\n\nGraphQL is resilient to some of these errors. Since the schema is strongly typed, the designer has the ability to restrict what type of data users can enter and what type the resolvers can return. This type system catches many errors and requires no manual checks.\n\nFor errors not prevented by the type system, it's helpful to know what exact queries were made, and with what variables. [Apollo Engine](https://www.apollographql.com/engine) is a tool that does exactly this. It can help discover and reproduce errors by showing the exact conditions in which the error occurred.\n\n## Moving a feature to GraphQL\n\nYou have decided to use GraphQL in production. You don't want to immediately refactor the APIs or apps. You want to move a single feature over to GraphQL to learn how to use it and monitor it in production.\n\n#### How should the transition to GraphQL happen?\n\nAs with any large change, the adoption of GraphQL should be incremental. GraphQL allows teams to leave existing services as they are and build convenient gateways on top of them.\n\n#### Who owns the schema design?\n\nGraphQL schemas work best when their design is heavily influenced by the needs of the product developers. It's tempting to design a schema to resemble the underlying sources or databases, but this can be hurtful to the usefulness of GraphQL.\n\n#### How do I set up authentication/authorization for my GraphQL schema?\n\nAuthentication and authorization are important topics to discuss with any API. GraphQL provides a very granular approach to handling these topics. But don't worry, if an API being consumed by GraphQL already has authorization built-in, it may be possible to ignore it completely.\n\n#### How can I secure my schema from malicious or expensive queries?\n\nPublic APIs of any kind need some kind of safeguards against malicious queries. Since GraphQL allows for recursive queries, it wouldn't be hard to create a query that is overly complicated and acts as a DoS attack, even by accident. There are multiple ways to prevent something like this from happening, from complexity limiting to query depth limiting. Read the [guide on security](https://blog.apollographql.com/securing-your-graphql-api-from-malicious-queries-16130a324a6b) to learn more.\n\n#### What kinds of cache should I set up?\n\nGraphQL can be cached in multiple places.\n\nOn the client, caches can prevent multiple queries from being called when not necessary. Client caches for GraphQL differ from REST clients in one important way: cache can handle queries that have never been made. This is possible because of how a GraphQL response is normalized and stored. For example, if a client requests a list of movies, each movie is cached separately on the client. Later, if the client requests a single movie in a different query and the needed information is in the cache, the request doesn't have to be made. This normalized cache is a part of `apollo-client` by default.\n\nCache can also be set up at the schema level. Whole-query caching, partial-query caching, and cache backed by a CDN can all be used to lower response times and make a GraphQL schema as performant as possible.\n\nWhole-query and CDN caches are most useful when an API receives many of the same queries. This commonly happens with public data, like content on pages of a site. Regardless of whether the API is used for public data or not, these caches almost always provide large performance benefits and are highly recommended. You can read more about how to set up whole-query and CDN caching with `apollo-server` 2.0 [here](https://www.apollographql.com/docs/guides/performance.html).\n\nPartial query caching can be achieved by caching the responses from underlying services with something like Redis or Memcache. With this strategy, even if two queries look completely different from one another, if there is any duplication of data fetched, those results can be shared, preventing unnecessary traffic. The [`RESTDataSource`](https://www.apollographql.com/docs/apollo-server/features/data-sources.html) does this automatically if the appropriate `cache-control` headers are present in REST responses.\n\n#### How can I monitor the health of my GraphQL schema?\n\nMany apps and sites are powered almost completely by an API such as a GraphQL schema, so it's important to make sure the API is healthy at all times. Indicators of an unhealthy service include long response times, high resource usage, and unusual traffic patterns.\n\n[Apollo Engine](https://www.apollographql.com/platform) is a great tool to track many of these things. It allows close inspection of fields to make it easy to see both total response times as well as how long each field took to execute.\n\nApollo Engine also has some integrations to make monitoring easier. The [Slack Integration](https://www.apollographql.com/docs/platform/integrations#slack) delivers daily reports to give teams a quick overview of the health of their schema. The [DataDog integration](https://www.apollographql.com/docs/platform/integrations#datadog)) works with existing DataDog accounts, to help teams track schema performance.\n\n## Moving a product to GraphQL\n\nYou have a good understanding of how to write, deploy, and monitor GraphQL in production. You are looking to scale GraphQL features to your entire product line.\n\n#### How do I organize schema code to scale for a larger project?\n\nKeeping all schema code together makes sense for smaller projects, but once a project reaches a certain size, or has many people working on it, managing conflicts in the same file and code navigation can get difficult. Splitting types and resolvers up into smaller files can make this process much easier. Read [this blog post](https://blog.apollographql.com/modularizing-your-graphql-schema-code-d7f71d5ed5f2) to learn more.\n\n<!-- TODO: @jakedawkins Add server testing -->\n\n#### How can I test my client?\n\n`react-apollo` comes with everything needed to test a client app that makes queries to a GraphQL schema. Read the [Testing React Components](/docs/react/recipes/testing) guide to learn more.\n\n#### How can I safely make changes to the schema?\n\nSchemas naturally evolve over time. GraphQL schemas are more resilient to change than other APIs, but there are still occasions where breaking changes will need to happen to support new functionality. The [versioning guide](../guides/versioning.html) explains in more detail what kinds of changes are safe to make, and what kinds could break existing clients.\n\nAdditionally, using the [Apollo CLI](https://www.npmjs.com/package/apollo) with Apollo Engine provides the tools needed to [validate schema changes](https://www.apollographql.com/docs/engine/features/schema-history.html) over time. This makes collaboration easier and more transparent.\n","path":"/resources/faq","filePath":"docs/source/resources/faq.md"}]},{"title":"References","pages":[{"title":"Configuring Apollo projects","description":"How to configure Apollo VS Code and CLI with apollo.config.js","content":"\nApollo projects are configured using an `apollo.config.js` file at the root of your project. Many Apollo tools leverage your the Apollo config, reducing the net amount of configuration you need to do in your project in the end.\n\nIf you're using one of our workflow tools like the Apollo CLI or the Apollo VS Code extension, you'll need to have an `apollo.config.js` project to get the features those tools bring.\n\nThere are two types of projects, `client` and `service`, which can be in the same configuration file if necessary. This document describes all the options available in the Apollo config and defines which are required vs. optional.\n\n<h2 id=\"client-config\">Client projects</h2>\n\nClient projects are configured through a top level `client` key in the config.\n\n```js line=2\nmodule.exports = {\n  client: { ... },\n};\n```\n\n### `client.service`\n\n**Required** –– the CLI and VS Code extension rely on knowledge of your schema to show you \"intellisense\" (eg. autocomplete on fields, metrics annotations, query validation).\n\nThere are a few different ways you can link your client to a schema:\n\n1. Use the Apollo [schema registry](/docs/platform/schema-registry.html)\n1. With a remote endpoint (from a running server)\n1. With a local schema file\n\n#### _Option 1_: Use the Apollo schema registry\n\nTo link your client to a schema through the Apollo schema registry, you'll need to have at least one version of your schema uploaded to the [registry](/docs/platform/schema-registry.html).\n\nWith Engine set up, you can point your client directly to your graph's schema by putting your graph's Engine ID in your Apollo config, like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    service: 'my-apollo-service' // the id of your service in Engine (from the URL)\n  }\n};\n```\n\n> **Note:** you must have a [registered schema](/docs/platform/schema-registry.html#publish) for features like VS Code intellisense, which requires knowledge of your schema, to work properly.\n\nIf you're tracking different versions of your schema in the registry using schema variants, you can link your client to a specific variant like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    service: 'my-apollo-service@staging' // \"staging\" is the schema variant we're using\n  }\n};\n```\n\nIf a schema variant is not specified, Apollo tools will fall back to the default value of `current`.\n\n#### _Option 2_: Link a schema from a remote endpoint\n\nRemote endpoints can be used to pull down a schema from a running service. This can be configured like so:\n\n```js line=3-11\nmodule.exports = {\n  client: {\n    service: {\n      name: 'github',\n      url: 'https://api.github.com/graphql',\n      // optional headers\n      headers: {\n        authorization: 'Bearer lkjfalkfjadkfjeopknavadf'\n      },\n      // optional disable SSL validation check\n      skipSSLValidation: true\n    }\n  }\n};\n```\n\n#### _Option 3_: Link a schema from a local file\n\nIn some cases you may have a locally generated file with your schema that you want to link. This can be either a `.graphql` file with the schema in SDL form or a saved introspection result in `.json`. To link your client project to a local schema file, configure it like so:\n\n```js line=3-6\nmodule.exports = {\n  client: {\n    service: {\n      name: 'my-service-name',\n      localSchemaFile: './path/to/schema.graphql'\n    }\n  }\n};\n```\n\n### `client.includes`\n\n_Optional_ –– by default, Apollo tools will look under a `./src` directory to find all operations and SDL to extract.\n\nClient projects often contain client-side schema definitions for local state with Apollo Client. To make sure the Apollo CLI and VS Code extension can find these files and read them correctly, you may need to tell Apollo which folders to look for your schema and queries in like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    includes: ['./imports/**/*.js'], // array of glob patterns\n    service: ...\n  },\n};\n```\n\n### `client.excludes`\n\n_Optional_ –– by default, Apollo tools will exclude `**/node_modules` and `**/__tests___` when looking for your queries and schema files.\n\nIf you want Apollo to ignore any of your other folders when looking for queries and schema definitions, adjust your config like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    excludes: ['**/__tests__/**/*'], // array of glob patterns\n    service: ...\n  },\n};\n```\n\n### `client.tagName`\n\n_Optional_ –– custom tagged template literal.\n\nWhen using GraphQL with JavaScript or TypeScript projects, it is common to use the `gql` tagged template literal to write out operations. Apollo tools will be looking through your files for the `gql` tag to extract your queries, so if you use a different template literal, you can configure it like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    tagName: \"graphql\",\n    service: ...\n  }\n};\n```\n\n### `client.addTypename`\n\n_Optional_ –– Apollo will by default add the `__typename` field to all your operations automatically and to all your generated types during codegen.\n\nGraphQL clients like Apollo Client often add the `__typename` field to operations automatically when they're sent over the wire. This can come in really handy for things like caching, but it can be turned off by adding `addTypename: false` to the client config:\n\n```js line=3\nmodule.exports = {\n  client: {\n    addTypename: false,\n    service: ...\n  }\n};\n```\n\n> **Note:** For consistency, we recommend that you keep this option consistent with how your `ApolloClient` is configured.\n\n### `client.clientOnlyDirectives`, `client.clientSchemaDirectives`\n\n_Optional_ –– By default, Apollo projects support the following client-side directives:\n\n- `@client` for local state\n- `@rest` for using apollo-link-rest\n- `@connection` for custom pagination with Apollo Client\n- `@type` for dynamic type names with apollo-link-rest\n\nClient side applications can use custom directives on their queries that aren't meant to be sent to the server. Configuration of client side directives beyond the defaults listed above can be set up like so:\n\n```js line=3-4\nmodule.exports = {\n  client: {\n    clientOnlyDirectives: [\"connection\", \"type\"],\n    clientSchemaDirectives: [\"client\", \"rest\"],\n    service: ...\n  }\n};\n```\n\n`clientOnlyDirectives` are directives that should be stripped out of the operation before being sent to the server. An example of this is the `@connection` directive.\n\n`clientSchemaDirectives` are directives that indicate a portion of the operation that is not meant to be sent to the server. These directives are removed as well as the fields they are placed on. An example of this type of directive is the `@client` directive.\n\n<h2 id=\"service-config\">Server projects</h2>\n\nServer projects are configured through a top level `service` key in the config.\n\n```js line=2\nmodule.exports = {\n  service: { ... },\n};\n```\n\nDefining a `service` key in your Apollo config will provide the CLI with the information it needs to perform commands like `apollo service:push` and `apollo service:check`. You can set up the schema for your service to load in one of two ways:\n\n1. Using a remote endpoint\n1. Using a local schema file\n\n<h4 id=\"service-remote-endpoint\">Option 1: Remote endpoint</h4>\n\nRemote endpoints can be used to pull down a schema from a running service. This can be configured like so:\n\n```js line=2-10\nmodule.exports = {\n  service: {\n    endpoint: {\n      url: 'https://api.github.com/graphql', // defaults to http://localhost:4000\n      headers: {\n        // optional\n        authorization: 'Bearer lkjfalkfjadkfjeopknavadf'\n      },\n      skipSSLValidation: true // optional, disables SSL validation check\n    }\n  }\n};\n```\n\n<h4 id=\"service-local-file\">Option 2: Local schema</h4>\n\nIn some cases you may have a locally generated file with your schema that you want to link. This can be either a `.graphql` file with the schema in SDL form or a saved introspection result in `.json`. To link your client project to a local schema file, configure it like so:\n\n```js line=3\nmodule.exports = {\n  service: {\n    localSchemaFile: './path/to/schema.graphql'\n  }\n};\n```\n","path":"/references/apollo-config","filePath":"docs/source/references/apollo-config.md"},{"title":"Turning on analytics","description":"Turn on metrics reporting to get performance and schema usage insights","content":"\nGraphQL offers a number of interesting insights in the realm of server performance and usage monitoring. Because the structure of GraphQL queries requires clients to request exactly the fields they need, simple instrumentation allows us to elicit exactly which fields in the schema are being used at any given time. This helps us understand how much usage different parts of our data model get at a far more granular level than we could achieve out of the box with non-GraphQL APIs.\n\n<h4>Tracing query execution</h4>\n\nA \"trace\" corresponds to exactly one [GraphQL operation](https://www.apollographql.com/docs/resources/graphql-glossary.html#operation) and represents a breakdown of timing and error information for each individual field resolved as part of that operation.\n\nBy recording which resolvers executed in our server and their traces, we can build a rich dataset. From it, we see exactly which query shapes are being run, who is sending them, which parts of the schema are most utilized, which resolvers in the server are bottlenecks, etc.\n\nWe've specifically built an interface to view this information into [Apollo Engine](https://engine.apollographql.com/) and any GraphQL server can report metrics to Engine by sending data in the `apollo-tracing` format to our metrics ingress. Read on to learn how to set this up in your environment.\n\n<h2 id=\"apollo-server\">Apollo Server</h2>\n\nApollo Server has had the ability to report its performance usage metrics to Engine built-in. To set it up, get an API key from [Engine](https://engine.apollographql.com/) by logging in and creating a graph. Then set your API key in the `ENGINE_API_KEY` environment variable or pass it into your Apollo Server constructor like so:\n\n```js line=6-8\nconst { ApolloServer } = require('apollo-server');\n\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  engine: {\n    apiKey: 'YOUR API KEY HERE'\n  }\n});\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀  Server ready at ${url}`);\n});\n```\n\nFor advanced configuration options to set up logging, error filtering, and client-aware metrics reporting take a look at our [server documentation](https://www.apollographql.com/docs/apollo-server/features/metrics.html).\n\n<h2 id=\"other-servers\">Other servers</h2>\n\nThere are 2 ways to send metrics data from your server to Engine:\n\n1. Report traces directly from your server to our reporting endpoint\n2. Use an Apollo tracing package and the Engine proxy (deprecated)\n\n### Engine reporting endpoint\n\nWe recommend following the agent pattern to report trace metrics from your server to the Engine reporting endpoint. This is what Apollo Server does internally and you can view the code for the [Apollo Server reference agent](https://github.com/apollographql/apollo-server/blob/3d6912434051ae7038153ef39e32f485a35609f0/packages/apollo-engine-reporting/src/agent.ts) as an example.\n\nWe've been working with our community to build agent integrations for non-JavaScript servers. If you're interested in collaborating with us on an integration for your server, please get in touch with us at <support@apollographql.com> or via our [Apollo Spectrum Community](https://spectrum.chat/apollo).\n\nThere are four steps to creating a reporting agent for any server:\n\n1. Translating execution information into the correct Tracing format\n2. Implementing a default signature function to identify operations\n3. Emitting batches of Traces to the reporting endpoint\n4. Providing plugins for more advanced reporting functionality\n\n<h3 id=\"tracing-format\">1. Tracing Format</h3>\n\nThe first step of creating a metrics reporting agent will be to hook into the GraphQL execution pipeline to create the metrics and translate them into the proper data format.\n\nThe reporting endpoint accepts a batch of \"traces\" encoded as protobuf. Each individual trace represents execution of a single operation, specifically timing and error information of that execution, broken down by field. Each trace also contains context that is operation-specific (e.g. which client an operation was sent from, if the response was fetched from the cache). In addition to the batch of trace details, the metrics report also includes the context within which all operations were executed (e.g. staging vs prod) in a report header.\n\nAs mentioned, this batch of traces and context is encoded via protobuf. The schema for the protobuf message is defined as the `FullTracesReport` message in the [TypeScript reference implementation](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting-protobuf/src/reports.proto#L380). The reporting agent is **not** responsible for aggregating this list of individual traces and filtering out certain traces to persist. That process is handled via Apollo's cloud services.\n\nAs a good starting point, we recommend implementing an extension to the GraphQL execution that creates a report with one trace, as defined in the `Trace` message of [the protobuf schema](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting-protobuf/src/reports.proto#L9). The next step will be to batch multiple traces into a single report, which we recommend batches of 5-10 seconds while limiting reports to a reasonable size (~4MB).\n\n> Many server runtimes already have support for emitting tracing information as a [GraphQL extension](https://github.com/apollographql/apollo-tracing), which involves hooking into the request pipeline and capturing timing and error data about each resolver's execution. These implementations include runtimes in [Node](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/extension.ts), [Ruby](https://github.com/uniiverse/apollo-tracing-ruby), [Scala](https://github.com/sangria-graphql/sangria-slowlog#apollo-tracing-extension), [Java](https://github.com/graphql-java/graphql-java/pull/577), [Elixir](https://github.com/sikanhe/apollo-tracing-elixir), and [.NET](https://graphql-dotnet.github.io/docs/getting-started/metrics/). If you're working on adding metrics reporting functionality for one of _these languages_, reading through that tracing instrumentation is a good place to start and to plug into. For _other languages_, we recommend reading through the [Apollo Server instrumentation](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/extension.ts) as reference.\n\nAn example of a FullTracesReport message, represented as JSON, can be found below\\*\n\n<h3 id=\"query-signature\">2. Operation Signing</h3>\n\nIn order to correctly group GraphQL operations, it's important to define a method for \"signing\" a query. Because GraphQL queries can be expressed in a variety of ways, this is a harder problem than it may\nappear to be at first thought. For instance, even though all of the following queries request the same\ninformation, it's ambiguous whether they should be treated equally.\n\n```gql\nquery AuthorForPost($foo: String!) {\n  post(id: $foo) {\n    author\n  }\n}\n\nquery AuthorForPost($bar: String!) {\n  post(id: $bar) {\n    author\n  }\n}\n\nquery AuthorForPost($foo: String!) {\n  post(id: $foo) {\n    author\n  }\n}\n\nquery AuthorForPost {\n  post(id: \"my-post-id\") {\n    author\n  }\n}\n\nquery AuthorForPost {\n  post(id: \"my-post-id\") {\n    writer: author\n  }\n}\n```\n\nEven though this concept lacks definition, it's important to decide on how queries should be grouped together when tracking metrics about GraphQL execution. The concept of a **\"query signature\"** is what we use at Apollo to group similar operations together even if their exact textual representations are not identical. The query signature, along with the operation name, are used to group queries together in the `FullTracesReport`.\n\nThe TypeScript reference implementation uses a default signature method and allows for that signature method to also be overridden by the user. The [implementation of the default](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/signature.ts) drops unused fragments and/or operations, hides String literals, ignores aliases, sorts the tree deterministically, and ignores whitespace differences. We recommend using the same default signature method for consistency across different server runtimes.\n\n<h3 id=\"sending-metrics\">3. Sending Metrics</h3>\n\nOnce a metrics report (i.e. batch of traces) is prepared, it will need to be sent to an ingress for aggregation and sampling. Currently, this is all performed in Apollo's cloud services. The endpoint for this aggregation and sampling is at `https://engine-report.apollodata.com/api/ingress/traces`, which supports the protobuf format mentioned above via a `POST` request. The reporting endpoint accepts a gzipped body as well. To see the full reference implementation, see the `sendReport()` method in the [TypeScript reference agent](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/agent.ts#L210).\n\nReporting agents can authenticate either via the `X-Api-Key` header or the `authtoken` cookie with the service API key.\n\nWe recommend implementing retries with backoff on 5xx responses and network errors and allowing for the batching size to be tunable by the user. Additionally, we recommend adding a shutdown hook to send all pending reports to ensure that healthy server shutdowns do not result in missing data, as this tracing information is especially important.\n\n> NOTE: In the future, we plan to release a local aggregation and sampling agent that could be used to lessen the bandwidth requirements on reporting agents.\n\n<h3 id=\"advanced-features\">4. [Optional] Advanced Reporting Features</h3>\n\nThe reference TypeScript implementation also includes several more advanced features which may be worth porting to new implementations. All of these features are implemented in the agent itself and are documented in the interface description for the EngineReportingOptions of [the agent](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/agent.ts#L51).\n\nFor example, the option to send reports immediately may be particularly useful to GraphQL servers running in a serverless environment, like AWS Lambda or Google Cloud Functions.\n\nAnother important feature is the ability to limit information sent, particularly to avoid reporting [personal data](https://en.wikipedia.org/wiki/Personal_data). Because the most common place for personal data to appear is in variables and headers, the TypeScript agent offers options for `privateVariables` and `privateHeaders`.\n\n<h3 id=\"traces-report-example\">Example FullTracesReport, represented as JSON</h3>\n\n```json\n{\n  \"header\": {\n    \"hostname\": \"www.example.com\",\n    \"schemaTag\": \"staging\",\n    \"schemaHash\": \"alskncka384u1923e8uino1289jncvo019n\"\n  },\n  \"tracesPerQuery\": {\n    \"# Foo\\nquery Foo { user { email } }\": {\n      \"trace\": [\n        {\n          \"endTime\": \"2018-11-25T18:28:36.604Z\",\n          \"startTime\": \"2018-11-25T18:28:36.104Z\",\n          \"clientName\": \"c1\",\n          \"clientVersion\": \"v1\",\n          \"http\": {\n            \"method\": \"POST\"\n          },\n          \"durationNs\": \"2498055950907169\",\n          \"root\": {\n            \"fieldName\": \"user\",\n            \"type\": \"User!\",\n            \"startTime\": \"1\",\n            \"endTime\": \"10\",\n            \"child\": [\n              {\n                \"fieldName\": \"email\",\n                \"type\": \"String!\",\n                \"startTime\": \"11\",\n                \"endTime\": \"12\",\n                \"parentType\": \"User\"\n              }\n            ],\n            \"parentType\": \"Query\"\n          }\n        },\n        {\n          \"endTime\": \"2018-11-25T18:28:37.004Z\",\n          \"startTime\": \"2018-11-25T18:28:36.404Z\",\n          \"clientName\": \"c2\",\n          \"clientVersion\": \"v1\",\n          \"http\": {\n            \"method\": \"POST\"\n          },\n          \"durationNs\": \"13154220\",\n          \"root\": {\n            \"fieldName\": \"user\",\n            \"type\": \"User!\",\n            \"startTime\": \"1\",\n            \"endTime\": \"10\",\n            \"child\": [\n              {\n                \"fieldName\": \"email\",\n                \"type\": \"String!\",\n                \"startTime\": \"13\",\n                \"endTime\": \"15\",\n                \"parentType\": \"User\"\n              }\n            ],\n            \"parentType\": \"Query\"\n          },\n          \"clientReferenceId\": \"c2_id\"\n        }\n      ]\n    }\n  }\n}\n```\n","path":"/references/setup-analytics","filePath":"docs/source/references/setup-analytics.md"},{"title":"Apollo Engine guide","description":"Account management, data privacy, GDPR compliance, and other information about Apollo Engine","content":"\n[Apollo Engine](https://engine.apollographql.com/) is our cloud service for schema management and performance metrics monitoring. Its foundation is built on a few types of data input from servers: publishing schema introspections, publishing operations from clients, and sending traces of request execution. From those data inputs we can provide rich schema usage insights, schema history management, schema change validation, operation safelisting, query usage insights, and more.\n\nEngine's core schema management features are all available in an unlimited capacity for free, and always will be. Engine's advanced features, like operation safelisting, schema change validation, resolver-level query tracing, longer data retention, and third-party integrations are available with subscriptions to the Apollo Team plan.\n\nMore information on pricing and billing can be found [here](https://www.apollographql.com/plans/).\n\n![The Apollo Engine Architecture](../img/apollo-engine/engine-architecture.png)\n\n<h2 id=\"accounts\">Accounts</h2>\n\nEngine accounts are authenticated using GitHub by default. We also offer single sign-on (SAML or OIDC) to our [Enterprise](https://www.apollographql.com/plans/) customers.\n\n<h3 id=\"team-collaboration\">Team collaboration</h3>\n\nEngine accounts mirror your GitHub organizations. The first time you log in, we create a personal Engine account for you with the same name as your GitHub username.\n\nThe Engine GitHub application asks for permission to read which GitHub organizations you’re in and their members and teams (but not code!). If you grant Engine permission to see an organization, we create an Engine account with the same name as that GitHub organization. All members of that organization on GitHub will be able to see the new account in Engine. This is how you create a shared team account in Engine.\n\nWhen you sign in to Engine, you will have access to all the teams where you're a member of the organization on GitHub. You can use the organization account picker to switch between accounts. If another member of a GitHub organization you belong to has already signed up the GitHub organization for Engine access, you’ll have access to that existing account.\n\nIf you’d like to work with additional team members and you are the admin of a GitHub organization, simply add them to your GitHub organization. If you aren’t an admin, have an admin add you to their GitHub organization.\n\n<h3 id=\"add-organization\">Adding an organization</h3>\n\nIf you’re looking for a GitHub organization that you’re a member of and don’t see it in Engine, it’s likely that Engine does not have read access for that organization.\n\nIf you want to add or remove an organization from Engine, you should manage those settings on GitHub. There, you will be able to Grant or Revoke access to Engine for organizations you can administer. For organizations you do not administer, you can\n\"Request\" access to Engine and the administrators will receive a request by E-mail.\n\n<h3 id=\"github-permissions\">GitHub permissions</h3>\n\nGitHub’s OAuth service is used for read-only information about organizations and users. Engine does not need access rights to your source code or to any other sensitive data in its login system.\n\nIf your Engine account is owned by a GitHub organization, then Engine will allow all members of that organization to access the account. As you add or remove team members from your Github org, Engine will know about that and accordingly update the authorization for those users.\n\n<!--\n######################################################################\nServices\n######################################################################\n-->\n\n<h2 id=\"services\">Graphs</h2>\n\nA _graph_ (formerly called _service_) in Engine represents a _project_ or _application_. When you create a new graph, we provide an API key used to send performance metrics and schema versions to our cloud service. This information is then accessible through the Engine interface.\n\n<h3 id=\"creating-services\">Creating a graph</h3>\n\nTo create a graph, you will need to select an account for that graph to belong to. All members of the account will be able to see the graph's data and settings options. You can transfer graphs between any of your Engine accounts by visiting its Settings page and change the “owner” to whichever account you’d like.\n\nGraphs in Engine have globally unique IDs. We recommend that you prefix your ID with the name of your company or organization to avoid naming collisions with other graphs in the system.\n\n<h3 id=\"environments\">Managing environments</h3>\n\nEach graph in Engine should represent a single application, and environments within your application should be tracked using [_variants_](https://www.apollographql.com/docs/platform/schema-registry.html#schema-tags). All metrics that your server reports to Engine and all schema versions that you register should be tagged with their environment, and you'll be able to filter and look at the data for individual variants within Engine.\n\n#### API keys\n\nAPI keys can be added and removed from a graph at any time. They are used to both send data to Engine (eg. server reporting configuration) and fetch information from Engine (eg. vs code extension configuration).\n\nYou can manage your API keys on your graph's settings page. It is recommended that you use one API key per function (eg. one key per data source) to have more granular control over how your Engine data is sent and accessed.\n\n<h2 id=\"data-privacy\">Data privacy</h2>\n\nAll data that is sent to Engine from your server can be configured and turned off to meet your data privacy needs. This section will walk through what information Engine sees about your GraphQL graph's requests, what Engine’s default behavior to handle request data is, and how you can configure Engine to the level of data privacy your team needs.\n\n<h3 id=\"architecture\">Architecture</h3>\n\nEngine is primarily a cloud service that ingests and stores performance metrics data from your server. There are two ways to get data into Engine:\n\n1. Use **Apollo Server 2** (Node servers) and configure performance metrics reporting by providing an Engine API key in your server configuration.\n2. Run the **Engine proxy** (deprecated) in front of your server and install an Apollo tracing package in your server.\n\n#### Apollo Server 2\n\nIf you’ve set up Engine metrics forwarding using Apollo Server 2, Apollo Server will automatically start tracing the execution your requests and forwarding that information to Engine. Engine uses this trace data to reconstruct both operation-level timing data for given query shapes and field-level timing data for your overall schema. This data will become available for you to explore in the Engine interface.\n\nApollo Server will never forward the responses of your requests to Engine, but it will forward the shape of your request, the time it took each resolver to execute for that request, and the variables and headers of the request (configurable, see below).\n\n#### Engine Proxy (deprecated)\n\nThis configuration option is primarily used to forward metrics to the Engine ingress from non-Node servers. The proxy is installed and run in your own environment on-prem as a separately hosted process that you route your client requests through.\n\nAs your clients make requests to your server, the proxy reads response extension data to make caching decisions and aggregates tracing and error information into reports that it sends to the Engine ingress.\n\nWhile the Engine proxy sees your client request data and service response data, it only collects and forwards data that goes into the reports you see in the Engine dashboards. All information sent by your on-premise proxy to the out-of-band Engine cloud service is configurable, and can be turned off through configuration options. Data is aggregated and sent approximately every 5 seconds.\n\n<h3 id=\"data-collection\">Data collection</h3>\n\nThis section describes which parts of your GraphQL HTTP requests are seen and collected by Engine.\n\n#### Query operation string\n\nBoth Apollo Server 2 and the Engine proxy report the full operation string of your request to the Engine cloud service. Because of this, you should be careful to put any sensitive data like passwords and personal data in the GraphQL variables object rather than in the operation string itself.\n\n#### Variables\n\nBoth Apollo Server 2 and the Engine proxy will report the query variables for each request to the Engine cloud service by default. This can be disabled in the following ways:\n\n- **Apollo Server 2** – use the privateVariables option in your Apollo Server configuration for Engine.\n- **Engine proxy** – use the privateVariables option in your proxy configuration, or prevent all variables from being reported with noTraceVariables option.\n\n#### Authorization & Cookie HTTP Headers\n\nEngine will **never** collect your application's `Authorization`, `Cookie`, or `Set-Cookie` headers and ignores these if received. Engine will collect all other headers from your request to show in the trace inspector unless turned off with these configurations:\n\n- **Apollo Server 2** – use the [`privateHeaders` option](https://www.apollographql.com/docs/apollo-server/api/apollo-server.html#EngineReportingOptions) in your Apollo Server configuration for Engine.\n- **Engine Proxy** – use the [`privateHeaders` option](./proxy-config.html#Reporting) in your proxy configuration.\n\nIf you perform authorization in another header (like `X-My-API-Key`), be sure to add this to `privateHeaders` configuration. Note that unlike headers in general, this configuration option **is** case-sensitive.\n\n<h3 id=\"response\">Response</h3>\n\nLet’s walk through Engine’s default behavior for reporting on fields in a typical GraphQL response:\n\n```\n// GraphQL Response\n{\n  \"data\": { ... },          // Never sent to the Engine cloud service\n  \"errors\": [ ... ],        // Sent to Engine, used to report on errors for operations and fields.\n  \"extensions\": {\n    \"tracing\": { ... },     // Sent to Engine, used to report on performance data for operations and fields.\n    \"cacheControl\": { ... } // Sent to Engine, used to determine cache policies and forward CDN cache headers.\n  }\n}\n```\n\n#### `response.data`\n\nNeither Apollo Server 2 nor the Engine proxy will ever send the contents of this to the Engine cloud service. The responses from your GraphQL service stay on-prem.\n\nIf you've configured whole query caching through the Engine proxy and Engine determines that a response it sees is cacheable, then the response will be stored in your [cache](https://www.apollographql.com/docs/apollo-server/features/caching#saving-full-responses-to-a-cache) (either in-memory in your proxy or as an external memcached you configure).\n\n#### `response.errors`\n\nIf either Apollo Server 2 or the Engine proxy sees a response with an `\"errors\"` field, they will read the `message` and `locations` fields if they exist and report them to the Engine cloud service.\n\nYou can disable reporting errors to the out-of-band Engine cloud service like so:\n\n- **Apollo Server 2** &mdash; enable the [`maskErrorDetails` option](/docs/apollo-server/api/apollo-server#EngineReportingOptions) to remove the messages and other details from error traces sent to Apollo's cloud service.\n- **Apollo Server 2** &mdash; specify a [`rewriteError` function](https://www.apollographql.com/docs/apollo-server/features/errors#for-apollo-engine-reporting) that filters or transforms your errors before they are sent to Apollo's cloud service. This can be used to strip sensitive data from errors or filter \"safe\" errors from Engine's reporting.\n- **Engine proxy** &mdash; use the [`noTraceErrors` option](./proxy-config.html#Reporting) to disable sending error traces to the Engine cloud service.\n\n#### Disable Reporting (Engine proxy)\n\nWe've added the option to disable reporting of proxy stats and response traces to the Engine cloud service so that integration tests can run without polluting production data.\n\nTo disable all reporting, use the [`disabled` option](./proxy-config.html#Reporting) for the Engine proxy.\n\n<!--\n######################################################################\nGDOR\n######################################################################\n-->\n\n<h2 id=\"gdpr\" title=\"GDPR\">GDPR</h2>\n\nEffective May 25, 2018, the General Data Protection Regulation (GDPR) expands European Union (EU) residents’ (Data Subjects) rights concerning their personal data. Meteor Development Group Inc. (“MDG” also dba Apollo) stands ready to assist our customers to become or remain compliant with GDPR after this crucial transition.\n\n#### What is GDPR?\n\nGDPR standardizes EU regulations and expands the rights of Data Subjects pertaining to personal data while expanding the definition of what constitutes personal data. GDPR provides Data Subjects with increased rights to control and delete their personal data, and it broadly prohibits the processing of special categories of personal data.\n\n#### How has Apollo prepared for GDPR?\n\nWe have been complying with GDPR since before it became enforceable on May 25, 2018. We are enhancing our products, processes, and procedures to meet our obligations as a data processor (Processor).\n\n#### How will GDPR affect the way companies use Apollo's products or services?\n\nOur products and services are not intended to be used for processing personal data. Our products and services are focused on software, systems, and applications - not individuals. If a customer wishes to set up a custom API, custom attribute, or custom event to track such data, it may do so. Our processing is data agnostic and automated, so all data is processed in the same way in accordance with a customer’s configuration. If, however, a customer believes that it has included personal data in the information processed by Apollo, we will assist the customer in meeting its obligations in accordance with the requirements of GDPR and the terms of our Data Processing Agreement.\n\n#### How can Apollo assist customers in meeting their obligations under GDPR?\n\nAs a Processor, we will assist customers in fulfilling their obligations as data controllers (Controllers) by:\n\n- supporting customers in complying with requests from Data Subjects\n- aggregating applicable personal data for customers replying to complaints from Data Subjects\n- replying to investigations and inquiries from supervisory authorities concerning processing activities on behalf of a customer\n- conducting Data Protection Impact Assessments\n\n#### How can Apollo help address requests from Data Subjects?\n\nApollo has implemented a process to intake, review, and fulfill customer requests arising from Data Subject Access Requests (DSAR) they receive. As a result of a DSAR, customers might request that Apollo securely delete or return the Data Subject’s personal data. Due to their sensitivity, such requests will be handled by Apollo on a case-by-case basis.\n\n#### Where can I learn more about Apollo's security and privacy policies?\n\nThe legal terms and policies that apply to Apollo's corporate websites and customer products or services are available at https://www.meteor.com/policy.\n\n#### Where can I get more help?\n\nIf you have any questions (including interest in a Data Processing Addendum or DPA), or encounter any issues, please reach out to <a href=\"https://engine.apollographql.com/support\">support</a>.\n\n<!--\n######################################################################\nPolicies and Agreements\n######################################################################\n-->\n\n<h2 id=\"policies\" title=\"Policies and Agreements\">Policies and Agreements</h2>\n\nTo learn about other ways that we protect your data, please read over our [Terms of Service](https://www.apollographql.com/policies/terms) and [Privacy Policy](https://www.apollographql.com/policies/privacy).\n","path":"/references/apollo-engine","filePath":"docs/source/references/apollo-engine.md"},{"title":"Apollo Engine proxy (deprecated)","description":"Configuring and running the Engine proxy","content":"\n> DEPRECATED: The engine proxy is not maintained, and to integrate with the Apollo platform's metrics, we recommend using Apollo Server's native reporting functionality. To integrate a non-Node server, take a look at our guide [here](./setup-analytics#other-servers).\n\n## Background\n\nThe Apollo Engine proxy is a small process that can be run in front of your GraphQL server. Its primary functions are:\n\n1. Sending **performance metrics** data from your server, which extends its responses with [`apollo-tracing`](https://github.com/apollographql/apollo-tracing) information, to the Engine cloud service.\n1. Proving a **full query caching** layer, which is controlled using the [`cacheControl`](https://github.com/apollographql/apollo-cache-control) directive and configured to be either in-memory or shared through Memcache.\n1. Automatically **persisting queries** through a caching layer that can map query IDs to full query strings, allowing clients to send just query IDs over the wire.\n\nThe proxy has been **deprecated since Apollo Server 2** was released. Apollo Server 2+ has [metrics reporting](https://www.apollographql.com/docs/apollo-server/features/metrics.html), [data source caching](https://www.apollographql.com/docs/apollo-server/features/data-sources.html), [persisted queries](/docs/apollo-server/features/apq), and [full query caching](https://github.com/apollographql/apollo-server/blob/release-2.5.0/docs/source/features/caching.md) (starting at Apollo Server 2.5) as built-in features, and using it allows you to forego running the proxy. The newest features in Apollo Engine are not supported in the Engine proxy and we recommend that all Node users use Apollo Server 2+ instead of running the proxy.\n\nThat said, the proxy is still a good option for getting set up with Engine in a few **specific** circumstances:\n\n1. You are not using Apollo Server, your server has an [`apollo-tracing`](https://github.com/apollographql/apollo-tracing) plugin, and you want to get **performance metrics** insights.\n1. You are not using Apollo Server and you want to use Apollo's **automatic persisted queries**.\n\n## Setup\n\nTo get started with using Engine through the Engine proxy, you will need to:\n\n1. [Install a package in your GraphQL server that adds `extension` data (in the Apollo Tracing format) to each request's response.](#Instrument-your-server)\n1. [Get your Engine API key.](#Get-your-API-key)\n1. [Configure and deploy the Engine proxy to run in front of your server using either Docker or npm.](#Run-the-proxy)\n\n### Instrument your server\n\nTo get the performance metrics value out of Engine, you'll need to install a package in your server that adds the `apollo-tracing` GraphQL extension. If you want to set up response caching, you'll also need to install a package that adds the `apollo-cache-control` extension.\n\n> **Note:** If you're installing the Engine proxy _just_ to set up automatic persisited queries, you can skip ahead to the [next section](#Get-your-API-key).\n\nThe `apollo-tracing` and `apollo-cache-control` extensions are open specifications that can be implemented by any GraphQL server, and the following is a list of implementations:\n\n1. **Node** with [Apollo Server](https://www.apollographql.com/docs/apollo-server/) natively supports tracing and cache control. See [Node setup instructions](#run-the-proxy) for a more streamlined Node setup option.\n1. **Ruby** with [GraphQL-Ruby](http://graphql-ruby.org/) supports tracing with the [apollo-tracing-ruby](https://github.com/uniiverse/apollo-tracing-ruby) gem.\n1. **Java** with [GraphQL-Java](https://github.com/graphql-java/graphql-java) natively supports tracing. [Read the docs about using Apollo tracing.](https://www.graphql-java.com/documentation/master/instrumentation/)\n1. **Scala** with [Sangria](https://github.com/sangria-graphql/sangria) supports tracing with [sangria-slowlog](https://github.com/sangria-graphql/sangria-slowlog#apollo-tracing-extension) project.\n1. **Elixir** with [Absinthe](https://github.com/absinthe-graphql/absinthe) supports tracing with the [apollo-tracing-elixir](https://github.com/sikanhe/apollo-tracing-elixir) package.\n\nYou can test that you’ve correctly enabled Apollo Tracing by running any query against your API using GraphiQL.\n\nThe `tracing` field should now be returned as part of the response's `extensions` like below. Don’t worry, this data won’t make it back to your clients once you've set up the Engine proxy, because the proxy will filter it out.\n\n```js line=3-5\n{\n  \"data\": { ... },\n  \"extensions\": {\n    \"tracing\": { ... }\n  }\n}\n```\n\n### Get your API key\n\n[Log into Apollo Engine](http://engine.apollographql.com/?_ga=2.233930590.1351805406.1542648368-1704540304.1492481658) and create a graph to get an API key. We’ll be using your new key in the next step.\n\n### Run the proxy\n\nThe proxy is a small process written in Go that you host and run inside your infrastructure. It's designed to allow all of your requests and responses to pass through normally while it collects trace data, caches results, and identifies persisted queries. It's designed to handle large volumes of traffic comfortably without overloading. It does not rely on accessing the Engine cloud service to run or perform caching functions, but if it cannot talk to the Engine cloud service it will not be able to report metrics.\n\nApollo distributes the Engine proxy in two forms: as an **npm package** and as a **Docker container**. You can use any one of the following options for running the proxy, depending what works best for you and your team:\n\n1. [Run the proxy with Apollo Server](#proxy-with-apollo-server)\n1. [Run a standalone proxy using Node](#standalone-proxy-with-node)\n1. [Run a standalone proxy using Docker](#standalone-proxy-with-docker)\n1. [Run the proxy through a Platform as a Service (eg. Heroku)](#platform-as-a-service)\n1. [Run the proxy in a serverless environment (eg. Lambda)](#serverless)\n\n<h4 style=\"position: relative;\">\n<span id=\"proxy-with-apollo-server\" style=\"position: absolute; top: -100px;\" ></span>\nOption 1: Running the proxy with Apollo Server\n</h4>\n\nThe two cases where you should be running the Engine proxy with Apollo Server are:\n\n1. You are using Apollo Server 1 and want the Apollo platform features that Engine brings.\n1. You are using Apollo Server >2 & <2.5+ and want full query caching using the Engine proxy.\n\n> **Note:** If you're using Apollo Server but neither of these conditions apply to you, you should be using the built-in features of Apollo Server 2+ instead of the Engine proxy.\n\nThis section assumes you're running your GraphQL server with the `express` web server package for Node, but if you're using a different framework the steps will be similar.\n\nFirst, install the `apollo-engine` package from npm:\n\n```bash\nnpm install --save apollo-engine\n```\n\nThen import the `ApolloEngine` constructor and create a new Engine instance. You'll need to replace `app.listen()` with `engine.listen()` like below:\n\n```js\n// Import ApolloEngine\nconst { ApolloEngine } = require('apollo-engine');\nconst { ApolloServer } = require('apollo-server-express');\nconst express = require('express');\n\n// Initialize Apollo Server\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n\n  // Make sure that tracing and cacheControl are both enabled\n  tracing: true,\n  cacheControl: true,\n\n  // By setting this to \"false\", we avoid using Apollo Server 2's\n  // integrated metric reporting and fall-back to using the Apollo\n  // Engine Proxy (running separately) for metric collection.\n  engine: false\n});\n\n// Initialize your Express app like usual\nconst app = express();\n\n// All of your GraphQL middleware goes here\nserver.applyMiddleware({ app });\n\n// Initialize engine with your API key. Alternatively,\n// set the ENGINE_API_KEY environment variable when you\n// run your program.\nconst engine = new ApolloEngine({\n  apiKey: 'API_KEY_HERE'\n});\n\n// Call engine.listen(...) instead of app.listen(port) as you usually would\nengine.listen({\n  port: 4000,\n  expressApp: app\n});\n```\n\nEngine is now wrapping your endpoint and processing your GraphQL requests and responses like normal. If you call your endpoint again, your requests will be routed through the Engine proxy to your server and back. If everything is working, you will no longer see `tracing` data in your responses because your Engine proxy is filtering and processing that information for you.\n\n<h4 style=\"position: relative;\">\n<span id=\"standalone-proxy-with-node\" style=\"position: absolute; top: -100px;\" ></span>\nOption 2: Running a standalone proxy using Node\n</h4>\n\nEven if your GraphQL server is not implemented with Node, you may find it easier to run a tiny Node program in your hosting environment than to run a Docker container. If so, this proxy deployment option is for you.\n\nThe `apollo-engine` npm package contains an `ApolloEngineLauncher` API, which simply runs the Engine proxy with a given configuration.\n\nFirst, install the `apollo-engine` package from npm:\n\n```bash\nnpm install --save apollo-engine\n```\n\nThen write a small Node program that uses it, like so:\n\n```js\nconst { ApolloEngineLauncher } = require('apollo-engine');\n\n// Define the Engine configuration.\nconst launcher = new ApolloEngineLauncher({\n  // Note: you can also provide this in the ENGINE_API_KEY environment variable.\n  apiKey: 'API_KEY_HERE',\n  origins: [\n    {\n      http: {\n        // The URL that the proxy should use to connect to your GraphQL server.\n        url: 'http://localhost:4000/api/graphql'\n      }\n    }\n  ],\n  // Tell the proxy which ports to listen to and which paths should\n  // be treated as GraphQL instead of transparently proxied as raw HTTP.\n  frontends: [\n    {\n      port: 3000, // default if left out: process.env.PORT\n      endpoints: ['/api/graphql'] // default if left out: /['/graphql]\n    }\n  ]\n});\n\n// Start the Proxy; crash on errors.\nlauncher.start().catch(err => {\n  throw err;\n});\n```\n\n> **Note:** Every deployment has its unique needs and we provide a variety of configuration options to fulfill them. For more configuration options, please see the [proxy config docs](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md).\n\n> **Note:** The argument to `new ApolloEngineLauncher()` is generally the same as the argument Node GraphQL users pass to `new ApolloEngine()`. The main differences are that you need to specify the origin's HTTP URL yourself with `new ApolloEngineLauncher()`, and the frontend `port` and `endpoints` are specified inside the constructor instead of as options to `listen()`.\n\nIf you run this program with Node, the proxy will start up and start accepting connections at http://localhost:3000. It will forward all requests to your server, which you told it is running on http://localhost:4000.\n\nIf you open up GraphiQL on http://localhost:3000, you'll notice that the `tracing` extension data is no longer in the result of your query. This is because Engine is consuming it! You can verify that everything is working correctly by checking the Engine UI for your new service and confirming that you see data in the Metrics section.\n\n<h4 style=\"position: relative;\">\n<span id=\"standalone-proxy-with-docker\" style=\"position: absolute; top: -100px;\" ></span>\nOption 3: Running a standalone proxy with Docker\n</h4>\n\nThe Engine proxy is also distributed as a Docker image that you can deploy and manage separate from your server. It does not matter where you choose to deploy and manage your proxy, though it's more efficient if your proxy is located on the same machine or network as your GraphQL server.\n\nThe Docker container distribution of Engine proxy is configured using a JSON `engine-config.json` configuration file, like so:\n\n```js\n{\n  \"apiKey\": \"API_KEY_HERE\",\n  \"origins\": [{\n    \"http\": {\n      \"url\": \"http://localhost:4000/api/graphql\"\n    }\n  }],\n  \"frontends\": [{\n    \"port\": 3000,\n    \"endpoints\": [\"/api/graphql\"]\n  }]\n}\n```\n\n> **Note:** Every deployment has its unique needs, and we provide a variety of configuration options to fulfill them. For example, if your origin GraphQL server is running in a virtual-hosted environment (e.g. Heroku, AWS), you may need to override the `Host` header sent to HTTP origins. For more details and instruction on configuration options, please see the [proxy config docs](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md).\n\nAs it is JSON file, all object keys must be quoted, and trailing commas and comments are not allowed. Any reference in our docs to options passed to `new ApolloEngine()` otherwise translates directly into the engine config file. Like with `ApolloEngineLauncher`, you need to specify your GraphQL server's origin http URL (or other origin type like [Lambda](./setup-lambda.html)) inside the config file, and you need to specify the frontend port and GraphQL paths inside the config file rather than separately (if you're not using the default values of `process.env.PORT` and `['/graphql']`).\n\nNext, make sure you have a working [Docker installation](https://docs.docker.com/engine/installation/) and type the following lines in your shell:\n\n```\n$ ENGINE_PORT=3000\n$ docker run --env \"ENGINE_CONFIG=$(cat engine-config.json)\" -p \"${ENGINE_PORT}:${ENGINE_PORT}\" gcr.io/mdg-public/engine:1.1\n```\n\n> **Note:** We use [semver](https://semver.org/) to name Engine Proxy release versions, and we release version 1.2.3 under the tags `1.2.3`, `1.2`, and `1`. If you want to pin to a precise version, use the `1.2.3` tag. If you'd like to take patch upgrades but not minor upgrades, use the `1.2` tag. If you'd like to take minor upgrades, use the `1` tag.\n\nThis will run the Engine Proxy via Docker, routing port 3000 inside the container to port 3000 outside the container. (You can also pass `--net=host` instead of the `-p 3000:3000` to just allow the Proxy direct access to your host's network.)\n\nThe Proxy should start up and accept connections at http://localhost:3000 and forward all requests to your server at http://localhost:4000. Load GraphiQL through Engine at http://localhost:3000/graphiql (or wherever you have configured your app to serve GraphiQL) and run any query. You should no longer see the `tracing` data in the result since Engine is now consuming it! Checking the Engine UI for your service, you should see data from the request you sent via GraphiQL come through in the metrics tab.\n\nYou can find the complete documentation for Engine configuration options on the [full API docs](./proxy-config.html) page, and some commonly-used fields worth knowing about are described in the [`new ApolloEngineLauncher()` docs](#api-apollo-engine-launcher).\n\n<h4 style=\"position: relative;\">\n<span id=\"platform-as-a-service\" style=\"position: absolute; top: -100px;\" ></span>\nOption 4: Running the proxy through a Platform as a Service (eg. Heroku)\n</h4>\n\nIt may be most convenient for you to run and host the Engine proxy outside your app's deployment altogether. If that is the case, automatically running the proxy on a Platform as a Service like Heroku might be the easiest option for you.\n\nWe have an example repository with a guide for [running the Engine proxy on Heroku](https://github.com/apollographql/engine-heroku-example) that you can follow along in. Like running a [standalone proxy with Docker](#standalone-proxy-with-docker), you'll need to configure your proxy with an `engine-config.json` file like so:\n\n```\n{\n  \"apiKey\": \"<ENGINE_API_KEY>\",\n  \"origins\": [\n    {\n      \"http\": {\n        \"url\": \"http://yourappname.herokuapp.com/graphql\",\n        \"overrideRequestHeaders\": {\n          \"Host\": \"yourappname.herokuapp.com\"\n        }\n      }\n    }\n  ],\n  \"frontends\": [\n    {\n      \"host\": \"0.0.0.0\",\n      \"port\": \"3000\",\n      \"graphqlPaths\": [\"/graphql\"]\n    }\n  ]\n}\n```\n\n> **Note:** For Virtual Hosted environments where the `PORT` is dynamically set in an environment variable named `$PORT`, you can leave out the `port` option. If your environment uses a different environment variable, you can name it with the `portFromEnv` option instead. For more details and instruction on configuration options, please see the [proxy config docs](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md).\n\nIt does not matter where you choose to deploy and manage your Engine proxy. We've built this guide for Heroku because they have an easy deployment mechanism for Docker containers, but we run our own Engine proxy on Amazon's [EC2 Container Service](https://aws.amazon.com/ecs/).\n\n<h4 style=\"position: relative;\">\n<span id=\"serverless\" style=\"position: absolute; top: -100px;\" ></span>\nOption 5: Running the proxy in a serverless environment (eg. Lambda)\n</h4>\n\nLast but not least, you may be wondering how to use Engine if you run your application in a serverless environment like Lamdba. If so, this is the guide for you!\n\n> **Note:** The best option for using Engine if you're running in a serverless environment is to use Apollo Server 2+ and its built-in reporting mechanism. Running the Engine proxy in serverless environments is tricky because the **proxy is stateful** and needs to be run separately from your cloud function.\n\nTo use Engine when running in serverless environments, we will need to configure and deploy the Engine proxy as a standalone docker container that is **separate** from your cloud function. The Engine proxy is stateful (it collects and aggregates your metrics across requests), and as such it should not be deployed with your cloud function, but separately.\n\nThe only available option for running the Engine proxy with cloud functions is to run the proxy in a standalone docker container. To do that, you can follow one of our guides here:\n\n1. [Run a standalone proxy using Node](#standalone-proxy-with-node)\n1. [Run a standalone proxy using Docker](#standalone-proxy-with-docker)\n1. [Run the proxy through a Platform as a Service (eg. Heroku)](#platform-as-a-service)\n\nThe proxy needs to be run separately from your function because it's responsible for capturing, aggregating, and sending to Engine the trace data from each Lamdba instance GraphQL response.\n\nThe main difference between setting up the proxy to work with cloud functions versus setting it up with a persistent server is in how you configure it. You'll want an `engine-config.json` that looks something like this:\n\n```\n{\n  \"apiKey\": \"<ENGINE_API_KEY>\",\n  \"origins\": [\n    {\n      \"lambda\": {\n          \"functionArn\":\"arn:aws:lambda:xxxxxxxxxxx:xxxxxxxxxxxx:function:xxxxxxxxxxxxxxxxxxx\",\n          \"awsAccessKeyId\":\"xxxxxxxxxxxxxxxxxxxx\",\n          \"awsSecretAccessKey\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n      }\n    }\n  ],\n  \"frontends\": [\n    {\n      \"host\": \"0.0.0.0\",\n      \"port\": 3001,\n      \"endpoints\": [\"/graphql\"]\n    }\n  ]\n}\n```\n\n> **Note:** This example is for AWS Lambda specifically, for which we have a special `origins` type. Other cloud functions are supported with the standard HTTP invocation, and for non-AWS cloud functions see [the standalone docs](#standalone-proxy-with-docker) for instructions on settup up the Engine proxy as a standalone API gateway to your cloud function. For full configuration details see [proxy config](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md)\n\nThe Engine proxy will invoke the Lambda function as if it was called from Amazon's [API Gateway](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-set-up-simple-proxy.html#api-gateway-simple-proxy-for-lambda-input-format), and the function should return a value suitable for [API Gateway](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-set-up-simple-proxy.html#api-gateway-simple-proxy-for-lambda-output-format).\n\nIf you've got a proxy running and successfully configured to talk to your cloud functions, then sending a request to it will invoke your function and return the response back to you. If everything is working, you should be able to visit the Metrics tab in the Engine UI and see data from the requests you're sending in the interface!\n\n## Feature configuration\n\nThe following proxy features require specific setup steps to get working.\n\n1. [Automatically **persisting** your queries](#automatic-persisted-queries)\n1. [**Caching** full query responses](#caching)\n1. [Integrating with your **CDN**](#cdn)\n1. [Using the Engine proxy with **query batching**](#query-batching)\n\n<h3 id=\"automatic-persisted-queries\">Automatic Persisted Queries (APQ)</h3>\n\nAutomatically persisting your queries is a performance technique in which you send a query hash to your server instead of the entire GraphQL query string. Your server keeps track of the map between these hashes and their full query strings and does the lookup on its end, saving you the bandwidth of sending the full query string over the wire.\n\nAn added benefit of using APQs with GraphQL is that it's an easy mechanism to transform your GraphQL POST requests into GET requests, allowing you to easily leverage any CDN infrastructure you may already have in place.\n\n> **Note:** Apollo Server 2 reduces the setup necessary to use automatic persisted queries, and these instructions are only necessary when using the Apollo Engine Proxy. To find out more visit the [Apollo Server](/docs/apollo-server/features/apq) docs.\n\nThe query registry that maps query hashes to query strings is stored in a user-configurable cache and read by the Engine proxy. This can either be an in-memory store (configured by default to be 50MB) within each Engine proxy instance, or an external, configurable [memcached](https://memcached.org/) store.\n\nTo use automatic persisted queries with the Engine proxy:\n\n- Use Engine proxy `v1.0.1` or newer.\n- If your GraphQL server is hosted on a different origin domain from where it will be accessed, setup the appropriate [CORS headers](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing) using the `overrideGraphqlResponseHeaders` object on the proxy's `frontend` configuration:\n\n  ```javascript\n  frontends: [{\n    overrideGraphqlResponseHeaders: {\n      'Access-Control-Allow-Origin': '*',\n    },\n  }],\n  ```\n\n- Configure your client to use APQs. If you're using Apollo Client, you can easily use [`apollo-link-persisted-queries`](https://github.com/apollographql/apollo-link-persisted-queries#automatic-persisted-queries) to set this up.\n  <!-- * Verify APQ is working properly using the [verification procedure] (// TODO(dman): get link to new article). -->\n  <!-- * Read [how it works] (// TODO(dman): get link to new article) for additional details. -->\n\nIf everything is set up correctly, you should see your client sending hashes insteady of query strings over the network, but receiving data as if it had sent a normal query.\n\n<h3 id=\"caching\">Caching</h3>\n\nTo bring caching to GraphQL we've developed [Apollo Cache Control](https://github.com/apollographql/apollo-cache-control), an open standard that allows servers to specify exactly which parts of a response can be cached and how long they can be cached for.\n\nWe've built a mechanism into the Engine proxy that allows it to read these \"cache hints\" that servers send along with their responses. It uses these hints to determine if the response can be cached, wether or not it should be cached for everyone or a specific user, and how long it can be cached for.\n\nThe Engine proxy computes a cache privacy level and expiration date by combining the data from all of the fields returned by the server for a particular request. It errs on the safe side, so shorter `maxAge` results override longer and `PRIVATE` scope overrides `PUBLIC`. A missing `maxAge` on a field will default to `0`, meaning that all fields in the result must have a `maxAge > 0` for the response to be cached at all.\n\nThe Engine proxy reads Apollo Cache Control extensions, caching whole query responses based on the computed cacheability of each new query. The Engine UI will visualize how each query was impacted by the cache policy set on it.\n\nThere are just a few steps to enable response caching in Engine proxy, and one of them is optional!\n\n1. [Extend your server's responses with `cacheControl` extensions.](#add-cache-extensions)\n1. [Annotate your schema and/or resolvers with cache control hints.](#annotate-your-responses)\n1. [Optional: Configure cache options in your Engine Proxy configuration.](#configure-cache-options)\n\n<h4 style=\"position: relative;\">\n<span id=\"add-cache-extensions\" style=\"position: absolute; top: -100px;\" ></span>\n1. Add `cacheControl` extensions to your sevrer\n</h4>\n\nIf you're using Apollo Server for your Node GraphQL server, the only server code change required is to add `cacheControl: true` to the options passed to your Apollo Server configuration.\n\n```js line=5,12\n// Apollo Server 2:\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  cacheControl: true\n});\n\n// Apollo Server 1.2 and onwards:\napp.use(\n  '/graphql',\n  bodyParser.json(),\n  graphqlExpress({\n    schema,\n    context: {},\n    cacheControl: true\n  })\n);\n```\n\nWe're working with the community to add support for Apollo Cache Control to non-Node GraphQL server libraries. Contact us at suppot@apollogrqphql.com if you're interested in joining the community to work on support for `express-graphql` or non-Node GraphQL servers.\n\n<h4 style=\"position: relative;\">\n<span id=\"annotate-your-responses\" style=\"position: absolute; top: -100px;\" ></span>\n2. Add cache hints to your responses\n</h4>\n\nNext we'll add some cache hints to our GarphQL responses. There are two ways to do this -- either dynamically in your resolvers or statically on your schema types and fields. Each `cacheControl` hint has two parameters:\n\n- The `maxAge` parameter defines the number of seconds that Engine Proxy should serve the cached response.\n- The `scope` parameter declares that a unique response should be cached for every user (`PRIVATE`) or a single response should be cached for all users (`PUBLIC`/default).\n\n**Interpreting `maxAge` for a query (how long the query can be cached for):**\n\nTo determine the expiration time of a particular query, the Engine proxy looks at all of the `maxAge` hints returned by the server, which have been set on a per-field basis, and picks the shortest.\n\nFor example, the following trace indicates a 4 minute (`maxAge = 240`) for one field and 1 min (`maxAge = 60`) for another. This means that the Engine proxy will use \"1 minute\" as the overall expiration time for the whole result. You can use the Trace view in the Engine UI to understand your cache hit rates and the overall `maxAge` for your queries:\n\n![Cache hints](../img/apollo-engine/cache-hints.png)\n\n> **Note:** If your query calls a type with a field referencing list of type objects, such as `[Post]` referencing `Author` in the `author` field, Engine will consider the `maxAge` of the `Author` type as well.\n\n**Setting cache scope for a query (public vs. private):**\n\nApollo Engine supports caching of personalized responses using the `scope: PRIVATE` cache hint. Private caching requires that Engine identify unique users, using the methods defined in the `sessionAuth` configuration section.\n\nEngine supports extracting users' identity from an HTTP header (specified in `header`), or an HTTP cookie (specified in `cookie`).\n\nFor security, Engine can be configured to verify the extracted identity before serving a cached response. This allows your service to verify the session is still valid and avoid replay attacks.\nThis verification is performed by HTTP request, to the URL specified in `tokenAuthUrl`.\n\nThe token auth URL will receive an HTTP POST containing: `{\"token\": \"AUTHENTICATION-TOKEN\"}`.\nIt should return an HTTP `200` response if the token is still considered valid.\nIt may optionally return a JSON body:\n\n- `{\"ttl\": 300}` to indicate the session token check can be cached for 300 seconds.\n- `{\"id\": \"alice\"}` to indicate an internal user ID that should be used for identification. By returning a persistent identifier such as a database key, Engine's cache can follow a user across sessions and devices.\n- `{\"ttl\": 600, \"id\": \"bob\"}` to combine both.\n\nAuthentication checks with `ttl>0` will be cached in a `store` named in `sessionAuth`, or in the default 50MB in-memory store.\n\n**Setting static cache hints in your schema:**\n\nCache hints can be added to your schema using directives on your types and fields. When executing your query, these hints will be added to the response and interpreted by Engine to compute a cache policy for the response.\n\nEngine sets cache TTL as the lowest `maxAge` in the query path.\n\n```graphql\ntype Post @cacheControl(maxAge: 240) {\n  id: Int!\n  title: String\n  author: Author\n  votes: Int @cacheControl(maxAge: 500)\n  readByCurrentUser: Boolean! @cacheControl(scope: PRIVATE)\n}\n\ntype Author @cacheControl(maxAge: 60) {\n  id: Int\n  firstName: String\n  lastName: String\n  posts: [Post]\n}\n```\n\nYou should receive cache control data in the `extensions` field of your response:\n\n```js\n\"cacheControl\": {\n  \"version\": 1,\n  \"hints\": [\n    {\n      \"path\": [\n        \"post\"\n      ],\n      \"maxAge\": 240\n    },\n    {\n      \"path\": [\n        \"post\",\n        \"votes\"\n      ],\n      \"maxAge\": 30\n    },\n    {\n      \"path\": [\n        \"post\",\n        \"readByCurrentUser\"\n      ],\n      \"scope\": \"PRIVATE\"\n    }\n  ]\n}\n```\n\nFor the above schema, there are a few ways to generate different TTLs depending on your query. Take the following examples:\n\n_Example 1_\n\n```graphql\nquery getPostsForAuthor {\n  Author {\n    posts\n  }\n}\n```\n\n`getPostsForAuthor` will have `maxAge` of 60 seconds, even though the `Post` object has `maxAge` of 240 seconds.\n\n_Example 2_\n\n```graphql\nquery getTitleForPost {\n  Post {\n    title\n  }\n}\n```\n\n`getTitleForPost` will have `maxAge` of 240 seconds (inherited from Post), even though the `title` field has no `maxAge` specified.\n\n_Example 3_\n\n```graphql\nquery getVotesForPost {\n  Post {\n    votes\n  }\n}\n```\n\n`getVotesForPost` will have `maxAge` of 240 seconds, even though the `votes` field has a higher `maxAge`.\n\n**Setting dynamic cache hints in your resolvers:**\n\nIf you'd like to add cache hints dynamically, you can use a programmatic API from within your resolvers.\n\n```js\nconst resolvers = {\n  Query: {\n    post: (_, { id }, _, { cacheControl }) => {\n      cacheControl.setCacheHint({ maxAge: 60 });\n      return find(posts, { id });\n    }\n  }\n}\n```\n\n**Setting a default `maxAge` for your whole schema:**\n\nThe power of cache hints comes from being able to set them precisely to different values on different types and fields based on your understanding of your implementation's semantics. But when getting started, you might just want to apply the same `maxAge` to most of your resolvers. You can specify a default max age when you set up `cacheControl` in your server. This max age will be applied to all resolvers which don't explicitly set `maxAge` via schema hints (including schema hints on the type that they return) or the programmatic API. You can override this for a particular resolver or type by setting `@cacheControl(maxAge: 0)`.\n\nJust like when you set `@cacheControl(maxAge: 5)` explicitly on a field or a type, data is considered to be public by default and the cache will be shared among all users of your site, so when using this option, be sure that you're really OK with creating a shared cache for all of your GraphQL queries. You can still override a specific type or resolver to use the private cache by setting `@cacheControl(scope: PRIVATE)`.\n\nFor example, for Express:\n\n```javascript\napp.use(\n  '/graphql',\n  bodyParser.json(),\n  graphqlExpress({\n    schema,\n    context: {},\n    tracing: true,\n    cacheControl: {\n      defaultMaxAge: 5\n    }\n  })\n);\n```\n\nSetting `defaultMaxAge` requires `apollo-server-*` 1.3.4 or newer.\n\n<h4 style=\"position: relative;\">\n<span id=\"configure-cache-options\" style=\"position: absolute; top: -100px;\" ></span>\n3. Optional: Configure cache options\n</h4>\n\nAs long as you're using a version of the Engine proxy that's greater than `1.0`, you won't have to configure anything to use public response caching. The proxy comes with a default 50MB in-memory cache. To enable private response caching or to configure details of how caching works, there are a few fields in the Engine configuration (ie, argument to `new ApolloServer`) that are relevant.\n\nHere is an example of changing the Engine config for caching `scope: PUBLIC` responses to use memcached instead of an in-memory cache.\nSince no `privateFullQueryStore` is provided, `scope: PRIVATE` responses will not be cached.\n\n```js\nconst engine = new ApolloEngine({\n  stores: [\n    {\n      memcache: {\n        url: ['localhost:4567']\n      }\n    }\n  ]\n  // ...\n});\n```\n\nBelow is an example of an Engine config for caching `scope: PUBLIC` and `scope: PRIVATE` responses, using the default (empty-string-named 50MB in-memory cache) for public responses and authorization tokens, and memcached for private responses.\nBy using a private response cache, we guarantee that a response affecting multiple users is never evicted for a response affecting only a single user.\n\n```js\nconst engine = new ApolloEngine({\n  stores: [\n    {\n      name: 'privateResponseMemcache',\n      memcache: {\n        url: ['localhost:4567']\n      }\n    }\n  ],\n  sessionAuth: {\n    header: 'Authorization',\n    tokenAuthUrl: 'https://auth.mycompany.com/engine-auth-check'\n  },\n  queryCache: {\n    privateFullQueryStore: 'privateResponseMemcache'\n    // By not mentioning publicFullQueryStore, we keep it enabled with\n    // the default empty-string-named in-memory store.\n  }\n  // ...\n});\n```\n\n**stores**\n\nStores is an array of places for Engine to store data such as: query responses, authentication checks, or persisted queries.\n\nEvery store must have a unique `name`. The empty string is a valid name; there is a default in-memory 50MB cache with the empty string for its name which is used for any caching feature if you don't specify a store name. You can specify the name of `\"disabled\"` to any caching feature to turn off that feature.\n\nEngine supports two types of stores:\n\n- `inMemory` stores provide a bounded LRU cache embedded within the Engine Proxy.\n  Since there's no external servers to configure, in-memory stores are the easiest to get started with.\n  Since there's no network overhead, in-memory stores are the fastest option.\n  However, if you're running multiple copies of Engine Proxy, their in-memory stores won't be shared --- a cache hit on one server may be a cache miss on another server.\n  In memory caches are wiped whenever Engine Proxy restarts.\n\n  The only configuration required for in memory stores is `cacheSize` --- an upper limit specified in bytes. It defaults to 50MB.\n\n- `memcache` stores use external [Memcached](https://memcached.org/) server(s) for persistence.\n  This provides a shared location for multiple copies of Engine Proxy to achieve the same cache hit rate.\n  This location is also not wiped across Engine Proxy restarts.\n\n  Memcache store configuration requires an array of addresses called `url`, for the memcached servers. (This name is misleading: the values are `host:port` without any URL scheme like `http://`.) All addresses must contain both host and port, even if using the default memcached port. The AWS Elasticache discovery protocol is not currently supported.\n  `keyPrefix` may also be specified, to allow multiple environments to share a memcached server (i.e. dev/staging/production).\n\nWe suggest developers start with an in-memory store, then upgrade to Memcached if the added deployment complexity is worth it for production.\nThis will give you much more control over memory usage and enable sharing the cache across multiple Engine proxy instances.\n\n**sessionAuth**\n\nThis is useful when you want to do per-session response caching with Engine. To be able to cache results for a particular user, Engine needs to know how to identify a logged-in user. In this example, we've configured it to look for an `Authorization` header, so private data will be stored with a key that's specific to the value of that header.\n\nYou can specify that the session ID is defined by either a header or a cookie. Optionally, you can specify a REST endpoint which the Engine Proxy can use to determine whether a given token is valid.\n\n**queryCache**\n\nThis maps the types of result caching Engine performs to the stores you've defined in the `stores` field.\nIn this case, we're sending public and private cached data to unique stores, so that responses affecting multiple users will never be evicted for responses affecting a single user.\n\nIf you leave `queryCache.publicFullQueryStore` blank, it will use the default 50MB in-memory cache. Set it to `\"disabled\"` to turn off the cache.\n\nIf you configure `sessionAuth` but leave `queryCache.privateFullQueryStore` blank, it will use the default 50MB in-memory cache. Set it to `\"disabled\"` to turn off the cache.\n\n#### Visualizing caching\n\nOne of the best parts about using caching via the Engine proxy is that you can easily see how it's working once you set it up. The Metrics views in the Engine UI show you exactly which responses are cached and which are not, so you can understand how caching is helping you make your server more performant. Here's what the Engine metrics charts look like when you have everything set up correctly:\n\n![Cache metrics charts](../img/apollo-engine/cache-metrics.png)\n\n#### How HTTP headers affect caching\n\nThe main way that your GraphQL server specifies cache behavior is through the `cacheControl` GraphQL extension, which is rendered in the body of a GraphQL response. However, Engine also understands and sets several caching-related HTTP headers.\n\n**HTTP headers interpreted by Engine**\n\nEngine will never decide to cache responses in its response cache unless you tell it to with the `cacheControl` GraphQL extension. However, Engine does observe some HTTP headers and can use them to restrict caching further than what the extension says. These headers include:\n\n- `Cache-Control` **response** header: If the `Cache-Control` response header contains `no-store`, `no-cache`, or `private`, Engine will not cache the response. If the `Cache-Control` response header contains `max-age` or `s-maxage` directives, then Engine will not cache any data for longer than the specified amount of time. (That is, data will be cached for the minimum of the header-provided `max-age` and the extension-provided `maxAge`.) `s-maxage` takes precedence over `max-age`.\n- `Cache-Control` **request** header: If the `Cache-Control` request header contains `no-cache`, Engine will not look in the cache for responses. If the `Cache-Control` request header contains `no-store`, Engine will not cache the response.\n- `Expires` response header: If the `Expires` response header is present, then Engine will not cache any data past the given date. The `Cache-Control` directives `s-maxage` and `max-age` take precedence over `Expires`.\n- `Vary` response header: If the `Vary` response header is present, then Engine will not return this response to any request whose headers named in the `Vary` header don't match the request that created this response. (For example, if a request had a `Accept-Language: de` header and the response had a `Vary: Accept-Language` header, then that response won't be returned from the cache to any response that does not also have a `Accept-Language: de` header.) Additionally, Engine uses a heuristic to store requests that have different values for headers that it suspects may show up in the response `Vary` header under different cache keys; currently that heuristic is that it assumes that any header that has ever shown up in a `Vary` header in a GraphQL response may be relevant.\n\n**HTTP headers set by Engine**\n\nWhen returning a GraphQL response which is eligible for the full-query cache (ie, all of the data has a non-zero `maxAge` set in the `cacheControl` GraphQL extension), Engine sets the `Cache-Control` header with a `max-age` directive equal to the minimum `maxAge` of all data in the response. If any of the data in the response has a `scope: PRIVATE` hint, the `Cache-Control` header will include the `private` directive; otherwise it will include the `public` directive. This header completely replaces any `Cache-Control` and `Expires` headers provided by your GraphQL server.\n\n<h3 id=\"cdn\">CDN integration</h3>\n\nMany high-traffic web services use content delivery networks (CDNs) such as [Cloudflare](https://www.cloudflare.com/), [Akamai](https://www.akamai.com/) or [Fastly](https://www.fastly.com/) to cache their content as close to their clients as possible.\n\n> Apollo Server 2 supports CDN integration out of the box and doesn't require the Engine Proxy. To learn how, read through the [guide on CDN integration](/docs/apollo-server/features/apq#cdn). For other server implementations, the Engine Proxy makes it straightforward to use CDNs with GraphQL queries whose responses can be cached while still passing more dynamic queries through to your GraphQL server.\n\nTo use the Engine proxy behind a CDN, you need to be able to tell the CDN which GraphQL responses it's allowed to cache and you need to make sure that your GraphQL requests arrive in a format that CDNs cache. Engine Proxy supports this by combining its [caching](#caching) and [automatic persisted queries](#automatic-persisted-queries) featues. This section explains the basic steps for setting up these features to work with CDNs; for more details on how to configure these features, see their respective sections.\n\n#### 1. Set up caching using Apollo Cache Contol\n\nYou'll need to follow the guide in the [caching](#caching) section to set up your server to extend its requests with cache hint extensions.\n\nOnce you have your server sending responses with cache hints in the `response.extensions` your Engine proxy will start serving the HTTP `Cache-Control` header on the _fully cacheable_ responses (any response containing only data with non-zero `maxAge` annotations). The header will refer to the minimum `maxAge` value across the whole response, and it will be `public` unless some of the data is tagged `scope: PRIVATE`. You should be able to observe this header in your browser's dev tools. The Engine proxy will also cache the responses in its own default public in-memory cache.\n\n#### 2. Set up automatic persisted queries\n\nAt this point, GraphQL requetss are still POST requests. Most CDNs will only cache GET requests, and GET requests generally work best if the URL is of a bounded size. To work with this, enable Apollo Engine Proxy's Automatic Persisted Queries (APQ) support. This allows clients to send short hashes instead of full queries, and you can configure it to use GET requests for those queries.\n\nTo do this, follow the steps in the [guide above](#automatic-persisted-queries). After completing the steps in that section of the guide, you should be able to observe queries being sent as `GET` requests with the appropriate `Cache-Control` response headers using your browser's developer tools.\n\n#### 3. Set up your CDN\n\nHow precisely this works relies upon which CDN you chose. Configure your CDN to send requests to your Engine proxy-powered GraphQL app. For some CDNs, you may need to specially configure your CDN to honor origin Cache-Control headers. For example, here is [Akamai's documentation on that setting](https://learn.akamai.com/en-us/webhelp/ion/oca/GUID-57C31126-F745-4FFB-AA92-6A5AAC36A8DA.html). If all is well, your cacheable queries should now be cached by your CDN! Note that requests served directly by your CDN will not show up in your Engine dashboard.\n\n<h3 id=\"query-batching\">Query batching</h3>\n\nQuery batching allows your client to batch multiple queries into one request. This means that if you render several view components within a short time interval, for example a navbar, sidebar, and content, and each of those do their own GraphQL query, the queries can be sent together in a single roundtrip.\n\nA batch of queries can be sent by simply sending a JSON-encoded array of queries in the request:\n\n```js\n[\n { \"query\": \"{\n  feed(limit: 2, type: NEW) {\n    postedBy {\n      login\n    }\n    repository {\n      name\n      owner {\n        login\n      }\n    }\n  }\n}\" },\n { \"query\": \"query CurrentUserForLayout {\n  currentUser {\n    __typename\n    avatar_url\n    login\n  }\n}\" }\n]\n```\n\nBatched requests to servers that don’t support batching fail without explicit code to handle batching, however the Engine proxy has batched request handling built-in.\n\nIf a batch of queries is sent, the batches are fractured by the Engine proxy and individual queries are sent to origins in parallel. Engine will wait for all the responses to complete and send a single response back to the client. The response will be an array of GraphQL results:\n\n```js\n[\n  {\n    data: {\n      feed: [\n        {\n          postedBy: {\n            login: 'AleksandraKaminska'\n          },\n          repository: {\n            name: 'GitHubApp',\n            owner: {\n              login: 'AleksandraKaminska'\n            }\n          }\n        },\n        {\n          postedBy: {\n            login: 'ashokhein'\n          },\n          repository: {\n            name: 'memeryde',\n            owner: {\n              login: 'ashokhein'\n            }\n          }\n        }\n      ]\n    }\n  },\n  {\n    data: {\n      currentUser: {\n        __typename: 'User',\n        avatar_url: 'https://avatars2.githubusercontent.com/u/11861843?v=4',\n        login: 'johannakate'\n      }\n    }\n  }\n];\n```\n\nIf your origin supports batching and you'd like to pass entire batches through instead of having the Engine proxy break them up, set `supportsBatch: true` within the origins section of the configuration:\n\n```js\nconst engine = new ApolloEngine({\n  apiKey: 'ENGINE_API_KEY',\n  origins: [\n    {\n      supportsBatch: true\n    }\n  ]\n});\n```\n\n#### Batching in Apollo Client with Engine\n\nApollo Client has built-in support for batching queries in your client application. To learn how to use query batching with Apollo Client, visit the in-depth guide on our package [`apollo-link-batch-http`](/docs/link/links/batch-http.html).\n\nIf you have questions, we're always available at support@apollographql.com.\n\n## Proxy configuration\n\nView our [full proxy configuration doc](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md) for information on every available configuration option for the Engine proxy.\n\n## Release notes\n\nView our [proxy release notes doc](https://github.com/apollographql/apollo/blob/master/docs/source/references/engine-proxy-release-notes.md) for documentation on each proxy version that's been released and a changelog of what that version contained.\n\n## Troubleshooting\n\n#### Check that your server is supported\n\nCheck that your server is one of the supported GraphQL servers listed [here](apollo-tracing.html).\n\nIf it is, please make sure you're running the [currently tested version](https://github.com/apollographql/apollo-engine-js/blob/master/package.json) of Apollo Server and your Node HTTP server package (Express, Connect, Hapi, Koa, etc), and the latest released versions of the Engine and Apollo packages.\n\nYou can enter the following into the commandline to see the latest package version, or look in `package.json`.\n\n```\n$ npm view apollo-engine version\n```\n\n#### Set debug logging levels for the Proxy\n\nSupport may request that you set the Engine Proxy logging level to DEBUG or higher. These logs will be part of your GraphQL server logs (if Proxy is deployed with the `ApolloEngine` Node API) or in the Proxy process logs (if Proxy is deployed standalone).\n\n```js\nconst engine = new ApolloEngine({\n  logging: {\n    level: 'DEBUG' // Engine Proxy logging level. DEBUG, INFO, WARN or ERROR\n  }\n});\n```\n\n#### Ensure you enabled Apollo Tracing\n\nTest that you enabled Apollo Tracing by checking if your GraphQL server returns trace extensions in GraphQL responses when not executed through Engine. If it does, it's is a sign that Apollo Tracing is properly configured.\n\n<h3 id=\"troubleshooting-faqs\">Troubleshooting FAQs</h3>\n\n#### I'm getting an error saying “The query failed!”, how do I fix it?\n\nThis may mean you need to upgrade an NPM package. Check that your package versions are all up-to-date. This also may mean a variety of other things. When this error is paired with a 503 error, the query did not receive an expected response.\n\n#### Why isn't data showing up in my dashboard?\n\nWe recommend double-checking that the Engine API key for the correct service is specified in the `ApolloEngine` constructor.\n\n#### How do I check that the Engine Proxy is up and running?\n\nThere is a health check URL at `[engine-frontend-url]/.well-known/apollo/engine-health`, which returns an HTTP status of 200 if the server is running.\n\n#### What is shown on the Engine Proxy logs?\n\nEach time the Engine proxy starts, you should see the following two lines in the logs indicating the Engine proxy is healthy:\n\n```\nINFO[0000] Started HTTP server.                          address=\"[::]:50485\"\nINFO[0000] Engine proxy started.                         version=2018.02-93-ge050c6b93\n```\n\nThese lines say what port Engine is listening on and the internal version number for the Proxy. If you don't want to see them, set the log level to 'WARN'\n\n```js\nconst engine = new ApolloEngine({\n  logging: {\n    level: 'WARN'\n  }\n});\n```\n\n<h3 id=\"get-support\">Submit a support ticket</h3>\n\nPlease include the following when submitting an issue to our support team:\n\n- Platform of GraphQL server\n- Are you using `new ApolloEngine`, `new ApolloEngineLauncher`, or the Docker container?\n- Engine configuration: arguments to `new ApolloEngine` or `new ApolloEngineLauncher`, or the JSON configuration file for the Docker container\n- Platform of GraphQL server\n- The query submitted and the full response\n\nSubmit your issue to support at apollographql.com or you can join us in [Apollo's Spectrum community](https://spectru.chat/apollo).\n","path":"/references/engine-proxy","filePath":"docs/source/references/engine-proxy.md"},{"content":"The versions given here are both for the [`apollo-engine` Node.js package](https://www.npmjs.com/package/apollo-engine) and the `gcr.io/mdg-public/engine` Docker container.\n\n<h3 id=\"v1.1.2\" title=\"v1.1.2\">1.1.2 - 2018-06-08</h3>\n\n* Fixes bug involving the X-Forwarded-For header not being set.\n* Simplified API for users of the `pipePath` argument in `engine.listen(...)` with the apollo-engine `npm` package. Now, rather than needing to explicitly specify the `pipePath` argument in the call, an string argument to `port` that begins with `\\\\.\\pipe\\` will result in listening on the specified named pipe. Thus, calls such as `engine.listen({pipePath: \"\\\\.\\pipe\\bar\", httpServer: foo})` can be replaced by `engine.listen({port: \"\\\\.\\pipe\\bar\", httpServer: foo})`, which should help users developing locally using TCP and deploying to servers using IISNode, such as Microsoft Azure.\n\n<h3 id=\"v1.1.1\" title=\"v1.1.1\">1.1.1 - 2018-05-07</h3>\n\n* The Engine Proxy now sanitizes invalid UTF-8 in HTTP headers and variables, fixing the error `Error reporting traces. error=\"POST https://engine-report.apollodata.com/api/ss/traces giving up after 6 attempts\"`\n* You may now use Engine with named pipes on Windows machines to support Node server deployments to Microsoft Azure. Instead of using the `port` argument in `engine.listen({port: process.env.PORT, httpServer: foo})`, you can now specify the `pipePath` argument to listen on a named pipe such as `engine.listen({pipePath: \"\\\\.\\pipe\\bar\", httpServer: foo})`. In Microsoft Azure, `process.env.PORT` is an acceptable input to `pipePath`.\n* The Engine Proxy now differentiates request timeouts from failed requests. This will remove the “Unable to communicate with backend” error and replace it with two errors: one for no response or refused connection, and one for request timeouts.\n* The Engine Proxy now sets the `X-Forwarded-For` header and does string appending to other `X-Forwarded-` headers if they are already set.\n\n<h3 id=\"v1.1.0\" title=\"v1.1.0\">1.1.0 - 2018-04-10</h3>\n\nBecause this is a minor release, if you are using Engine via the Docker container and have specified the `1.0` tag, you'll need to change to the `1.1` tag to upgrade to this release.\n\n* The Engine Proxy now supports serving HTTPS over TLS, including HTTP/2.\n* You may now set your API key with the environment variable `ENGINE_API_KEY` in addition to with the `apiKey` configuration option.\n* The Engine Proxy now sets the `X-Apollo-Engine` header on requests it proxies so that your origin GraphQL server can tell if it is running behind Engine. (This is primarily intended to improve diagnostics if Engine is misconfigured.)\n\n\n<h3 id=\"v1.0.6\" title=\"v1.0.6\">1.0.6 - 2018-04-06</h3>\n\n* New `reporting.noTraceErrors` option to disable sending error traces to Apollo servers. Use this if your error messages may contain [personal data](https://en.wikipedia.org/wiki/Personal_data). If you are interested in a more fine-grained way to configure this, contact <a href=\"https://engine.apollographql.com/support\">Apollo support</a>.\n* Fix problems running `ApolloEngine` when a corporate HTTP proxy is configured with an environment variable such as `$HTTP_PROXY`. (Specifically, make the default [`innerHost` option to `engine.listen`](../setup-node.html#api-engine.listen) actually be `127.0.0.1` as documented rather than the unspecified interface; the previously implemented default was unintentional as well as the cause of the corporate proxy bug.)\n\n<h3 id=\"v1.0.5\" title=\"v1.0.5\">1.0.5 - 2018-04-05</h3>\n\nThis release include a variety of changes related to caching.\n\n* The Engine Proxy now observes the `Vary` header in HTTP responses. See the new [documentation of cache header support](../proxy/guides.html#caching) for more details.\n* The Engine Proxy now explicitly requests that \"persisted query not found\" responses are not cached by CDNs or browsers. (Typically these responses are followed by the client informing Engine of the full matching query, so caching the not-found response was effectively cache poisoning.)\n* The Engine Proxy now includes `Cache-Control` headers on responses served from its cache, not just on responses it stores to its cache.\n* The Engine Proxy no longer uses a generic HTTP heuristic to generate a max age limit for responses with the HTTP header `Last-Modified` but no other HTTP-level max age specification. This was added accidentally in v1.0.4 and is not necessary given that we only cache data that explicitly requests it in the GraphQL extension.\n* The Engine Proxy now properly comma-separates fields in generated `Cache-Control` response headers.\n* The warning when trying to insert an oversized item into an in-memory cache is now more explicit about the size limit. (Items in the in-memory cache cannot be larger than approximately 1/1024 of the total cache size.)\n\n<h3 id=\"v1.0.4\" title=\"v1.0.4\">1.0.4 - 2018-03-23</h3>\n\n* The Engine Proxy now will compress responses to GraphQL queries by default if the client sends the standard HTTP `Accept-Encoding: gzip` header. You can disable this by passing `frontends: [{responseCompression: {disabled: true}}]` to the `ApolloEngine` constructor. (The Engine Proxy continues to accept compressed responses from your GraphQL origin by default as well.) Engine will never proactively compress responses to requests on non-GraphQL paths but will pass through any compression applied by the server it is proxying to.\n* The Engine Proxy has better support for HTTP caching headers:\n    * The Engine Proxy has a better parser for `Cache-Control` and similar headers sent by your GraphQL origin, which it can use to constrain the response's cache policy further than what the GraphQL `cacheControl` extension dictates. We still recommend that Engine users use the `cacheControl` GraphQL extension (if supported by your GraphQL server library) rather than HTTP caching headers so that your GraphQL server will be ready for partial query caching.\n    * The Engine Proxy now sets the `Cache-Control` header on cacheable GraphQL responses.\n    * The Engine Proxy now sets the `Age` header when serving responses from the query response cache.\n    * The Engine Proxy now respects the `Cache-Control: no-cache` HTTP header in client requests.\n* The Engine Proxy has more detailed logging about caching decisions when `logging.level` is set to `DEBUG`.\n* The Engine Proxy binary properly shuts down on the `SIGUSR2` signal (which is sent by the `nodemon` utility).\n* More details about GraphQL errors are included in traces sent to the Engine Service.\n* The `apollo-engine` npm package now includes all the dependencies needed to be included in a TypeScript project.\n\n<h3 id=\"v1.0.3\" title=\"v1.0.3\">1.0.3 - 2018-03-19</h3>\n\nThis version only has JS changes: the Docker container release is identical to 1.0.2.\n\n* `engine.listen()` and `launcher.start()` now register handlers for the `exit`, `uncaughtException`, `SIGINT`, `SIGTERM`, and `SIGUSR2` [events on `process`](https://nodejs.org/api/process.html#process_process_events) to kill the Engine Proxy process. You can customize the list of events with the new `processCleanupEvents` option.\n\n<h3 id=\"v1.0.2\" title=\"v1.0.2\">1.0.2 - 2018-03-14</h3>\n\n* Add `overrideGraphqlResponseHeaders` frontend configuration option. This option lets you set HTTP headers to be sent with all GraphQL HTTP responses. For now, this is required to avoid CORS errors if you use [persisted queries](./auto-persisted-queries.html) from clients from a different origin from your GraphQL (Engine) frontend.\n* Fix bug where certain malformed GraphQL requests were reported to Engine as having taken multiple millennia.\n* Improve support for `application/graphql` requests. We still recommend sending your requests as JSON, which is supported by more servers and supports variables, operation name, and client-to-server extension, but we now deal better with `application/graphql` requests if you send them.\n* Improve error handling when your GraphQL origin sends Engine an unsupported Content-Type.\n\n<h3 id=\"v1.0.1\" title=\"v1.0.1\">1.0.1 - 2018-03-07</h3>\n\nv1 of `apollo-engine` has a redesigned streamlined Node API called `ApolloEngine`. See [the 1.0 migration guide](./1.0-migration.html) for details on how to upgrade.  In addition to a simplified API and higher performance, the new API adds support for the Restify and Hapi v16 web frameworks, and it is easy to integrate with any Node web framework that works with `http.Server`.\n\nIf you aren't integrating with a Node GraphQL server but still find Node programs easier to run than Docker Containers, the `apollo-engine` npm module has a new API called `ApolloEngineLauncher` that allows you to run the Engine Proxy with arbitrary configuration without hooking into a Node GraphQL server.\n\nFeatures that used to depend on a caching store definition now are on by default, sharing a 50MB in-memory cache. Specifically:\n* The public full-query response cache is enabled by default. Only responses annotated with the `cache-control` extension are cached.\n* The private full-query response cache is enabled by default if `sessionAuth` is configured. Only responses annotated with the `cache-control` extension are cached.\n* Automatic persisted queries are on by default.\n* If `sessionAuth` is configured with a `tokenAuthUrl`, verifications are cached by default.\nIf you don't like these defaults, you can set each store name field to `\"disabled\"` to turn off the relevant feature. If you want to change the default cache size in bytes, add `stores: [{inMemory: {cacheSize: 123456}}]` to your Engine config (ie, the argument to `new ApolloEngine()`). If you want to change the default cache to memcached, add `stores: [{memcache: {url: [\"localhost:1234\"]}}]` to your Engine config.\n\nStarting with v1, the Docker container releases use the same version numbers as the `apollo-engine` npm releases. The following changes are mostly relevant to users of the Docker container:\n* It's valid to specify zero frontends. Engine Proxy will default to one with all default values.\n* The deprecated `endpoint` field is removed from `frontends` configuration. Put your endpoint (GraphQL URL path) in a list in `endpoints` instead, or continue to let `apollo-engine` set it for you.\n* The `endpoints` field on frontends now defaults to `[\"/graphql\"]` instead of being required.\n* The header secret feature (required so that double proxying middleware could tell if it's seeing the request for the first or second time) is removed. This was intended only for internal use by `apollo-engine`.\n* If you configure a frontend endpoint as `/graphql`, requests to `/graphql/` should be served also. (The `apollo-engine` `Engine` wrapper previously implemented this; now it is implemented natively inside the Engine Proxy.)\n* A bug that could lead to the warning `Encountered trace without end time. This is a bug in Engine proxy.` has been fixed.\n\n\n(v1.0.0 was a mistakenly published empty package from the beginning of apollo-engine's development. Do not use v1.0.0 --- go directly to v1.0.1!)\n\n\n<h3 id=\"v0.9.1\" title=\"v0.9.1\">0.9.1 - 2018-03-01</h3>\n\n* The `prettier` package was accidentally added as a dependency rather than a dev-only dependency in 0.9.0. It is now in devDependencies.\n\n<h3 id=\"v0.9.0\" title=\"v0.9.0\">0.9.0 - 2018-03-01</h3>\n\nSimplify how the apollo-engine npm module communicates with the Engine Proxy binary.  Backwards-incompatible changes:\n  - The `logger` option to `new Engine` added in 0.8.9 no longer exists. It is replaced by `proxyStdoutStream` and `proxyStderrStream` options, as well as a `restarting` event on the `Engine` object.\n  - The default log style is now the same as in the Docker container release of Engine Proxy: textual logs over stdout, instead of JSON over stderr.\n* Unknown fields in the Engine config file (or `engineConfig` option to `new Engine`) and unknown options passed to `new Engine` now result in an error.\n* Added support for receiving client-provided GraphQL extensions such as `persistedQuery` over GET requests. To use GET requests (with or without persisted queries), we recommend you upgrade to [`apollo-link-http` 1.5.0](https://www.npmjs.com/package/apollo-link-http) and pass `useGETForQueries: true` to `createHttpLink` in your client code.\n* Add support for proxying non-GraphQL requests with Lambda origins. This allows serving GraphiQL directly from a Lambda handler.\nNo additional configuration is required to start using this feature.\n* Added the ability to define the frontend port (the port Engine proxy will listen on) from an environment variable.\n  To define the frontend port via the environment, remove `\"port\": 1234,` from the frontend configuration, and add `\"portFromEnv\": \"MY_PORT_VARIABLE\"`.\n  This will cause the proxy to read the `MY_PORT_VARIABLE` environment variable.\n  Heroku users in particular should set `\"portFromEnv\": \"PORT\"`.\n* Improve error messages for GraphQL request parse failures and for several common configuration problems.\n* Bugfix to automatic config reloading.\n\n<h3 id=\"v0.8.10\" title=\"v0.8.10\">0.8.10 - 2018-02-12</h3>\n\n* Added support for GZIP content encoding for responses from Lambda origins.\n* Added support for function qualifiers for Lambda origins.\n* Allows per-endpoint origin specification on frontends via `endpointMap`, a &lt;string,string&gt; map from endpoint path to `originName`. Users can use this field instead of `endpoints` and `originName` to route different URL paths on a frontend to serve different origins. If `endpointMap` is set, the Proxy will return a 404 error to HTTP requests sent to paths that don't match one of its keys. The proxy will also verify that only one of `endpoint` [deprecated], `endpoints`, and `endpointMap` are set.\n\t* For example, if you have two origins with names `[adminOrigin, userOrigin]` and want to forward requests to `/admin` and `/user` respectively, on the `Frontend` config, specify `\"endpointMap\": {\"/admin\":\"adminOrigin\", \"/user\":\"userOrigin\"}` and do not specify `endpoint` or `endpoints`.\n* Fixed a bug where all custom extensions were assumed to be maps.\n\n<h3 id=\"v0.8.9\" title=\"v0.8.9\">0.8.9 - 2018-02-06</h3>\n\n* Fixed a bug where `Host` header was still not forwarded to origin servers if present.\n* Exposed stats field to better track Engine proxy memory usage.\n* Properly forward the Host header to the Engine Proxy.\n* New `logger` option to override some aspects of logging in apollo-engine. (Removed in 0.9.0.)\n* Do not override http origin url if set.\n* Allow endpoint to end with '/' or '\\'.\n\n### 2018.01-54-gce490265c - 2018-01-31\n\n* Fixed a bug where the `Host` header was not forwarded to origin servers. If the `Host` header is present, it will also be sent in the `X-Forwarded-Host` header. Both of these header values can be overridden via the field mentioned below.\n* Added the ability for users to override which headers are sent to their GraphQL origin. Users can do this by specifying the `overrideRequestHeaders` field in `origin.http` in the Engine config object. By default Engine will forward all header values it receives to the origin server. This field is only for users that want to override the default behavior.\n  * For example, to override the `Host` header which may need to be done when deploying Engine inside of a PaaS (such as Heroku) follow instructions [here](../setup-virtual.html).\n\n### 2018.01-43-g1747440e6 - 2018-01-29\n\n* Fixed an issue where Engine proxy would cache responses that set a cookie, causing cache hits to set the same cookie.\n  Engine proxy now skips cache for:\n    * Responses with a `Set-Cookie` header.\n    * Responses with a `WWW-Authenticate` header.\n    * Responses with a `Cache-Control` header value of: `no-cache` ,`no-store` or `private`.\n    * Responses with an `Expires` header of `0`, or any date in the past.\n* Fixed several issues with timestamps included in reports sent to engine backend.\n* Added the ability to dump stacktraces of all running threads when Engine proxy receives a `SIGUSR2` signal.\n  When requested, traces are dumped to stderr. This should not be necessary unless requested by Apollo support.\n* Added the ability to collect performance data from Engine proxy using [Go pprof profiler](https://golang.org/pkg/net/http/pprof/).\n  To enable the pprof server, add `\"debugServer\": {\"port\": 1234}` to your engine configuration.\n  Note that the pprof server offers no security, so a firewall etc is required if running in production.\n  Enabling the debug server should not be necessary unless requested by Apollo support.\n\n### 2018.01-17-g9c203510f - 2018-01-16\n\n* Fixed an issue where a data race could cause the proxy to crash.\n\n### 2018.01-1-gc024df504 - 2018-01-04\n\n* Added a flag to disable certificate validation when communicating with HTTPS origins.\n  To disable certificate validation, set `disableCertificateCheck: true` within the `http` section of the origin's configuration.\n  This is strongly discouraged, as it leaves Engine vulnerable to man-in-the-middle attacks. It is intended for testing only.\n\n* Added a flag to use custom certificate authorities when communicating with HTTPS origins.\n  To use custom certificate authorities, set: `trustedCertificates: /etc/ssl/cert.pem` (or another file path) within the `http` section of the origin's configuration.\n  CA certificates must be PEM encoded. Multiple certificates can be included in the same file.\n\n### 2017.12-45-g12ba029f9 - 2017-12-20\n\n* Added support for multiple endpoints per origin through a new `endpoints` setting, deprecated the previous `endpoint` setting.\n* Added a health check URL at `/.well-known/apollo/engine-health`, currently returning HTTP status 200 unconditionally.\n* Fixed an issue where reports would always be sent on shut down, even when reporting was disabled.\n* Fixed issues with reloading of `frontend`s, and dependencies like logging and caches.\n\n### 2017.12-28-gcc16cbea7 - 2017-12-12\n\n* Added a flag to disable compression when communicating with HTTP origins.\n  To disable compression, set `disableCompression: true` within the `http` section of the origin's configuration.\n* Exposed the maximum number of idle connections to keep open between engine an an HTTP origin.\n  To tune the maximum number of idle connections, set `maxIdleConnections: 1234` within the `http` section of the origin's configuration.\n  If no value is provided, the default is 100.\n* Fixed an issue where Engine would return an empty query duration on internal error.\n* Fixed an issue where Engine would return an empty query duration on cache hit.\n* Fixed an issue where configuration reloading would not affect cache stores.\n* Reduced the overhead of reporting while it is disabled.\n* Added support for GraphQL `\"\"\"block strings\"\"\"`.\n* *Breaking*: Added `name` field to origin configurations. Every defined origin must have a unique name (the empty string is OK).\n  This only affects configurations with multiple origins, which should be rare.\n\n### 2017.11-137-g908dbec6f - 2017-12-05\n\n* Improved persisted query handling so that cache misses are not treated like other GraphQL errors.\n* Fixed an issue where GraphQL query extensions (like `persistedQuery`) would be forwarded to the origin server. This caused issues with origins other than Apollo Server.\n\n### 2017.11-121-g2a0310e1b - 2017-11-30\n\n* Improved performance when reverse proxying non-GraphQL requests.\n* Removed `-restart=true` flag, which spawned and managed a child proxy process. This was only used by the `apollo-engine` Node.js package.\n* Added POSIX signal processing:\n  * On `SIGHUP`, reload configuration. Configurations provided through `STDIN` ignore `SIGHUP`.\n  * On `SIGTERM`, or `SIGINT`, attempt to send final stats and traces  before gracefully shutting down.\n* Added the ability to prevent certain GraphQL variables, by name, from being forwarded to Apollo Engine servers. The proxy replaces these variables with the string `(redacted)` in traces, so their presence can be verified but the value is not transmitted.\n\n  To blacklist GraphQL variables `password` and `secret`, add: `\"privateVariables\": [\"password\", \"secret\"]` within the `reporting` section of the configuration. There are no default private variables.\n* Added the option to disable reporting of stats and traces to Apollo servers, so that integration tests can run without polluting production data.\n\n To disable reporting, add `\"disabled\": true` within the `reporting` section of the configuration. Reporting is enabled by default.\n* Added the ability to forward log output to `STDOUT`, `STDERR`, or a file path. Previously logging was always sent to `STDERR`.\n\n To change log output, add `\"destination\": \"STDOUT\"` within the `logging` section of the configuration.\n Like query/request loggings, rotation of file logs is out of scope.\n* Fixed an issue where `Content-Type` values with parameters (e.g. `application/json;charset=utf=8`) would bypass GraphQL instrumentation.\n* Added support for the Automatic Persisted Queries protocol.\n\n### 2017.11-84-gb299b9188 - 2017-11-20\n\n* Fixed GraphQL parsing bugs that prevented handling requests containing list literals and object literals.\n* Added the ability for the proxy to output JSON formatted logs.\n* Fixed a bug with reverse proxying to HTTPS origins.\n\n### 2017.11-59-g4ff40ec30 - 2017-11-14\n\n* Fixed passing through custom fields on GraphQL errors.\n\n### 2017.11-40-g9585bfc6 - 2017-11-09\n\n* Fixed a bug where query parameters would be dropped from requests forwarded to origins.\n\n* Added the ability to send reports through an HTTP or SOCKS5 proxy.\n\n  To enable reporting through a proxy, set `\"proxyUrl\": \"http://192.168.1.1:3128\"` within the `reporting` section of the configuration.\n\n* Added support for transport level batching, like [apollo-link-batch-http](https://github.com/apollographql/apollo-link/tree/master/packages/apollo-link-batch-http).\n\n  By default, query batches are fractured by the proxy and individual queries are sent to origins, in parallel.\n  If your origin supports batching and you'd like to pass entire batches through, set `\"supportsBatch\": true` within the `origins` section of the configuration.\n\n* *BREAKING*: Changed behaviour when the proxy receives a non-GraphQL response from an origin server.\n  Previously the proxy would serve the non-GraphQL response, now it returns a valid GraphQL error indicating that the origin failed to respond.\n\n* Added support for the `includeInResponse` query extension. This allows clients to request GraphQL response extensions be forwarded through the proxy.\n\n  To instruct the proxy to strip extensions, set: `\"extensions\": { \"strip\": [\"cacheControl\", \"tracing\", \"myAwesomeExtension\"] }` within the `frontends` section of the configuration.\n  By default, Apollo extensions: `cacheControl` and `tracing` are stripped.\n\n  Stripped extensions may still be returned if the client requests them via the `includeInResponse` query extension.\n  To instruct the proxy to _never_ return extensions, set `\"extensions\": { \"blacklist\": [\"tracing\",\"mySecretExtension\"] }` within the `frontends` section of the configuration.\n  By default, the Apollo tracing extension: `tracing` is blacklisted.\n\n* *BREAKING*: Fixed a bug where literals in a query were ignored by query cache lookup. This change invalidates the current query cache.\n\n* Fixed a bug where the `X-Engine-From` header was not set in non-GraphQL requests forwarded to origins. This could result in an infinite request loop in the Node.js `apollo-engine` package.\n\n### 2017.10-431-gdc135a5d - 2017-10-26\n\n* Fixed an issue with per-type stats reporting.\n\n### 2017.10-425-gdd4873ae - 2017-10-26\n\n* Removed empty values in the request to server: `operationName`, `extensions`.\n* Improved error message when handling a request with GraphQL batching. Batching is still not supported at this time.\n\n\n### 2017.10-408-g497e1410\n\n* Removed limit on HTTP responses from origin server.\n* Fixed issue where the `apollo-engine` Node.js package would fail to clean up sidecar processes.\n* Switched query cache compression from LZ4 to Snappy.\n* *BREAKING*: Renamed the `logcfg` configuration section to `logging`.\n* *BREAKING*: Nested HTTP/Lambda origin configurations under child objects: `http` and `lambda`.\n* Added HTTP request logging, and GraphQL query logging options.\n\nThese changes mean that a basic configuration like:\n\n```\n{\n  \"apiKey\": \"<ENGINE_API_KEY>\",\n  \"logcfg\": {\n    \"level\": \"INFO\"\n  },\n  \"origins\": [\n    {\n      \"url\": \"http://localhost:3000/graphql\"\n    }\n  ],\n  \"frontends\": [\n    {\n      \"host\": \"127.0.0.1\",\n      \"port\": 3001,\n      \"endpoint\": \"/graphql\"\n    }\n  ]\n}\n```\n\nIs updated to:\n\n```\n{\n  \"apiKey\": \"<ENGINE_API_KEY>\",\n  \"logging\": {\n    \"level\": \"INFO\"\n  },\n  \"origins\": [\n    {\n      \"http\": {\n        \"url\": \"http://localhost:3000/graphql\"\n      }\n    }\n  ],\n  \"frontends\": [\n    {\n      \"host\": \"127.0.0.1\",\n      \"port\": 3001,\n      \"endpoint\": \"/graphql\"\n    }\n  ]\n}\n```\n\n### 2017.10-376-g0e29d5d5\n\n* Added (debug) log message to indicate if a query's trace was selected for reporting.\n* Fixed an issue where non-GraphQL errors (i.e. a `500` response with an HTML error page) would not be tracked as errors.\n","path":"/references/engine-proxy-release-notes","filePath":"docs/source/references/engine-proxy-release-notes.md"}]}],"localImages":{"assets/apollo-server.svg":"/static/apollo-server-ee7fbac9c0ca5b1dd6aef886bb695e63.svg","assets/engine-architecture.svg":"/static/engine-architecture-ba7f2c7ee5be9bb5011188ae29007476.svg","images/docs.svg":"/static/docs-b59a474b2fb0570c902833d93e1a625e.svg","images/fundamentals.svg":"/static/fundamentals-751b435fd96db75c65a162287342bf53.svg","images/guides.svg":"/static/guides-250d2bc5365d186c839942b48b352672.svg","images/index-get-started.svg":"/static/index-get-started-7a10feb59626e9bdc13c9db39cb43054.svg","images/manual.svg":"/static/manual-06178e29fd1a2c9d88d1a9afe28ead35.svg","images/persistedQueries.optPath.png":"/static/persistedQueries.optPath-98cb0f1ed777fbd3fb0d0701e41d5dee.png","img/account.billing.nav.png":"/static/account.billing.nav-c43fb1d50ab5f7e7c0676d14d09b27d6.png","img/engine-architecture.svg":"/static/engine-architecture-ba7f2c7ee5be9bb5011188ae29007476.svg","img/error.png":"/static/error-432f8f7802eae8a87ca41c8c4d309f8e.png","img/index-get-started.svg":"/static/index-get-started-7a10feb59626e9bdc13c9db39cb43054.svg","img/histogram.png":"/static/histogram-31340e74eb1d52d92a612fbcbcff729d.png","img/slack-setup-confirm.png":"/static/slack-setup-confirm-40b7285953993955a39fdbc6ba0f4d22.png","img/volume.png":"/static/volume-a031c5697c3702a32ba95acb78ef0858.png","img/integrations/slack-notification.png":"/static/slack-notification-4da2300985e218ab800eff749821c818.png","img/datadog/settings-link.png":"/static/settings-link-d7e922341e9e14e2dc77e8a886ad765a.png","img/apollo-engine/cache-hints.png":"/static/cache-hints-0255104ff1ad6edf5cbcd3fe4664532d.png","img/schema-validation/github-check.png":"/static/github-check-4a4238da8832c31605332a6a09ebd4b5.png","img/schema-validation/multi-github-check.png":"/static/multi-github-check-e095bc0eba1f4209a1df51b3cf3ce607.png","img/schema-history/schema-history.png":"/static/schema-history-4754f1046e1cbd09cfb0e694c478082a.png","img/setup-heroku/new-app.png":"/static/new-app-1a4fb1220072c0d2cc6eee851bcabd17.png","img/setup-heroku/create-app.png":"/static/create-app-4a2f86876c44baf7e8936fe595a6167b.png","assets/engine-field.png":"/static/engine-field-9bf148b0832c045767097b6cc5f2a6cf.png","images/graph-layer.png":"/static/graph-layer-6b46e9923358fe9219f762b94c58b45c.png","images/persistedQueries.newPath.png":"/static/persistedQueries.newPath-d500b543a6ad2a7d64ed7f190d40bd8c.png","img/heatmap.png":"/static/heatmap-831e22ea8e750bc7e3043215a20e078a.png","img/persistedQueries.optPath.png":"/static/persistedQueries.optPath-c39bec130a41f81c74391671a9c59074.png","img/persistedQueries.newPath.png":"/static/persistedQueries.newPath-ef211d56355771770478c10917a0901b.png","img/platform-diagram.png":"/static/platform-diagram-9f76c95ca7dea9f8d3f63b8d37b1ce0f.png","img/trace.png":"/static/trace-15bc5862604806e75c9f1fb1bbd0804c.png","img/client-awareness/field-usage.png":"/static/field-usage-963f97491e5bcd9388f1c4db8db99e17.png","img/datadog/datadog.png":"/static/datadog-d9dac87cddea6e2c36ea6803484cc33b.png","img/datadog/api-key.png":"/static/api-key-876acf317512f507e6e06db2d183d119.png","img/apollo-engine/cache-metrics.png":"/static/cache-metrics-865bf4119e5db00164c80c206d01907a.png","img/schema-history/github-diff.png":"/static/github-diff-f334e9dcc1707fd0346d6f10b530268a.png","img/setup-heroku/add-integration.png":"/static/add-integration-16177c9dad37bfd958f13854b44e8a2c.png","img/schema-history/schema-check.png":"/static/schema-check-fbfefbbf9b96c3d0ea83f689e6379cb3.png","assets/dev-tools.png":"/static/dev-tools-07a52e1ffc14e4f245f94c9f620e143e.png","assets/graphql-playground.png":"/static/graphql-playground-b2fa0c739348e9b91922a25e3b21890f.png","images/client-schema.png":"/static/client-schema-84ed12a64c4c57ba46fd55c0200625f1.png","images/schema-history.png":"/static/schema-history-63f8a91c30b6687ede7b5ae61b759e82.png","img/trace-inspector.png":"/static/trace-inspector-b79d4634fb4b3df152b6ca1eb3843524.png","img/traceWaterfall.png":"/static/traceWaterfall-f7e8839330bb8d53d2bff7dcad3a6994.png","img/setup-heroku/add-engine-key.png":"/static/add-engine-key-8f04108b588b4d40d3dfb6b527a0df5b.png","assets/engine-operation.png":"/static/engine-operation-b065ee96bbfeda9777cf1f3b35c0964c.png","images/alaunch.png":"/static/alaunch-be1b49c5bd490b83e43d8571bf8ae230.png","images/tips-apollo-engine-trace.png":"/static/tips-apollo-engine-trace-f8f8948f285f1f5d6393304b0269934d.png","img/overview.png":"/static/overview-26cafbefcab47df44c557c8f3e50efae.png","img/platform.jpg":"/static/platform-e80a1c35cc2a5400ab4a3f977fd4727c.jpg","images/editors/perf-annotation.png":"/static/perf-annotation-3f5358684bd5bf6cc808751425a8059f.png","images/launches.png":"/static/launches-83c2e0a3be0837c56f89f6167ec221d5.png","img/engine-architecture.png":"/static/engine-architecture-4ed38f5dc5db864eadddcdc4efeba67b.png","img/operation.png":"/static/operation-f6e3489e62927018998923a782d827aa.png","img/client-awareness/overview.png":"/static/overview-d6be789eb6757e6cd8f729ab53e890fb.png","images/editors/stats.gif":"/static/stats-aafa2f05ede89bf302dd36b52337cb3e.gif","img/integrations/integrations-tab.png":"/static/integrations-tab-a8d1a952049cc8969b71d90c46694442.png","img/integrations/slack-report.png":"/static/slack-report-654aa614b7e554f9260679b149d5a261.png","img/datadog/integration-tile.png":"/static/integration-tile-ac1e5d65c149af4a3703786e2e8c904e.png","img/schema-validation/service-check-page.png":"/static/service-check-page-1cead193c0c65131e50453559acef1ef.png","images/paginatedlaunches.png":"/static/paginatedlaunches-9332fd0a0679eeeec165328e639d6133.png","img/slack-setup-button.png":"/static/slack-setup-button-22e57bc5f41b1940b30bdf7c02f23b44.png","img/apollo-engine/engine-architecture.png":"/static/engine-architecture-4ed38f5dc5db864eadddcdc4efeba67b.png","img/slack-setup-popup.png":"/static/slack-setup-popup-0da8906197d6001a2f6a1c651a86aa21.png","img/client-awareness/cutover.png":"/static/cutover-ecbaae93dee3b59330da0f33945701a9.png","img/schema-explorer/explorer.png":"/static/explorer-d2f3d6c2571afba79768f4e3c2cc658d.png","img/datadog/settings-toggle.png":"/static/settings-toggle-6d976b5d78d9392b6367fe27732a246f.png","images/editors/jump-to-def.gif":"/static/jump-to-def-5355f10f27506ffbb51acca8d9cd891f.gif","images/editors/type-info.png":"/static/type-info-847eef5ed06f9609f59230a1808b0132.png","images/editors/warnings-and-errors.gif":"/static/warnings-and-errors-f3de1551ea13706f5329f9f94f14effd.gif","images/schematab.png":"/static/schematab-0774a4e5a5b324097895abb779c540ab.png","images/space-explorer.png":"/static/space-explorer-a81f37ed9dd7c56e7eb9ee3b52769e8d.png","img/schema-view/operation-schema-view.png":"/static/operation-schema-view-9a2f6d2bb54fe2829c05571652b802d5.png","img/schema-view/service-schema-view.png":"/static/service-schema-view-d7ad31d0a065c16a6039a1c18df20c23.png","images/moredetailsonatype.png":"/static/moredetailsonatype-b893f681b5b3bbcaf3ad9355bad8def6.png","images/editors/autocomplete.gif":"/static/autocomplete-d4cf44652b86bcb222ed6619c5b2ba0f.gif","assets/engine.png":"/static/engine-7b9cd78ee8057ac3cb3ebebefb36f9d0.png","images/noresolversjustquery.png":"/static/noresolversjustquery-f21bd417c9e97feeff3639f77c9e8700.png","images/introspection.png":"/static/introspection-23678a34fc9bee50688699ea13d9f4b6.png"},"owner":"apollographql","repo":"apollo","ref":"HEAD"},"filePath":"docs/source/tutorial/schema.md","versions":[{"id":"dev","basePath":"/","contents":[{"title":null,"pages":[{"title":"Welcome","description":"Start here to learn about the Apollo platform","content":"\nWelcome! 👋 We're excited you're here to learn about Apollo.\n\nThe Apollo GraphQL platform is an implementation of GraphQL that helps you manage data from the cloud to your UI. It's incrementally adoptable and can be layered over your existing services, including REST APIs and databases. Apollo includes two open-source libraries for the client and server, in addition to developer tooling that provides everything you need to run a graph API in production with confidence.\n\n<div class=\"documentation-buttons\">\n  <a href=\"/docs/tutorial/introduction.html\" class=\"btn default\">Try it out!</a>\n  <a href=\"/docs/intro/platform.html\" class=\"btn default hollow\">Learn more</a>\n</div>\n\n<div style=\"text-align:center\">\n  <img src=\"./img/platform.jpg\" alt=\"Graph layer\">\n</div>\n","path":"/","filePath":"docs/source/index.md"},{"title":"The Apollo GraphQL platform","description":"How Apollo helps you go from zero to production with GraphQL","content":"\nApollo is an implementation of GraphQL designed for the needs of product\nengineering teams building modern, data-driven applications. It\nencourages an agile, incremental approach and takes special care to\navoid requiring any changes to existing APIs and services. Apollo puts\nparticular emphasis on tooling and workflows.\n\nApollo is best used as a new layer in your stack that sits between your\nservices and your applications. It's a combination of open source\ncomponents, commercial extensions, and cloud services. The major pieces\nare:\n\n<div style=\"text-align:center\">\n  <img src=\"../img/platform-diagram.png\" alt=\"Graph layer\">\n</div>\n\n<h2 id=\"open-source\">Core open source components</h2>\n\n- **Apollo Server** is a JavaScript GraphQL server for defining a\n  _schema_ and a set of _resolvers_ that implement each part of that\n  schema. Typically Apollo Server is extensible: plugins can hook in to each stage of the\n  request pipeline and server's own lifecycle, making it possible to\n  implement custom behaviors in add-on packages. Apollo Server supports\n  AWS Lambda and other serverless environments.\n\n- **Apollo Client** is a sophisticated GraphQL client that\n  manages data and state in an application. Among other benefits, it\n  enables a declarative programming style that lets developers define\n  queries as part of UI components; the client manages all the hairy\n  details of binding query results to the UI, managing consistency,\n  caching, and so on. Apollo Client also supports an\n  exceptionally elegant approach to state management by _extending_ the\n  GraphQL schema inside the client with additional structure. Apollo Client\n  includes integrations for React, React Native, Vue, Angular, and\n  other view layers.\n\n- **iOS and Android** clients, originally contributed by the community,\n  make it possible to query a GraphQL API from native iOS and\n  Android applications.\n\n- **Apollo CLI** is a simple command line client that provides\n  access to Apollo cloud services.\n\n<h2 id=\"cloud-services\">Cloud services</h2>\n\n- **Schema registry** &mdash; a registry for GraphQL schemas that acts\n  as a central source of truth for a schema, enriched with additional\n  metadata like field-level usage statistics.\n\n- **Client registry** &mdash; a registry to track each known consumer\n  of a schema, which can include both pre-registered and ad-hoc clients.\n\n- **Operation registry** &mdash; a registry of all the known operations\n  against the schema, which similarly can include both pre-registered\n  and ad-hoc operations.\n\n- **Trace warehouse** &mdash; a data pipeline and storage layer that\n  captures structured information about each GraphQL operation\n  processed by an Apollo Server (or any other server that implements\n  the Apollo trace API), including the specific set of fields accessed,\n  the tree of resolver calls that were made with timing data for each,\n  and important metadata such as client identity and which version\n  of the schema was queried.\n\n<h2 id=\"gateway\">Gateway</h2>\n\n- **Apollo Gateway** &mdash; a configuration of Apollo Server and additional plugins\n  that functions as a GraphQL gateway. The gateway composes separately deployed \"micro-schemas\" that reference each other into a single master schema, which looks to a client just like any regular GraphQL schema. To answer queries, the gateway builds a query plan, fetches data from each upstream GraphQL service, and assembles it all back together into a single result.\n\n<h2 id=\"workflows\">Workflows</h2>\n\nOn top of these components, Apollo implements some useful workflows for\nmanaging a GraphQL API. Each of these workflows makes use of several\ndifferent parts of the platform, working together. Some examples are:\n\n<h3 id=\"schema-validation\">Schema change validation</h3>\n\nApollo includes a facility for checking the compatibility of a given\nschema against a set of previously-observed operations. This uses the\ntrace warehouse, operation registry, and (typically) the client\nregistry. As an example, an operation that references a missing field or\nan operation that doesn't pass a required argument to a field would\ncause an incompatibility error. The compatibility check runs statically,\ntaking advantage of the schema's type definitions, so it doesn't require\na running server.\n\n<h3 id=\"safelisting\">Safelisting</h3>\n\nApollo provides an end-to-end mechanism for _safelisting_ known clients\nand queries, a recommended best practice that limits production use of a\nGraphQL API to specific pre-arranged operations. There are two parts\nhere. First, the Apollo CLI extracts all the queries from a client\ncodebase, computes the over-the-wire subset of the query (stripping out\nthe part that references the client's local schema), and stores it in\nthe operation registry. Separately, an Apollo Server plugin synchronizes\nthe list of pre-registered operations to the server, which then rejects\nqueries that aren't present in its local copy.\n","path":"/intro/platform","filePath":"docs/source/intro/platform.md"},{"title":"Why GraphQL?","description":"Why adopting GraphQL and Apollo will help you ship features faster","content":"\nManaging data in modern applications can present a number of challenges. Developers have to aggregate data from multiple sources, distribute it upon multiple platforms, and plumb it into an app's UI. On top of that, front-end developers have to decide how to manage state on the client, all while executing complicated features such as caching and optimistic UI.\n\nAdopting GraphQL in your organization will ease these pain points considerably. Read on to learn how GraphQL's declarative approach to data fetching will simplify data transformation and speed up your API. You'll also learn how the Apollo platform enables faster development cycles thanks to its advanced ecosystem of tooling and excellent developer experience.\n\n<h2 id=\"dev-experience\">Developer experience</h2>\n\nImplementing GraphQL in your organization via the Apollo platform can help you ship features faster due to its excellent developer experience. Our #1 goal is to simplify data management across the stack. Features that are normally difficult to execute, such as fullstack caching, data normalization, and optimistic UI suddenly become trivial thanks to Apollo Client, Apollo Server, and Apollo Engine. Let's learn how!\n\n<h3 id=\"explore-api\">Explore your API</h3>\n\nGraphQL's strongly typed query language enables developers to take advantage of incredible tooling for exploring GraphQL APIs. Thanks to GraphQL's introspection system, developers can query a GraphQL schema for information about what queries and types it supports. Introspection unlocks some really cool features, such as automatic documentation, autocomplete, and more.\n\n<h4 id=\"graphql-playground\">GraphQL Playground</h4>\n\n[GraphQL Playground](https://github.com/prismagraphql/graphql-playground) by Prisma is an excellent IDE featuring automatically generated docs for your schema and query execution with autocomplete. At a glance, you can see all the data available in your GraphQL API without diving into the backend code or knowing what source it came from.\n\n![GraphQL Playground](../assets/graphql-playground.png)\n\nApollo Server 2+ sets up GraphQL Playground out of the box, so you can start exploring your schema and executing queries immediately.\n\n<h4 id=\"dev-tools\">Apollo DevTools</h4>\n\nApollo DevTools is a Chrome extension that allows you to inspect your Apollo Client cache, track active queries, and view mutations. You also have access to GraphiQL within Apollo DevTools which is convenient for testing queries as you're working on front-end code with Apollo Client.\n\n![Apollo DevTools](../assets/dev-tools.png)\n\n<h3 id=\"simplify-frontend\">Simplify front-end code</h3>\n\nIf you've worked with REST and a state management library like Redux, you're probably used to writing action creators, reducers, normalizing your data, and integrating middleware to make a single network request. With Apollo Client, you no longer have to worry about any of these concerns! Apollo Client sets up everything you need for a production-ready app so you can focus on writing queries instead of thousands of lines of state management code.\n\n```js\nimport ApolloClient from 'apollo-boost';\n\nconst client = new ApolloClient({\n  uri: 'https://dog-graphql-api.glitch.me/graphql'\n});\n```\n\nTeams who have switched to Apollo Client have reported [deleting thousands of lines of state management code](https://blog.apollographql.com/reducing-our-redux-code-with-react-apollo-5091b9de9c2a) and lots of complexity from their application. Since Apollo Client supports managing both local and remote data, you can use the Apollo cache as a single source of truth for all global state in your application.\n\n<h3 id=\"modern-tooling\">Modern tooling</h3>\n\nDeveloping your GraphQL API with the Apollo platform gives teams access to modern tooling that helps them uncover bugs quickly, gain visibility into their API, and develop challenging features such as caching with confidence.\n\n[Apollo Engine](https://engine.apollographql.com/login) is the only tool in the GraphQL ecosystem that can provide monitoring and analytics for your API. Apollo Engine displays per resolver tracing metrics that can help you pinpoint bugs, as well as performance distribution for every field in your schema. You can also pipe this data to services you're probably already using like DataDog, and set up Slack alerts if these numbers pass a certain threshold.\n\n![Apollo Engine](../assets/engine.png)\n\n<h2 id=\"declarative-data\">Declarative data fetching</h2>\n\nOne of the main advantages of adopting GraphQL is its declarative approach to data fetching. With GraphQL, there's no need to call multiple endpoints from the client or aggregate the data manually like you have to with traditional REST data fetching. Instead, you specify exactly the data you need and GraphQL gives you exactly what you asked for.\n\nWith REST, you would have to call all of these endpoints for each item in the list, filter down the data you need, and aggregate all of the remaining data into the shape your components consume.\n\n```bash\nGET /api/dogs/breeds\nGET /api/dogs/images\nGET /api/dogs/activities\n```\n\nNot only is this approach time-consuming, it's also prone to error and difficult to reuse logic across platforms. Compare this with GraphQL's declarative way to query data:\n\n```graphql\nconst GET_DOGS = gql`\n  query {\n    dogs {\n      id\n      breed\n      image {\n        url\n      }\n      activities {\n        name\n      }\n    }\n  }\n`;\n```\n\nHere, we're describing the shape of the object we want to receive from the server. GraphQL takes care of combining and filtering the data while returning exactly what we ask for.\n\nHow do we use this query in our app? Apollo Client builds off of GraphQL's declarative approach to data fetching. In a React app, all of the logic for retrieving your data, tracking loading and error states, and updating your UI is encapsulated in a single `Query` component. This encapsulation makes composing your data fetching components with your presentational components a breeze! Let’s see how to fetch GraphQL data with Apollo Client in a React app:\n\n```jsx\nconst Feed = () => (\n  <Query query={GET_DOGS}>\n    {({ loading, error, data }) => {\n      if (error) return <Error />;\n      if (loading || !data) return <Fetching />;\n\n      return <DogList dogs={data.dogs} />;\n    }}\n  </Query>\n);\n```\n\nApollo Client takes care of the request cycle from start to finish, including tracking loading and error states for you. There’s no middleware to set up or boilerplate to write before making your first request, nor do you need to worry about transforming and caching the response. All you have to do is describe the data your component needs and let Apollo Client do the heavy lifting. 💪\n\nYou’ll find that when you switch to Apollo Client, you’ll be able to delete a lot of unnecessary code related to data management. The exact amount will vary depending on your application, but some teams have reported up to thousands of lines. To learn more about how Apollo Client enables advanced features like optimistic UI, refetching, and pagination with less code, check out our [documentation for Apollo Client](/docs/react/).\n\n<h2 id=\"performance\">Improved performance</h2>\n\nIn many cases, layering a GraphQL API over your existing REST endpoints can improve your app's performance, especially on devices with slow network connections. While you should always measure to determine how integrating GraphQL will affect your application, it's generally accepted that GraphQL improves performance by helping avoid round trips to the server and reducing payload size.\n\n<h3 id=\"smaller-payload\">Smaller payloads</h3>\n\nSince the response back from the server contains only the properties you specify in your query, GraphQL can significantly reduce payload size compared to a REST endpoint. Let's take a look at our dogs query from earlier in the article:\n\n```graphql\nconst GET_DOGS = gql`\n  query {\n    dogs {\n      id\n      breed\n      image {\n        url\n      }\n      activities {\n        name\n      }\n    }\n  }\n`;\n```\n\nThe response back from the server will be a list of dog objects with `id`, `breed`, `image`, and `activities` properties. It doesn't matter if the underlying REST endpoints we call in our resolvers return back objects with 100 properties! All of those extraneous properties will be filtered out before the response is sent back to the client.\n\n<h3 id=\"round-trip\">Avoid round trips</h3>\n\nSince each GraphQL request returns only one response, switching to GraphQL can help you avoid costly round trips from the client to your server. With REST, each resource represents a round trip, which can quickly add up. If you're fetching items in a list, you'll have to complete a round trip for every resource multiplied by the number of items, causing slow load times, especially on mobile devices.\n\n```bash\nGET /api/dogs/breeds\nGET /api/dogs/images\nGET /api/dogs/activities\n```\n\nWith GraphQL, each query represents a single round trip from the client to server. If you'd like to reduce round trips even further, you can implement [query batching](/docs/react/advanced/network-layer#query-batching) to batch multiple queries into a single request.\n\n<h3 id=\"production\">Ready for production</h3>\n\nWhile the GraphQL specification was first made public by Facebook in 2015, GraphQL has been a key component of their mobile application deployment since 2012.\n\nAt Apollo, we found GraphQL to be an excellent solution to many of the problems we encountered with existing techniques, and now use it to power critical infrastructure. Over the years, we’ve worked with the open-source community along with customers and partners of all sizes to continually bring new innovations to the open-source Apollo offerings, and we're proud that those offerings are suitable for everything from startups to large-scale deployments.\n\nIn addition to our own experience, we have received extensive feedback, contributions and support from enterprise customers who are actively using Apollo GraphQL in production. A few of our most public and notable case-studies are:\n\n- [**The New York Times**](https://open.nytimes.com/the-new-york-times-now-on-apollo-b9a78a5038c): Learn how The New York Times switched from Relay to Apollo & implemented features in their app such as SSR and persisted queries.\n- [**Airbnb**](https://medium.com/airbnb-engineering/reconciling-graphql-and-thrift-at-airbnb-a97e8d290712): Airbnb is betting big on the Apollo platform to power the data layer for their microservices.\n- [**Express**](https://dev-blog.apollodata.com/changing-the-architecture-of-express-com-23c950d43323): Easy-to-use pagination with Apollo helped improve the Express eCommerce team's key product pages.\n- [**Major League Soccer**](https://dev-blog.apollodata.com/reducing-our-redux-code-with-react-apollo-5091b9de9c2a): MLS' switch from Redux to Apollo for state management enabled them to delete nearly all of their Redux code.\n- [**Expo**](https://dev-blog.apollodata.com/using-graphql-apollo-at-expo-4c1f21f0f115): Developing their React Native app with Apollo allowed the Expo engineers to focus on improving their product instead of writing data fetching logic.\n- [**KLM**](https://youtu.be/T2njjXHdKqw): Learn how the KLM team scaled their Angular app with GraphQL and Apollo.\n","path":"/intro/benefits","filePath":"docs/source/intro/benefits.md"}]},{"title":"Tutorial","pages":[{"title":"0. Introduction","description":"Start here to learn how to build fullstack apps with Apollo","content":"\nWelcome! We're excited that you've decided to learn Apollo. This fullstack tutorial will guide you through building your first app with the Apollo platform in about an hour. Throughout the tutorial, you'll learn how to build a graph API and connect it to a React frontend.\n\nWe want you to feel confident that you have the knowledge you need to build a production-ready app with Apollo, so we're forgoing hello world in favor of a real world example complete with authentication, pagination, testing, and more. Ready? Let's dive right in!\n\n<h2 id=\"what-is-apollo\">What is Apollo?</h2>\n\nApollo is a complete platform for implementing a graph over your data. It includes two runtime libraries, **Apollo Server** and **Apollo Client**, for building and querying your graph's API. It also features developer tooling that integrates with your existing workflow and gives you full visibility into the performance and security of your graph.\n\nWhy do you need a graph? Today, one of the most difficult parts of building an app is figuring out your data layer. Often, there's many data sources you need to fetch from and many clients you need to support. When you layer a graph in between your services and your UI, you can remove a lot of complexity from your data fetching logic and ship features faster.\n\n<div style=\"text-align:center\">\n  <img src=\"../images/graph-layer.png\" alt=\"Graph layer\">\n</div>\n\n**[GraphQL](https://www.graphql.org/)** is the specification that we'll be using to communicate between our graph API and client. The spec itself is language-agnostic and unopinionated, so we're choosing to implement GraphQL with the Apollo platform.\n\n<h2 id=\"tutorial-app\">What we'll build</h2>\n\nIn this tutorial, we'll build an interactive app for reserving your spot on an upcoming Space-X launch. You can think of it as an Airbnb for space travel! All of the data is real, thanks to the [SpaceX-API](https://github.com/r-spacex/SpaceX-API).\n\nHere's what the finished app will look like:\n\n<div style=\"text-align:center\">\n  <img src=\"../images/space-explorer.png\" alt=\"Space explorer\">\n</div>\n\nThe app has five screens: a login screen, a list of launches, a launch detail, a profile page, and a cart. The graph API powering our space app connects to a REST API and a SQLite database. Don't worry if you're unfamiliar with those technologies, you don't need to know how to build a REST API or SQLite database from scratch in order to complete the tutorial.\n\nWe want this to model a real world Apollo app as much as possible, so we're covering essential topics like authentication, pagination, state management, testing, and deployment.\n\n<h2 id=\"prerequisites\">Prerequisites</h2>\n\nThe tutorial assumes that you're comfortable with JavaScript/ES6, you've fetched data from an API before, and you have basic familiarity with React. If you need to brush up on your React skills, we recommend going through the [official tutorial](https://reactjs.org/tutorial/tutorial.html). Building your frontend with React is not a requirement for using Apollo, although it is the most popular way developers integrate with Apollo Client. Even if you use another view layer like Angular or Vue, you will still be able to pick up on the concepts covered in the client section and apply them to your view layer of choice.\n\n<h3 id=\"system-requirements\">System requirements</h3>\n\nBefore we begin, make sure you have:\n\n- [Node.js](https://nodejs.org/) v6.9.0 or greater\n- [npm](https://www.npmjs.com/) 3.10.8 or greater\n- [git](https://git-scm.com/) v2.14.1 or greater\n\nWhile it's not a requirement, we recommend using [VSCode](https://code.visualstudio.com/) as your editor so you can take advantage of all the awesome features the Apollo VSCode extension enables. We're hoping to support other editors in the future.\n\n<h2 id=\"dev-environment\">Set up your development environment</h2>\n\nNow the fun begins! First, you'll need to install our developer tools:\n\n- [Apollo Engine (required)](https://engine.apollographql.com) : Our cloud service where you'll register and manage your graph API.\n- [Apollo DevTools for Chrome (suggested)](https://chrome.google.com/webstore/detail/apollo-client-developer-t/jdkknkkbebbapilgoeccciglkfbmbnfm) : Our Chrome extension giving you full visibility into your client.\n- [Apollo VSCode (suggested)](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo): Our editor integration that offers intelligent autocomplete, metrics, and more.\n\nNext, in your terminal, clone [this repository](https://github.com/apollographql/fullstack-tutorial):\n\n```bash\ngit clone https://github.com/apollographql/fullstack-tutorial/\n```\n\nThere are two folders: one for the starting point (`start`) and one for the final version (`final`). Within each directory are two folders: one for the server and one for the client. We will be working in the server folder first. If you're comfortable with building a graph API already and you want to skip to the client portion, navigate to the [last half of the tutorial](./client.html).\n\n<!--\nTODO: Add in this section after Apollo VSCode works for server development\n<h3 id=\"vscode\">Configure Apollo VSCode</h3> -->\n\n<h3 id=\"help\">Where can I get help?</h3>\n\nWe know that learning a new technology can sometimes be overwhelming, and it's totally normal to get stuck! If that happens, we recommend joining the [Apollo Spectrum](https://spectrum.chat/apollo) community and posting in the relevant channel (either #apollo-server or #apollo-client) for some quick answers.\n\nIf something in the tutorial seems confusing or contains an error, we'd love your feedback! Just click the Edit on GitHub link on the right side of the page to open a new pull request or open an issue on the repository.\n","path":"/tutorial/introduction","filePath":"docs/source/tutorial/introduction.md"},{"title":"1. Build a schema","description":"Create a blueprint for your graph's data","content":"\nThe first step on our journey toward building our graph API is constructing its **schema**. You can think of a schema as a blueprint for all of the data you can access in your graph. Throughout this section, you'll learn how to build and explore your graph's schema with Apollo.\n\n<h2 id=\"setup\">Set up Apollo Server</h2>\n\nBefore we write our schema, we need to set up our graph API's server. **Apollo Server** is a library that helps you build a production-ready graph API over your data. It can connect to any data source, including REST APIs and databases, and it seamlessly integrates with Apollo developer tooling.\n\nFrom the root, let's install our project's dependencies:\n\n```bash\ncd start/server && npm install\n```\n\nThe two packages you need to get started with Apollo Server are `apollo-server` and `graphql`, which we've already installed for you. Now, let's navigate to `src/index.js` so we can create our server. Copy the code below into the file.\n\n_src/index.js_\n\n```js\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\n\nconst server = new ApolloServer({ typeDefs });\n```\n\nTo build our graph API, we need to import the `ApolloServer` class from `apollo-server`. We also need to import our schema from `src/schema.js`. Next, let's create a new instance of `ApolloServer` and pass our schema to the `typeDefs` property on the configuration object.\n\nBefore we can start the server, we need to write our schema first.\n\n<h2 id=\"write-schema\">Write your graph's schema</h2>\n\nEvery graph API is centered around its schema. You can think of a schema as a blueprint that describes all of your data's types and their relationships. A schema also defines what data we can fetch through queries and what data we can update through mutations. It is strongly typed, which unlocks powerful developer tooling.\n\nSchemas are at their best when they are designed around the needs of the clients that are consuming them. Since a schema sits in between your clients and your underlying services, it serves as a perfect middle ground for frontend and backend teams to collaborate. We recommend that teams practice **Schema First Development** and agree upon the schema first before any API development begins.\n\nLet's think about the data we will need to expose in order to build our app. Our app needs to:\n\n- Fetch all upcoming rocket launches\n- Fetch a specific launch by its ID\n- Login the user\n- Book launch trips if the user is logged in\n- Cancel launch trips if the user is logged in\n\nOur schema will be based on these features. In `src/schema.js`, import `gql` from Apollo Server and create a variable called `typeDefs` for your schema. Your schema will go inside the `gql` function (between the backticks in this portion: <code>gql\\`\\`</code>).\n\n_src/schema.js_\n\n```js\nconst { gql } = require('apollo-server');\n\nconst typeDefs = gql``;\n\nmodule.exports = typeDefs;\n```\n\n<h3 id=\"query\">Query type</h3>\n\nWe'll start with the **Query type**, which is the entry point into our schema that describes what data we can fetch.\n\nThe language we use to write our schema is GraphQL's schema definition language (SDL). If you've used TypeScript before, the syntax will look familiar. Copy the following SDL code between the backticks where the `gql` function is invoked in  `src/schema.js`\n\n_src/schema.js_\n\n```graphql\ntype Query {\n  launches: [Launch]!\n  launch(id: ID!): Launch\n  # Queries for the current user\n  me: User\n}\n```\n\nFirst, we define a `launches` query to fetch all upcoming rocket launches. This query returns an array of launches, which will never be null. Since all types in GraphQL are nullable by default, we need to add the `!` to indicate that our query will always return data. Next, we define a query to fetch a `launch` by its ID. This query takes an argument of `id` and returns a single launch. Finally, we will add a `me` query to fetch the current user's data. Above the `me` query is an example of a comment added to the schema.\n\nHow do we define what properties are exposed by `Launch` and `User`? For these types, we need to define a GraphQL object type.\n\n<h3 id=\"object\">Object & scalar types</h3>\n\nLet's define what the structure of `Launch` looks like by creating an **object type**:\n\n_src/schema.js_\n\n```graphql\ntype Launch {\n  id: ID!\n  site: String\n  mission: Mission\n  rocket: Rocket\n  isBooked: Boolean!\n}\n```\n\nThe `Launch` type has **fields** that correspond to object and scalar types. A **scalar type** is a primitive type like `ID`, `String`, `Boolean`, or `Int`. You can think of scalars as the leaves of your graph that all fields resolve to. GraphQL has many scalars built in, and you can also define [custom scalars](/docs/apollo-server/features/scalars-enums.html) like `Date`.\n\nThe `Mission` and `Rocket` types represent other object types. Let's define the fields on `Mission`, `Rocket`, and `User`:\n\n_src/schema.js_\n\n```graphql\ntype Rocket {\n  id: ID!\n  name: String\n  type: String\n}\n\ntype User {\n  id: ID!\n  email: String!\n  trips: [Launch]!\n}\n\ntype Mission {\n  name: String\n  missionPatch(size: PatchSize): String\n}\n\nenum PatchSize {\n  SMALL\n  LARGE\n}\n```\n\nYou'll notice that the field `missionPatch` takes an argument of `size`. GraphQL is flexible because any fields can contain arguments, not just queries. The `size` argument corresponds to an **enum type**, which we're defining at the bottom with `PatchSize`.\n\nThere are some other less common types you might also encounter when building your graph's schema. For a full list, you can reference this handy [cheat sheet](https://devhints.io/graphql#schema).\n\n<h3 id=\"mutation\">Mutation type</h3>\n\nNow, let's define the **Mutation type**. The `Mutation` type is the entry point into our graph for modifying data. Just like the `Query` type, the `Mutation` type is a special object type.\n\n_src/schema.js_\n\n```graphql\ntype Mutation {\n  # if false, booking trips failed -- check errors\n  bookTrips(launchIds: [ID]!): TripUpdateResponse!\n\n  # if false, cancellation failed -- check errors\n  cancelTrip(launchId: ID!): TripUpdateResponse!\n\n  login(email: String): String # login token\n}\n```\n\nBoth the `bookTrips` and `cancelTrip` mutations take an argument and return a `TripUpdateResponse`. The return type for your GraphQL mutation is completely up to you, but we recommend defining a special response type to ensure a proper response is returned back to the client. In a larger project, you might abstract this type into an interface, but for now, we're going to define `TripUpdateResponse`:\n\n_src/schema.js_\n\n```graphql\ntype TripUpdateResponse {\n  success: Boolean!\n  message: String\n  launches: [Launch]\n}\n```\n\nOur mutation response type contains a success status, a corresponding message, and the launch that we updated. It's always good practice to return the data that you're updating in order for the Apollo Client cache to update automatically.\n\n<h2 id=\"apollo-server-run\">Run your server</h2>\n\nNow that we have scoped out our app's schema, let's run the server by calling `server.listen()`.\n\n_src/index.js_\n\n```js\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\n\nconst server = new ApolloServer({ typeDefs });\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀 Server ready at ${url}`);\n});\n```\n\nIn your terminal, run `npm start` to start your server! 🎉 Apollo Server will now be available on port 4000.\n\n<h3 id=\"apollo-server-explore\">Explore your schema</h3>\n\nBy default, Apollo Server supports [GraphQL Playground](/docs/apollo-server/features/graphql-playground.html). The Playground is an interactive, in-browser GraphQL IDE for exploring your schema and testing your queries. Apollo Server automatically serves GraphQL Playground in development only.\n\nThe GraphQL Playground provides the ability to introspect your schema. **Introspection** is a technique used to provide detailed information about a graph's schema. To see this in action, check out the right hand side of GraphQL Playground and click on the `schema` button.\n\n<div style=\"text-align:center\">\n  <img src=\"../images/schematab.png\" alt=\"Schema button\">\n</div>\n\nYou can quickly have access to the documentation of a GraphQL API via the `schema` button.\n\n<div style=\"text-align:center\">\n  <img src=\"../images/moredetailsonatype.png\" alt=\"More details on a Schema Type\">\n</div>\n\nThat's all for building our schema. Let's move on to the next part of our tutorial.\n","path":"/tutorial/schema","filePath":"docs/source/tutorial/schema.md"},{"title":"2. Hook up your data sources","description":"Connect REST and SQL data to your graph","content":"\nTime to accomplish: _10 Minutes_\n\nNow that we've constructed our schema, we need to hook up our data sources to our GraphQL API. GraphQL APIs are extremely flexible because you can layer them on top of any service, including any business logic, REST APIs, databases, or gRPC services.\n\nApollo makes connecting these services to your graph simple with our data source API. An **Apollo data source** is a class that encapsulates all of the data fetching logic, as well as caching and deduplication, for a particular service. By using Apollo data sources to hook up your services to your graph API, you're also following best practices for organizing your code.\n\nIn the next sections, we'll build data sources for a REST API and a SQL database and connect them to Apollo Server. Don't worry if you're not familiar with either of those technologies, you won't need to understand them deeply in order to follow the examples. 😀\n\n<h2 id=\"rest-api\">Connect a REST API</h2>\n\nFirst, let's connect the [Space-X v2 REST API](https://github.com/r-spacex/SpaceX-API) to our graph. To get started, install the `apollo-datasource-rest` package:\n\n```bash\nnpm install apollo-datasource-rest --save\n```\n\nThis package exposes the `RESTDataSource` class that is responsible for fetching data from a REST API. To build a data source for a REST API, extend the `RESTDataSource` class and define `this.baseURL`.\n\nIn our example, the `baseURL` for our API is `https://api.spacexdata.com/v2/`. Let's create our `LaunchAPI` data source by adding the code below to `src/datasources/launch.js`:\n\n_src/datasources/launch.js_\n\n```js\nconst { RESTDataSource } = require('apollo-datasource-rest');\n\nclass LaunchAPI extends RESTDataSource {\n  constructor() {\n    super();\n    this.baseURL = 'https://api.spacexdata.com/v2/';\n  }\n}\n\nmodule.exports = LaunchAPI;\n```\n\nThe Apollo `RESTDataSource` also sets up an in-memory cache that caches responses from our REST resources with no additional setup. We call this **partial query caching**. What's great about this cache is that you can reuse existing caching logic that your REST API exposes. If you're curious to learn more about partial query caching with Apollo data sources, please check out [our blog post](https://blog.apollographql.com/easy-and-performant-graphql-over-rest-e02796993b2b).\n\n<h3 id=\"fetching\">Write data fetching methods</h3>\n\nThe next step is to add methods to the `LaunchAPI` data source that correspond to the queries our graph API needs to fetch. According to our schema, we'll need a method to get all of the launches. Let's add a `getAllLaunches` method to our `LaunchAPI` class now:\n\n_src/datasources/launch.js_\n\n```js\nasync getAllLaunches() {\n  const response = await this.get('launches');\n  return Array.isArray(response)\n    ? response.map(launch => this.launchReducer(launch))\n    : [];\n}\n```\n\nThe Apollo REST data sources have helper methods that correspond to HTTP verbs like `GET` and `POST`. In the code above, `this.get('launches')`, makes a `GET` request to `https://api.spacexdata.com/v2/launches` and stores the returned launches in the `response` variable. Then, the `getAllLaunches` method maps over the launches and transforms the response from our REST endpoint with `this.launchReducer`. If there are no launches, an empty array is returned.\n\nNow, we need to write our `launchReducer` method in order to transform our launch data into the shape our schema expects. We recommend this approach in order to decouple your graph API from business logic specific to your REST API. First, let's recall what our `Launch` type looks like in our schema. You don't have to copy this code:\n\n_src/schema.js_\n\n```graphql\ntype Launch {\n  id: ID!\n  site: String\n  mission: Mission\n  rocket: Rocket\n  isBooked: Boolean!\n}\n```\n\nNext, let's write a `launchReducer` function to transform the data into that shape. Copy the following code into your `LaunchAPI` class:\n\n_src/datasources/launch.js_\n\n```js\nlaunchReducer(launch) {\n  return {\n    id: launch.flight_number || 0,\n    cursor: `${launch.launch_date_unix}`,\n    site: launch.launch_site && launch.launch_site.site_name,\n    mission: {\n      name: launch.mission_name,\n      missionPatchSmall: launch.links.mission_patch_small,\n      missionPatchLarge: launch.links.mission_patch,\n    },\n    rocket: {\n      id: launch.rocket.rocket_id,\n      name: launch.rocket.rocket_name,\n      type: launch.rocket.rocket_type,\n    },\n  };\n}\n```\n\nWith the above changes, we can easily make changes to the `launchReducer` method while the `getAllLaunches` method stays lean and concise. The `launchReducer` method also makes testing the `LaunchAPI` data source class easier, which we'll cover later.\n\nNext, let's take care of fetching a specific launch by its ID. Let's add two methods, `getLaunchById`, and `getLaunchesByIds` to the `LaunchAPI` class.\n\n_src/datasources/launch.js_\n\n```js\nasync getLaunchById({ launchId }) {\n  const response = await this.get('launches', { flight_number: launchId });\n  return this.launchReducer(response[0]);\n}\n\ngetLaunchesByIds({ launchIds }) {\n  return Promise.all(\n    launchIds.map(launchId => this.getLaunchById({ launchId })),\n  );\n}\n```\n\nThe `getLaunchById` method takes in a flight number and returns the data for a particular launch, while `getLaunchesByIds` returns several launches based on their respective `launchIds`.\n\nNow that we've connected our REST API successfully, let's connect our database!\n\n<h2 id=\"database\">Connect a database</h2>\n\nOur REST API is read-only, so we need to connect our graph API to a database for saving and fetching user data. This tutorial uses SQLite for our SQL database, and Sequelize for our ORM. Our `package.json` already included these packages, thus they were installed in the first part of this tutorial with `npm install`. Also, since this section contains some SQL-specific code that isn't necessary to understanding Apollo data sources, we've already built a `UserAPI` data source for you in `src/datasources/user.js`. Please navigate to that file so we can explain the overall concepts.\n\n<h3 id=\"custom-data-source\">Build a custom data source</h3>\n\nApollo doesn't have support for a SQL data source yet (although we'd love to help guide you if you're interested in contributing), so we will need to create a custom data source for our database by extending the generic Apollo data source class. You can create your own with the `apollo-datasource` package.\n\nHere are some of the core concepts for creating your own data source:\n\n- The `initialize` method: You'll need to implement this method if you want to pass in any configuration options to your class. Here, we're using this method to access our graph API's context.\n- `this.context`: A graph API's context is an object that's shared among every resolver in a GraphQL request. We're going to explain this in more detail in the next section. Right now, all you need to know is that the context is useful for storing user information.\n- Caching: While the REST data source comes with its own built in cache, the generic data source does not. You can use [our cache primitives](/docs/apollo-server/features/data-sources.html#using-memcached-redis-as-a-cache-storage-backend) to build your own, however!\n\nLet's go over some of the methods we created in `src/datasources/user.js` to fetch and update data in our database. You will want to reference these in the next section:\n\n- `findOrCreateUser({ email })`: Finds or creates a user with a given `email` in the database\n- `bookTrips({ launchIds })`: Takes an object with an array of `launchIds` and books them for the logged in user\n- `cancelTrip({ launchId })`: Takes an object with a `launchId` and cancels that launch for the logged in user\n- `getLaunchIdsByUser()`: Returns all booked launches for the logged in user\n- `isBookedOnLaunch({ launchId })`: Determines whether the logged in user booked a certain launch\n\n<h2 id=\"apollo-server\">Add data sources to Apollo Server</h2>\n\nNow that we've built our `LaunchAPI` data source to connect our REST API and our `UserAPI` data source to connect our SQL database, we need to add them to our graph API.\n\nAdding our data sources is simple, just create a `dataSources` property on your `ApolloServer` that corresponds to a function that returns an object with your instantiated data sources. Let's see what that looks like by navigating to `src/index.js` and adding the code below:\n\n_src/index.js_\n\n```js line=3,5,6,8,12-15\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\nconst { createStore } = require('./utils');\n\nconst LaunchAPI = require('./datasources/launch');\nconst UserAPI = require('./datasources/user');\n\nconst store = createStore();\n\nconst server = new ApolloServer({\n  typeDefs,\n  dataSources: () => ({\n    launchAPI: new LaunchAPI(),\n    userAPI: new UserAPI({ store })\n  })\n});\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀 Server ready at ${url}`);\n});\n```\n\nFirst, we import our `createStore` function to set up our database, as well as our data sources: `LaunchAPI` and `UserAPI`. Then, we create our database by calling `createStore`. Finally, we add the `dataSources` function to our `ApolloServer` to connect `LaunchAPI` and `UserAPI` to our graph. We also pass in our database we created to the `UserAPI` data source.\n\nIf you use `this.context` in your datasource, it's critical to create a new instance in the `dataSources` function and to not share a single instance. Otherwise, `initialize` may be called during the execution of asynchronous code for a specific user, and replace the  `this.context` by the context of another user.\n\nNow that we've hooked up our data sources to Apollo Server, it's time to move on to the next section and learn how to call our data sources from within our resolvers.\n","path":"/tutorial/data-source","filePath":"docs/source/tutorial/data-source.md"},{"title":"3. Write your graph's resolvers","description":"Learn how a GraphQL query fetches data","content":"\nTime to accomplish: _15 Minutes_\n\nUp until now, our graph API hasn't been very useful. We can inspect our graph's schema, but we can't actually run queries against it. Now that we've built our schema and data sources, it's time to leverage all of our hard work by calling our data sources in our graph API's resolver functions to possibly trigger business logic and/or to fetch and/or update data.\n\n<h2 id=\"resolver-api\">What is a resolver?</h2>\n\n**Resolvers** provide the instructions for turning a GraphQL operation (a query, mutation, or subscription) into data. They either return the same type of data we specify in our schema or a promise for that data.\n\nBefore we can start writing resolvers, we need to learn more about what a resolver function looks like. Resolver functions accept four arguments:\n\n```js\nfieldName: (parent, args, context, info) => data;\n```\n\n- **parent**: An object that contains the result returned from the resolver on the parent type\n- **args**: An object that contains the arguments passed to the field\n- **context**: An object shared by all resolvers in a GraphQL operation. We use the context to contain per-request state such as authentication information and access our data sources.\n- **info**: Information about the execution state of the operation which should only be used in advanced cases\n\nRemember the `LaunchAPI` and `UserAPI` data sources we created in the previous section and passed to the `context` property of `ApolloServer`? We're going to call them in our resolvers by accessing the `context` argument.\n\nThis might sound confusing at first, but it will start to make more sense once we dive into practical examples. Let's get started!\n\n<h3 id=\"apollo-server\">Connecting resolvers to Apollo Server</h3>\n\nFirst, let's connect our resolver map to Apollo Server. Right now, it's just an empty object, but we should add it to our `ApolloServer` instance so we don't have to do it later. Navigate to `src/index.js` and add the following code to the file:\n\n_src/index.js_\n\n```js line=4,13\nconst { ApolloServer } = require('apollo-server');\nconst typeDefs = require('./schema');\nconst { createStore } = require('./utils');\nconst resolvers = require('./resolvers');\n\nconst LaunchAPI = require('./datasources/launch');\nconst UserAPI = require('./datasources/user');\n\nconst store = createStore();\n\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  dataSources: () => ({\n    launchAPI: new LaunchAPI(),\n    userAPI: new UserAPI({ store })\n  })\n});\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀 Server ready at ${url}`);\n});\n```\n\nApollo Server will automatically add the `launchAPI` and `userAPI` to our resolvers' context so we can easily call them.\n\n<h2 id=\"query\">Write Query resolvers</h2>\n\nFirst, let's start by writing our resolvers for the `launches`, `launch`, and `me` fields on our `Query` type. We structure our resolvers into a map where the keys correspond to the types and fields in our schema. If you ever get stuck remembering which fields are on a type, you can always check your graph API's schema.\n\nNavigate to `src/resolvers.js` and paste the code below into the file:\n\n_src/resolvers.js_\n\n```js\nmodule.exports = {\n  Query: {\n    launches: (_, __, { dataSources }) =>\n      dataSources.launchAPI.getAllLaunches(),\n    launch: (_, { id }, { dataSources }) =>\n      dataSources.launchAPI.getLaunchById({ launchId: id }),\n    me: (_, __, { dataSources }) => dataSources.userAPI.findOrCreateUser()\n  }\n};\n```\n\nThe code above shows the resolver functions for the `Query` type fields: `launches`, `launch`, and `me`. The first argument to our _top-level_ resolvers, `parent`, is always blank because it refers to the root of our graph. The second argument refers to any `arguments` passed into our query, which we use in our `launch` query to fetch a launch by its id. Finally, we destructure our data sources from the third argument, `context`, in order to call them in our resolvers.\n\nOur resolvers are simple and concise because the logic is embedded in the `LaunchAPI` and `UserAPI` data sources. We recommend keeping your resolvers thin as a best practice, which allows you to safely refactor without worrying about breaking your API.\n\n<h3 id=\"query-playground\">Run queries in the playground</h3>\n\nApollo Server sets up GraphQL Playground so that you can run queries and explore your schema with ease. Go ahead and start your server by running `npm start` and open up the playground in a browser window at `http://localhost:4000/`.\n\nStart by copying the GraphQL query below and pasting it in the left side of the playground. Then, hit the play button at the center to get a response.\n\n```graphql\nquery GetLaunches {\n  launches {\n    id\n    mission {\n      name\n    }\n  }\n}\n```\n\nWhen you write a GraphQL query, you always want to start with the **operation keyword** (either query or mutation) and its name (like `GetLaunches`). It's important to give your queries descriptive names so they're discoverable in Apollo developer tooling. Next, we use a pair of curly braces after the query name to indicate the body of our query. We specify the `launches` field on the `Query` type and use another pair of curly braces to indicate a **selection set**. The selection set describes which fields we want our query response to contain.\n\nWhat's awesome about GraphQL is that the shape of your query will match the shape of your response. Try adding and removing fields from your query and notice how the response shape changes.\n\nNow, let's write a launch query that accepts an argument. Copy the query below and paste it in the playground. Then, click the play button to get a response.\n\n```graphql\nquery GetLaunchById {\n  launch(id: 60) {\n    id\n    rocket {\n      id\n      type\n    }\n  }\n}\n```\n\nInstead of hard coding the argument `60`, you can also set variables in the bottom left corner. Here's how to run that same query with variables:\n\n```graphql\nquery GetLaunchById($id: ID!) {\n  launch(id: $id) {\n    id\n    rocket {\n      id\n      type\n    }\n  }\n}\n```\n\nYou can paste `{ \"id\": 60 }` into the Query Variables section below before running your query. Feel free to experiment with running more queries before moving on to the next section.\n\n<h3 id=\"pagination\">Paginated queries</h3>\n\nRunning the `launches` query returned a large data set of launches, which can slow down our app. How can we ensure we're not fetching too much data at once?\n\n**Pagination** is a solution to this problem that ensures that the server only sends data in small chunks. Cursor-based pagination is our recommended approach over numbered pages, because it eliminates the possibility of skipping items and displaying the same item more than once. In cursor-based pagination, a constant pointer (or **cursor**) is used to keep track of where in the data set the next items should be fetched from.\n\nWe'll use cursor-based pagination for our graph API. Open up the `src/schema.js` file and update the `Query` type with `launches` and also add a new type called `LaunchConnection` to the schema as shown below:\n\n_src/schema.js_\n\n```js\ntype Query {\n  launches( # replace the current launches query with this one.\n    \"\"\"\n    The number of results to show. Must be >= 1. Default = 20\n    \"\"\"\n    pageSize: Int\n    \"\"\"\n    If you add a cursor here, it will only return results _after_ this cursor\n    \"\"\"\n    after: String\n  ): LaunchConnection!\n  launch(id: ID!): Launch\n  me: User\n}\n\n\"\"\"\nSimple wrapper around our list of launches that contains a cursor to the\nlast item in the list. Pass this cursor to the launches query to fetch results\nafter these.\n\"\"\"\ntype LaunchConnection { # add this below the Query type as an additional type.\n  cursor: String!\n  hasMore: Boolean!\n  launches: [Launch]!\n}\n...\n```\n\nYou'll also notice we've added comments (also called docstrings) to our schema, indicated by `\"\"\"`. Now, the `launches` query takes in two parameters, `pageSize` and `after`, and returns a `LaunchConnection`. The `LaunchConnection` type returns a result that shows the list of launches, in addition to a `cursor` field that keeps track of where we are in the list and a `hasMore` field to indicate if there's more data to be fetched.\n\nOpen up the `src/utils.js` file in the repo you cloned in the previous section and check out the `paginateResults` function. The `paginateResults` function in the file is a helper function for paginating data from the server. Now, let's update the necessary resolver functions to accommodate pagination.\n\nLet's import `paginateResults` and replace the `launches` resolver function in the `src/resolvers.js` file with the code below:\n\n_src/resolvers.js_\n\n```js line=1,5-26\nconst { paginateResults } = require('./utils');\n\nmodule.exports = {\n  Query: {\n    launches: async (_, { pageSize = 20, after }, { dataSources }) => {\n      const allLaunches = await dataSources.launchAPI.getAllLaunches();\n      // we want these in reverse chronological order\n      allLaunches.reverse();\n\n      const launches = paginateResults({\n        after,\n        pageSize,\n        results: allLaunches\n      });\n\n      return {\n        launches,\n        cursor: launches.length ? launches[launches.length - 1].cursor : null,\n        // if the cursor of the end of the paginated results is the same as the\n        // last item in _all_ results, then there are no more results after this\n        hasMore: launches.length\n          ? launches[launches.length - 1].cursor !==\n            allLaunches[allLaunches.length - 1].cursor\n          : false\n      };\n    },\n    launch: (_, { id }, { dataSources }) =>\n      dataSources.launchAPI.getLaunchById({ launchId: id }),\n     me: async (_, __, { dataSources }) =>\n      dataSources.userAPI.findOrCreateUser(),\n  }\n};\n```\n\nLet's test the cursor-based pagination we just implemented. If you stopped your server, go ahead and restart your graph API again with `npm start`, and run this query in the playground:\n\n```graphql\nquery GetLaunches {\n  launches(pageSize: 3) {\n    launches {\n      id\n      mission {\n        name\n      }\n    }\n  }\n}\n```\n\nThanks to our pagination implementation, you should only see three launches returned back from our API.\n\n<h2 id=\"types\">Write resolvers on types</h2>\n\nIt's important to note that you can write resolvers for any types in your schema, not just queries and mutations. This is what makes GraphQL so flexible.\n\nYou may have noticed that we haven't written resolvers for all our types, yet our queries still run successfully. GraphQL has default resolvers; therefore, we don't have to write a resolver for a field if the parent object has a property with the same name.\n\nLet's look at a case where we do want to write a resolver on our `Mission` type. Navigate to `src/resolvers.js` and copy this resolver into our resolver map underneath the `Query` property:\n\n_src/resolvers.js_\n\n```js\nMission: {\n  // make sure the default size is 'large' in case user doesn't specify\n  missionPatch: (mission, { size } = { size: 'LARGE' }) => {\n    return size === 'SMALL'\n      ? mission.missionPatchSmall\n      : mission.missionPatchLarge;\n  },\n},\n```\n\n_src/schema.js_\n```js\n  type Mutation {\n    # ... with rest of schema\n    missionPatch(mission: String, size: PatchSize): PatchSize\n  }\n```\n\nThe first argument passed into our resolver is the parent, which refers to the mission object. The second argument is the size we pass to our `missionPatch` field, which we use to determine which property on the mission object we want our field to resolve to.\n\nNow that we know how to add resolvers on types other than `Query` and `Mutation`, let's add some more resolvers to the `Launch` and `User` types. Copy this code into your resolver map:\n\n_src/resolvers.js_\n\n```js\nLaunch: {\n  isBooked: async (launch, _, { dataSources }) =>\n    dataSources.userAPI.isBookedOnLaunch({ launchId: launch.id }),\n},\nUser: {\n  trips: async (_, __, { dataSources }) => {\n    // get ids of launches by user\n    const launchIds = await dataSources.userAPI.getLaunchIdsByUser();\n\n    if (!launchIds.length) return [];\n\n    // look up those launches by their ids\n    return (\n      dataSources.launchAPI.getLaunchesByIds({\n        launchIds,\n      }) || []\n    );\n  },\n},\n```\n\nYou may be wondering where we're getting the user from in order to fetch their booked launches. This is a great observation - we still need to authenticate our user! Let's learn how to authenticate users and attach their user information to the context in the next section before we move onto `Mutation` resolvers.\n\n<h2 id=\"authentication\">Authenticate users</h2>\n\nAccess control is a feature that almost every app will have to handle at some point. In this tutorial, we're going to focus on teaching you the essential concepts of authenticating users instead of focusing on a specific implementation.\n\nHere are the steps you'll want to follow:\n\n1. The context function on your `ApolloServer` instance is called with the request object each time a GraphQL operation hits your API. Use this request object to read the authorization headers.\n1. Authenticate the user within the context function.\n1. Once the user is authenticated, attach the user to the object returned from the context function. This allows us to read the user's information from within our data sources and resolvers, so we can authorize whether they can access the data.\n\nLet's open up `src/index.js` and update the `context` function on `ApolloServer` to the code shown below:\n\n_src/index.js_\n\n```js line=1,4,8,10\nconst isEmail = require('isemail');\n\nconst server = new ApolloServer({\n  context: async ({ req }) => {\n    // simple auth check on every request\n    const auth = (req.headers && req.headers.authorization) || '';\n    const email = Buffer.from(auth, 'base64').toString('ascii');\n\n    // if the email isn't formatted validly, return null for user\n    if (!isEmail.validate(email)) return { user: null };\n    // find a user by their email\n    const users = await store.users.findOrCreate({ where: { email } });\n    const user = users && users[0] ? users[0] : null;\n\n    return { user: { ...user.dataValues } };\n  },\n  // .... with the rest of the server object code below, typeDefs, resolvers, etc....\n```\n\nJust like in the steps outlined above, we're checking the authorization headers on the request, authenticating the user by looking up their credentials in the database, and attaching the user to the `context`. While we definitely don't advocate using this specific implementation in production since it's not secure, all of the concepts outlined here are transferable to how you'll implement authentication in a real world application.\n\nHow do we create the token passed to the `authorization` headers? Let's move on to the next section, so we can write our resolver for the `login` mutation.\n\n<h2 id=\"mutation\">Write Mutation resolvers</h2>\n\nWriting `Mutation` resolvers is similar to the resolvers we've already written. First, let's write the `login` resolver to complete our authentication flow. Add the code below to your resolver map underneath the `Query` resolvers:\n\n_src/resolvers.js_\n\n```js\nMutation: {\n  login: async (_, { email }, { dataSources }) => {\n    const user = await dataSources.userAPI.findOrCreateUser({ email });\n    if (user) return Buffer.from(email).toString('base64');\n  }\n},\n```\n\nThe `login` resolver receives an email address and returns a token if a user exists. In a later section, we'll learn how to save that token on the client.\n\nNow, let's add the resolvers for `bookTrips` and `cancelTrip` to `Mutation`:\n\n_src/resolvers.js_\n\n```js\nMutation: {\n  bookTrips: async (_, { launchIds }, { dataSources }) => {\n    const results = await dataSources.userAPI.bookTrips({ launchIds });\n    const launches = await dataSources.launchAPI.getLaunchesByIds({\n      launchIds,\n    });\n\n    return {\n      success: results && results.length === launchIds.length,\n      message:\n        results.length === launchIds.length\n          ? 'trips booked successfully'\n          : `the following launches couldn't be booked: ${launchIds.filter(\n              id => !results.includes(id),\n            )}`,\n      launches,\n    };\n  },\n  cancelTrip: async (_, { launchId }, { dataSources }) => {\n    const result = await dataSources.userAPI.cancelTrip({ launchId });\n\n    if (!result)\n      return {\n        success: false,\n        message: 'failed to cancel trip',\n      };\n\n    const launch = await dataSources.launchAPI.getLaunchById({ launchId });\n    return {\n      success: true,\n      message: 'trip cancelled',\n      launches: [launch],\n    };\n  },\n},\n```\n\nBoth `bookTrips` and `cancelTrips` must return the properties specified on our `TripUpdateResponse` type from our schema, which contains a success indicator, a status message, and an array of launches that we've either booked or cancelled. The `bookTrips` mutation can get tricky because we have to account for a partial success where some launches could be booked and some could fail. Right now, we're simply indicating a partial success in the `message` field to keep it simple.\n\n<h3 id=\"mutation-playground\">Run mutations in the playground</h3>\n\nIt's time for the fun part - running our mutations in the playground! Go back to the playground in your browser and reload the schema with the little return arrow at the top on the right of the address line.\n\nGraphQL mutations are structured exactly like queries, except they use the `mutation` keyword. Let's copy the mutation below and run in the playground:\n\n```graphql\nmutation LoginUser {\n  login(email: \"daisy@apollographql.com\")\n}\n```\n\nYou should receive back a string that looks like this: `ZGFpc3lAYXBvbGxvZ3JhcGhxbC5jb20=`. Copy that string because we will need it for the next mutation.\n\nNow, let's try booking some trips. Only authorized users are permitted to book trips, however. Luckily, the playground has a section where we can paste in our authorization header from the previous mutation to authenticate us as a user. First, paste this mutation into the playground:\n\n```graphql\nmutation BookTrips {\n  bookTrips(launchIds: [67, 68, 69]) {\n    success\n    message\n    launches {\n      id\n    }\n  }\n}\n```\n\nNext, paste our authorization header into the HTTP Headers box at the bottom:\n\n```json\n{\n  \"authorization\": \"ZGFpc3lAYXBvbGxvZ3JhcGhxbC5jb20=\"\n}\n```\n\nThen, run the mutation. You should see a success message, along with the ids of the mutations we just booked. Testing mutations manually in the playground is a good way to explore our API, but in a real-world application, we should run automated tests so we can safely refactor our code. In the next section, you'll actually learn about running your graph in production instead of testing your graph.\n","path":"/tutorial/resolvers","filePath":"docs/source/tutorial/resolvers.md"},{"title":"4. Run your graph in production","description":"Learn about deployment and essential developer tooling","content":"\nTime to accomplish: _15 Minutes_\n\nGreat job for making it this far! We've already learned how to build a GraphQL API with Apollo, connect it to REST and SQL data sources, and send GraphQL queries. Now that we've completed building our graph, it's finally time to deploy it! 🎉\n\nAn Apollo GraphQL API can be deployed to any cloud service, such as Heroku, AWS Lambda, or Netlify. In this tutorial, we'll deploy our graph API to [Zeit Now](https://zeit.co/now). You will need to create a [Now account](https://zeit.co/signup) in order to follow these steps. If you haven't already created an [Apollo Engine](https://engine.apollographql.com/) account, you will need to sign up for one.\n\n<h2 id=\"engine\">Publish your schema to Engine</h2>\n\nBefore we deploy our app, we need to publish our schema to the Apollo Engine cloud service in order to power developer tooling like VSCode and keep track of schema changes. Just like npm is a registry for JavaScript packages, Apollo Engine contains a schema registry that makes it simple to pull the most recent schema from the cloud.\n\nIn a production application, you should set up this publishing script as part of your CI workflow. For now, we will run a script in our terminal that uses the Apollo CLI to publish our schema to Engine.\n\n<h3 id=\"api-key\">Get an Engine API key</h3>\n\nFirst, we need an Apollo Engine API key. Navigate to [Apollo Engine](https://engine.apollographql.com/), login, and click on New Service at the top. The prompt will instruct you to name your service. When you're finished, click Create Service. You'll see a key appear prefixed by `service:`. Copy that key so we can save it as an environment variable.\n\nLet's save our key as an environment variable. It's important to make sure we don't check our Engine API key into version control. Go ahead and make a copy of the `.env.example` file located in `server/` and call it `.env`. Add your Engine API key that you copied from the previous step to the file:\n\n```\nENGINE_API_KEY=service:<your-service-name>:<hash-from-apollo-engine>\n```\n\nThe entry should basically look like this:\n\n```\nENGINE_API_KEY=service:my-service-439:E4VSTiXeFWaSSBgFWXOiSA\n```\n\nOur key is now stored under the environment variable `ENGINE_API_KEY`.\n\n<h3 id=\"publish\">Check and publish with the Apollo CLI</h3>\n\nIt's time to publish our schema to Engine! First, start your server in one terminal window by running `npm start`. In another terminal window, run:\n\n```bash\nnpx apollo service:push --endpoint=http://localhost:4000\n```\n\n> npx is a tool bundled with npm for easily running packages that are not installed globally.\n\nThis command publishes your schema to the Apollo registry. Once your schema is uploaded, you should be able to see your schema in the [Apollo Engine](https://engine.apollographql.com/) explorer. In future steps, we will pull down our schema from Engine in order to power the Apollo VSCode extension.\n\nFor subsequent publishes, we may first want to check for any breaking changes in our new schema against the old version. In a terminal window, run:\n\n```bash\nnpx apollo service:check --endpoint=http://localhost:4000\n```\n\n<h3 id=\"benefits\">What are the benefits of Engine?</h3>\n\nPublishing your schema to Apollo Engine unlocks many features necessary for running a graph API in production. Some of these features include:\n\n- **Schema explorer:** With Engine's powerful schema registry, you can quickly explore all the types and fields in your schema with usage statistics on each field. This metric makes you understand the cost of a field. How expensive is a field? Is a certain field in so much demand?\n- **Schema history:** Apollo Engine’s schema history allows developers to confidently iterate a graph's schema by validating the new schema against field-level usage data from the previous schema. This empowers developers to avoid breaking changes by providing insights into which clients will be broken by a new schema.\n- **Performance analytics:** Fine-grained insights into every field, resolvers and operations of your graph's execution\n- **Client awareness:** Report client identity (name and version) to your server for insights on client activity.\n\nWe also want to be transparent that the features we just described, such as viewing specific execution traces and validating schema changes against recent operations, are only available on a paid plan. Individual developers just getting started with GraphQL probably don't need these features, but they become incredibly valuable as you're working on a team. Additionally, layering these paid features on top of our free developer tools like Apollo VSCode makes them more intelligent over time.\n\nWe're committed to helping you succeed in building and running an Apollo graph API. This is why features such as publishing and downloading schemas from the registry, our open source offerings like Apollo Client and Apollo Server, and certain developer tools like Apollo VSCode and Apollo DevTools will always be free forever.\n\n<h2 id=\"deploy\">Deploy your graph API</h2>\n\nTo deploy our app to Now, run the `now` command from the `server` directory of the app. The command may prompt you to login if you haven't already.\n\n```bash\n$ npx now\n```\n\nThe `now` command immediately deploys our graph API to the cloud and returns the hosted URL. Make sure you either copy the URL or run `npx now ls` in your terminal to retrieve the URL, since we'll need it in the following section when we build our client.\n\nCongrats on deploying your first Apollo graph API! 🚀 Let's move on to the second half of the tutorial where we connect the API we just built to a React app.\n","path":"/tutorial/production","filePath":"docs/source/tutorial/production.md"},{"title":"5. Connect your API to a client","description":"Hook up your graph to Apollo Client","content":"\nTime to accomplish: _10 Minutes_\n\nThe next half of this tutorial exclusively focuses on connecting a graph API to a frontend with Apollo Client. **Apollo Client** is a complete data management solution for any client. It's view-layer agnostic, which means it can integrate with React, Vue, Angular, or even vanilla JS. Thanks to its intelligent cache, Apollo Client offers a single source of truth for all of the local and remote data in your application.\n\nWhile Apollo Client works with any view layer, it's most commonly used with React. In this section, you'll learn how to connect the graph API you just built in the previous half of this tutorial to a React app. Even if you're more comfortable with Vue or Angular, you should still be able to follow many of the examples since the concepts are the same. Along the way, you'll also learn how to build essential features like authentication and pagination, as well as tips for optimizing your workflow.\n\n<h2 id=\"dev-environment\">Set up your development environment</h2>\n\nFor this half of the tutorial, we will be working in the `client/` folder of the project. You should have the project already from the server portioned, but if you don't, make sure to clone [the tutorial](https://github.com/apollographql/fullstack-tutorial/). From the root of the project, run:\n\n```bash\ncd start/client && npm install\n```\n\nNow, our dependencies are installed. Here are the packages we will be using to build out our frontend:\n\n- `apollo-client`: A complete data management solution with an intelligent cache. In this tutorial, we will be using the Apollo Client 3.0 preview since it includes local state management capabilities and sets your cache up for you.\n- `react-apollo`: The view layer integration for React that exports components such as `Query` and `Mutation`\n- `graphql-tag`: The tag function `gql` that we use to wrap our query strings in order to parse them into an AST\n\n<h3 id=\"vscode\">Configure Apollo VSCode</h3>\n\nWhile Apollo VSCode is not required to successfully complete the tutorial, setting it up unlocks a lot of helpful features such as autocomplete for operations, jump to fragment definitions, and more.\n\nFirst, make a copy of the `.env.example` file located in `client/` and call it `.env`. Add your Engine API key that you already created in step #4 to the file:\n\n```\nENGINE_API_KEY=service:<your-service-name>:<hash-from-apollo-engine>\n```\n\nThe entry should basically look something like this:\n\n```\nENGINE_API_KEY=service:my-service-439:E4VSTiXeFWaSSBgFWXOiSA\n```\n\nOur key is now stored under the environment variable `ENGINE_API_KEY`. Apollo VSCode uses this API key to pull down your schema from the registry.\n\nNext, create an Apollo config file called `apollo.config.js`. This config file is how you configure both the Apollo VSCode extension and CLI. Paste the snippet below into the file:\n\n```js\nmodule.exports = {\n  client: {\n    name: 'Space Explorer [web]',\n    service: 'space-explorer',\n  },\n};\n```\n\nGreat, we're all set up! Let's dive into building our first client.\n\n<h2 id=\"apollo-client-setup\">Create an Apollo Client</h2>\n\nNow that we have installed the necessary packages, let's create an `ApolloClient` instance.\n\nNavigate to `src/index.js` so we can create our client. The `uri` that we pass in is the graph endpoint from the service you deployed in step 4.\n\nIf you didn't complete the server portion, you can use the `uri` from the code below. Otherwise, use your own deployment's URL, which may be different than the one below. Navigate to `src/index.js` and copy the code below:\n\n_src/index.js_\n\n```js\nimport { ApolloClient } from 'apollo-client';\nimport { InMemoryCache } from 'apollo-cache-inmemory';\nimport { HttpLink } from 'apollo-link-http';\n\nconst cache = new InMemoryCache();\nconst link = new HttpLink({\n  uri: 'http://localhost:4000/'\n})\nconst client = new ApolloClient({\n  cache,\n  link\n})\n\n```\n\nIn just a few lines of code, our client is ready to fetch data! Let's try making a query in the next section.\n\n<h2 id=\"first-query\">Make your first query</h2>\n\nBefore we show you how to use the React integration for Apollo, let's send a query with vanilla JavaScript.\n\nWith a `client.query()` call, we can query our graph's API. Add the following line of code to your imports in `src/index.js`.\n\n_src/index.js_\n\n```js line=1\nimport gql from \"graphql-tag\";\n```\nAnd add this code to the bottom of `index.js`:\n\n_src/index.js_\n```\n// ... above is the instantiation of the client object.\nclient\n  .query({\n    query: gql`\n      query GetLaunch {\n        launch(id: 56) {\n          id\n          mission {\n            name\n          }\n        }\n      }\n    `\n  })\n  .then(result => console.log(result));\n```\n\nOpen up your console and run `npm start`. This will compile your client app. Once it is finished, your browser should open to `http://localhost:3000/` automatically. When the index page opens, open up your [Developer Tools console](https://developers.google.com/web/tools/chrome-devtools/console/) and you should see an object with a `data` property containing the result of our query. You'll also see some other properties, like `loading` and `networkStatus`. This is because Apollo Client tracks the loading state of your query for you.\n\nApollo Client is designed to fetch graph data from any JavaScript frontend. No frameworks needed. However, there are view layer integrations for different frameworks that makes it easier to bind queries to the UI.\n\nGo ahead and delete the `client.query()` call you just made and the `gql` import statement. Now, we'll connect our client to React.\n\n<h2 id=\"react-apollo\">Connect your client to React</h2>\n\nConnecting Apollo Client to our React app with `react-apollo` allows us to easily bind GraphQL operations to our UI.\n\nTo connect Apollo Client to React, we will wrap our app in the `ApolloProvider` component exported from the `react-apollo` package and pass our client to the `client` prop. The `ApolloProvider` component is similar to React’s context provider. It wraps your React app and places the client on the context, which allows you to access it from anywhere in your component tree.\n\nOpen `src/index.js` and add the following lines of code:\n\n_src/index.js_\n\n```js lines=1,4,6\nimport { ApolloProvider } from 'react-apollo';\nimport React from 'react';\nimport ReactDOM from 'react-dom';\nimport Pages from './pages';\n\n// previous variable declarations\n\nReactDOM.render(\n  <ApolloProvider client={client}>\n    <Pages />\n  </ApolloProvider>, document.getElementById('root'));\n```\n\nNow, we're ready to start building our first `Query` components in the next section.\n","path":"/tutorial/client","filePath":"docs/source/tutorial/client.md"},{"title":"6. Fetch data with queries","description":"Learn how to fetch data with the Query component","content":"\n Time to accomplish: _15 Minutes_\n\nApollo Client simplifies fetching data from a graph API because it intelligently caches your data, as well as tracks loading and error state. In the previous section, we learned how to fetch a sample query with Apollo Client without using a view integration. In this section, we'll learn how to use the `Query` component from `react-apollo` to fetch more complex queries and execute features like pagination.\n\n<h2 id=\"fetch-data\">The Query component</h2>\n\nThe `Query` component is one of the most important building blocks of an Apollo app. It's a React component that fetches a GraphQL query and exposes the result so you can render your UI based on the data it returns.\n\nThe `Query` component uses the **render prop** pattern to fetch and load data from queries into our UI. The render prop pattern provides the ability to add a function as a child to our `Query` component that will notify React about what you want to render. It exposes the `error`, `loading` and `data` on a result object that is passed into the render prop function. Let's see an example:\n\n<h2 id=\"launches\">Fetching a list</h2>\n\nTo create a `Query` component, import `Query` from `react-apollo`, pass your query wrapped with `gql` to `this.props.query`, and provide a render prop function to `this.props.children` that uses the `loading`, `data`, and `error` properties on the result object to render UI in your app.\n\nFirst, we're going to build a GraphQL query that fetches a list of launches. We're also going to import some components that we will need in the next step. Navigate to `src/pages/launches.js` to get started and copy the code below into the file.\n\n_src/pages/launches.js_\n\n```js\nimport React, { Fragment } from 'react';\nimport { Query } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { LaunchTile, Header, Button, Loading } from '../components';\n\nconst GET_LAUNCHES = gql`\n  query launchList($after: String) {\n    launches(after: $after) {\n      cursor\n      hasMore\n      launches {\n        id\n        isBooked\n        rocket {\n          id\n          name\n        }\n        mission {\n          name\n          missionPatch\n        }\n      }\n    }\n  }\n`;\n```\n\nHere, we're defining a query to fetch a list of launches by calling the `launches` query from our schema. The `launches` query returns an object type with a list of launches, in addition to the `cursor` of the paginated list and whether or not the list `hasMore` launches. We need to wrap the query with the `gql` function in order to parse it into an AST.\n\nNow, let's pass that query to Apollo's `Query` component to render the list:\n\n_src/pages/launches.js_\n\n```js\nexport default function Launches() {\n  return (\n    <Query query={GET_LAUNCHES}>\n      {({ data, loading, error }) => {\n        if (loading) return <Loading />;\n        if (error) return <p>ERROR</p>;\n\n        return (\n          <Fragment>\n            <Header />\n            {data.launches &&\n              data.launches.launches &&\n              data.launches.launches.map(launch => (\n                <LaunchTile\n                  key={launch.id}\n                  launch={launch}\n                />\n              ))}\n          </Fragment>\n        );\n      }}\n    </Query>\n  );\n};\n```\n\nTo render the list, we pass the `GET_LAUNCHES` query from the previous step into our `Query` component. We then define a render prop function as the child of `Query` that's called with the state of our query (`loading`, `error`, and `data`). Depending on the state, we either render a loading indicator, an error message, or a list of launches.\n\nWe're not done yet! Right now, this query is only fetching the first 20 launches from the list. To fetch the full list of launches, we need to build a pagination feature that displays a `Load More` button for loading more items on the screen. Let's learn how!\n\n<h3 id=\"pagination\">Build a paginated list</h3>\n\nApollo Client has built-in helpers to make adding pagination to our app much easier than it would be if we were writing the logic ourselves.\n\nTo build a paginated list with Apollo, we first need to destructure the `fetchMore` function from the `Query` render prop function.\n\n_src/pages/launches.js_\n\n```js lines=4\nexport default function Launches() {\n  return (\n    <Query query={GET_LAUNCHES}>\n      {({ data, loading, error, fetchMore }) => {\n        // same as above\n      }}\n    </Query>\n  );\n};\n```\n\nNow that we have `fetchMore`, let's connect it to a Load More button to fetch more items when it's clicked. To do this, we will need to specify an `updateQuery` function on the return object from `fetchMore` that tells the Apollo cache how to update our query with the new items we're fetching.\n\nCopy the code below and add it above the closing `</Fragment>` tag in the render prop function we added in the previous step.\n\n_src/pages/launches.js_\n\n```js lines=5,9\n{data.launches &&\n  data.launches.hasMore && (\n    <Button\n      onClick={() =>\n        fetchMore({\n          variables: {\n            after: data.launches.cursor,\n          },\n          updateQuery: (prev, { fetchMoreResult, ...rest }) => {\n            if (!fetchMoreResult) return prev;\n            return {\n              ...fetchMoreResult,\n              launches: {\n                ...fetchMoreResult.launches,\n                launches: [\n                  ...prev.launches.launches,\n                  ...fetchMoreResult.launches.launches,\n                ],\n              },\n            };\n          },\n        })\n      }\n    >\n      Load More\n    </Button>\n  )\n}\n```\n\nFirst, we check to see if we have more launches available in our query. If we do, we render a button with a click handler that calls the `fetchMore` function from Apollo. The `fetchMore` function receives new variables for the list of launches query, which is represented by our cursor.\n\nWe also define the `updateQuery` function to tell Apollo how to update the list of launches in the cache. To do this, we take the previous query result and combine it with the new query result from `fetchMore`.\n\nIn the next step, we'll learn how to wire up the launch detail page to display a single launch when an item in the list is clicked.\n\n<h2 id=\"launch\">Fetching a single launch</h2>\n\nLet's navigate to `src/pages/launch.js` to build out our detail page. First, we should import some components and define our GraphQL query to get the launch details.\n\n_src/pages/launch.js_\n\n```js\nimport React, { Fragment } from 'react';\nimport { Query } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport Loading from '../components/loading';\nimport Header from '../components/header';\nimport ActionButton from '../containers/action-button';\nimport LaunchDetail from '../components/launch-detail';\n\nexport const GET_LAUNCH_DETAILS = gql`\n  query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      id\n      site\n      isBooked\n      rocket {\n        id\n        name\n        type\n      }\n      mission {\n        name\n        missionPatch\n      }\n    }\n  }\n`;\n```\n\nNow that we have a query, let's render a `Query` component to execute it. This time, we'll also need to pass in the `launchId` as a variable to the query, which we'll do by adding a `variables` prop to `Query`. The `launchId` comes through as a prop from the router.\n\n_src/pages/launch.js_\n\n```js\nexport default function Launch({ launchId }) {\n  return (\n    <Query query={GET_LAUNCH_DETAILS} variables={{ launchId }}>\n      {({ data, loading, error }) => {\n        if (loading) return <Loading />;\n        if (error) return <p>ERROR: {error.message}</p>;\n\n        return (\n          <Fragment>\n            <Header image={data.launch.mission.missionPatch}>\n              {data.launch.mission.name}\n            </Header>\n            <LaunchDetail {...data.launch} />\n            <ActionButton {...data.launch} />\n          </Fragment>\n        );\n      }}\n    </Query>\n  );\n}\n```\n\nJust like before, we use the status of the query to render either a `loading` or `error` state, or data when the query completes.\n\n<h3 id=\"fragments\">Using fragments to share code</h3>\n\nYou may have noticed that the queries for fetching a list of launches and fetching a launch detail share a lot of the same fields. When we have two GraphQL operations that contain the same fields, we can use a **fragment** to share fields between the two.\n\nTo learn how to build a fragment, navigate to `src/pages/launches.js` and copy the code below into the file:\n\n_`src/pages/launches.js`_\n\n```js\nexport const LAUNCH_TILE_DATA = gql`\n  fragment LaunchTile on Launch {\n    id\n    isBooked\n    rocket {\n      id\n      name\n    }\n    mission {\n      name\n      missionPatch\n    }\n  }\n`;\n```\n\nWe define a GraphQL fragment by giving it a name (`LaunchTile`) and defining it on a type on our schema (`Launch`). The name we give our fragment can be anything, but the type must correspond to a type in our schema.\n\nTo use our fragment in our query, we import it into the GraphQL document and use the spread operator to spread the fields into our query:\n\n_`src/pages/launches.js`_\n\n```js lines=6,10\nconst GET_LAUNCHES = gql`\n  query launchList($after: String) {\n    launches(after: $after) {\n      cursor\n      hasMore\n      launches {\n        ...LaunchTile\n      }\n    }\n  }\n  ${LAUNCH_TILE_DATA}\n`;\n```\n\nLet's use our fragment in our launch detail query too. Be sure to import the fragment from the `launches` page before you use it:\n\n```js lines=1,10,13\nimport { LAUNCH_TILE_DATA } from './launches';\n\nexport const GET_LAUNCH_DETAILS = gql`\n  query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      site\n      rocket {\n        type\n      }\n      ...LaunchTile\n    }\n  }\n  ${LAUNCH_TILE_DATA}\n`;\n```\n\nGreat, now we've successfully refactored our queries to use fragments. Fragments are a helpful tool that you'll use a lot as you're building GraphQL queries and mutations.\n\n<h3 id=\"fetch-policy\">Customizing the fetch policy</h3>\n\nSometimes, it's useful to tell Apollo Client to bypass the cache altogether if you have some data that constantly needs to be refreshed. We can do this by customizing the `Query` component's `fetchPolicy`.\n\nFirst, let's navigate to `src/pages/profile.js` and write our query:\n\n_src/pages/profile.js_\n\n```js\nimport React, { Fragment } from 'react';\nimport { Query } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { Loading, Header, LaunchTile } from '../components';\nimport { LAUNCH_TILE_DATA } from './launches';\n\nconst GET_MY_TRIPS = gql`\n  query GetMyTrips {\n    me {\n      id\n      email\n      trips {\n        ...LaunchTile\n      }\n    }\n  }\n  ${LAUNCH_TILE_DATA}\n`;\n```\n\nNext, let's render a `Query` component to fetch a logged in user's list of trips. By default, Apollo Client's fetch policy is `cache-first`, which means it checks the cache to see if the result is there before making a network request. Since we want this list to always reflect the newest data from our graph API, we set the `fetchPolicy` for this query to `network-only`:\n\n_src/pages/profile.js_\n\n```js lines=3\nexport default function Profile() {\n  return (\n    <Query query={GET_MY_TRIPS} fetchPolicy=\"network-only\">\n      {({ data, loading, error }) => {\n        if (loading) return <Loading />;\n        if (error) return <p>ERROR: {error.message}</p>;\n\n        return (\n          <Fragment>\n            <Header>My Trips</Header>\n            {data.me && data.me.trips.length ? (\n              data.me.trips.map(launch => (\n                <LaunchTile key={launch.id} launch={launch} />\n              ))\n            ) : (\n              <p>You haven't booked any trips</p>\n            )}\n          </Fragment>\n        );\n      }}\n    </Query>\n  );\n}\n```\n\nIf you try to render this query, you'll notice that it returns null. This is because we need to implement our login feature first. We're going to tackle login in the next section.\n\nNow that we've learned how to build `Query` components that can fetch a paginated list, share fragments, and customize the fetch policy, it's time to progress to the next section so we can learn how to update data with mutations!\n","path":"/tutorial/queries","filePath":"docs/source/tutorial/queries.md"},{"title":"7. Update data with mutations","description":"Learn how to update data with the Mutation component","content":"\nTime to accomplish: _12 Minutes_\n\nWith Apollo Client, updating data from a graph API is as simple as calling a function. Additionally, the Apollo Client cache is smart enough to automatically update in most cases. In this section, we'll learn how to use the `Mutation` component from `react-apollo` to login a user.\n\n<h2 id=\"query-component\">What is a Mutation component?</h2>\n\nThe `Mutation` component is another important building block in an Apollo app. It's a React component that provides a function to execute a GraphQL mutation. Additionally, it tracks the loading, completion, and error state of that mutation.\n\nUpdating data with a `Mutation` component from `react-apollo` is very similar to fetching data with a `Query` component. The main difference is that the first argument to the `Mutation` render prop function is a **mutate function** that actually triggers the mutation when it is called. The second argument to the `Mutation` render prop function is a result object that contains loading and error state, as well as the return value from the mutation. Let's see an example:\n\n<h2 id=\"fetch-data\">Update data with Mutation</h2>\n\nThe first step is defining our GraphQL mutation. To start, navigate to `src/pages/login.js` and copy the code below so we can start building out the login screen:\n\n_src/pages/login.js_\n\n```js\nimport React from 'react';\nimport { Mutation, ApolloConsumer } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { LoginForm, Loading } from '../components';\n\nconst LOGIN_USER = gql`\n  mutation login($email: String!) {\n    login(email: $email)\n  }\n`;\n```\n\nJust like before, we're using the `gql` function to wrap our GraphQL mutation so it can be parsed into an AST. We're also importing some components that we'll use in the next steps. Now, let's bind this mutation to our component by passing it to the `mutation` prop:\n\n_src/pages/login.js_\n\n```js\nexport default function Login() {\n  return (\n    <Mutation mutation={LOGIN_USER}>\n      {(login, { data }) => <LoginForm login={login} />}\n    </Mutation>\n  );\n}\n```\n\nOur `Mutation` component takes a render prop function as a child that exposes a mutate function (`login`) and the data object returned from the mutation. Finally, we pass our login function to the `LoginForm` component.\n\nTo create a better experience for our users, we want to persist the login between sessions. In order to do that, we need to save our login token to `localStorage`. Let's learn how we can use the `onCompleted` handler on `Mutation` to persist our login:\n\n<h3 id=\"apolloconsumer\">Expose Apollo Client with ApolloConsumer</h3>\n\nOne of the main functions of `react-apollo` is that it puts your `ApolloClient` instance on React's context. Sometimes, we need to access the `ApolloClient` instance to directly call a method that isn't exposed by the `react-apollo` helper components. The `ApolloConsumer` component can help us access the client.\n\n`ApolloConsumer` takes a render prop function as a child that is called with the client instance. Let's wrap our `Mutation` component with `ApolloConsumer` to expose the client. Next, we want to pass an `onCompleted` callback to `Mutation` that will be called once the mutation is complete with its return value. This callback is where we will save the login token to `localStorage`.\n\nIn our `onCompleted` handler, we also call `client.writeData` to write local data to the Apollo cache indicating that the user is logged in. This is an example of a **direct write** that we'll explore further in the next section on local state management.\n\n_src/pages/login.js_\n\n```js lines=3,4,7-10,22\nexport default function Login() {\n  return (\n    <ApolloConsumer>\n      {client => (\n        <Mutation\n          mutation={LOGIN_USER}\n          onCompleted={({ login }) => {\n            localStorage.setItem('token', login);\n            client.writeData({ data: { isLoggedIn: true } });\n          }}\n        >\n          {(login, { loading, error }) => {\n            // this loading state will probably never show, but it's helpful to\n            // have for testing\n            if (loading) return <Loading />;\n            if (error) return <p>An error occurred</p>;\n\n            return <LoginForm login={login} />;\n          }}\n        </Mutation>\n      )}\n    </ApolloConsumer>\n  );\n}\n```\n\n<h3 id=\"authenticate\">Attach authorization headers to the request</h3>\n\nWe're almost done completing our login feature! Before we do, we need to attach our token to the GraphQL request's headers so our server can authorize the user. To do this, navigate to `src/index.js` where we create our `ApolloClient` and replace the code below for the constructor:\n\n_src/index.js_\n\n```js lines=5,6\nconst client = new ApolloClient({\n  cache,\n  link: new HttpLink({\n    uri: 'http://localhost:4000/graphql',\n    headers: {\n      authorization: localStorage.getItem('token'),\n    },\n  }),\n});\n\ncache.writeData({\n  data: {\n    isLoggedIn: !!localStorage.getItem('token'),\n    cartItems: [],\n  },\n});\n```\n\nSpecifying the `headers` option on `HttpLink` allows us to read the token from `localStorage` and attach it to the request's headers each time a GraphQL operation is made.\n\nIn the next section, we'll add the `<Login>` form to the user interface. For that, we need to learn how Apollo allows us to manage local state in our app.\n","path":"/tutorial/mutations","filePath":"docs/source/tutorial/mutations.md"},{"title":"8. Manage local state","description":"How to store and query local data in the Apollo cache","content":"\nTime to accomplish: _15 Minutes_\n\nIn almost every app we build, we display a combination of remote data from our graph API and local data such as network status, form state, and more. What's awesome about Apollo Client is that it allows us to store local data inside the Apollo cache and query it alongside our remote data with GraphQL.\n\nWe recommend managing local state in the Apollo cache instead of bringing in another state management library like Redux so the Apollo cache can be a single source of truth.\n\nManaging local data with Apollo Client is very similar to how you've already managed remote data in this tutorial. You'll write a client schema and resolvers for your local data. You'll also learn to query it with GraphQL just by specifying the `@client` directive. Let's dive in!\n\n<h2 id=\"local-schema\">Write a local schema</h2>\n\nJust like how a schema is the first step toward defining our data model on the server, writing a local schema is the first step we take on the client.\n\nNavigate to `src/resolvers.js` and copy the following code to create your client schema (as well as blank client resolvers for later):\n\n_src/resolvers.js_\n\n```js\nimport gql from 'graphql-tag';\n\nexport const typeDefs = gql`\n  extend type Query {\n    isLoggedIn: Boolean!\n    cartItems: [ID!]!\n  }\n\n  extend type Launch {\n    isInCart: Boolean!\n  }\n\n  extend type Mutation {\n    addOrRemoveFromCart(id: ID!): [Launch]\n  }\n`;\n\nexport const resolvers = {};\n```\n\nTo build a client schema, we **extend** the types of our server schema and wrap it with the `gql` function. Using the extend keyword allows us to combine both schemas inside developer tooling like Apollo VSCode and Apollo DevTools.\n\nWe can also add local fields to server data by extending types from our server. Here, we're adding the `isInCart` local field to the `Launch` type we receive back from our graph API.\n\n<h2 id=\"store-initialization\">Initialize the store</h2>\n\nNow that we've created our client schema, let's learn how to initialize the store. Since queries execute as soon as the component mounts, it's important for us to warm the Apollo cache with some default state so those queries don't error out. We will need to write initial data to the cache for both `isLoggedIn` and `cartItems`:\n\nJump back to `src/index.js` and notice we had already added a `cache.writeData` call to prepare the cache in the last section. While we're here, make sure to also import the `typeDefs` and `resolvers` that we just created so we can use them later:\n\n_src/index.js_\n\n```js line=1,11-12,15-20\nimport { resolvers, typeDefs } from './resolvers';\n\nconst client = new ApolloClient({\n  cache,\n  link: new HttpLink({\n    uri: 'http://localhost:4000/graphql',\n    headers: {\n      authorization: localStorage.getItem('token'),\n    },\n  }),\n  typeDefs,\n  resolvers,\n});\n\ncache.writeData({\n  data: {\n    isLoggedIn: !!localStorage.getItem('token'),\n    cartItems: [],\n  },\n});\n```\n\nNow that we've added default state to the Apollo cache, let's learn how to query local data from within our React components.\n\n<h2 id=\"local-query\">Query local data</h2>\n\nQuerying local data from the Apollo cache is almost the same as querying remote data from a graph API. The only difference is that you add a `@client` directive to a local field to tell Apollo Client to pull it from the cache.\n\nLet's look at an example where we query the `isLoggedIn` field we wrote to the cache in the last mutation exercise.\n\n_src/index.js_\n\n```js line=8,17-19\nimport { Query, ApolloProvider } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport Pages from './pages';\nimport Login from './pages/login';\nimport injectStyles from './styles';\n\nconst IS_LOGGED_IN = gql`\n  query IsUserLoggedIn {\n    isLoggedIn @client\n  }\n`;\n\ninjectStyles();\nReactDOM.render(\n  <ApolloProvider client={client}>\n    <Query query={IS_LOGGED_IN}>\n      {({ data }) => (data.isLoggedIn ? <Pages /> : <Login />)}\n    </Query>\n  </ApolloProvider>,\n  document.getElementById('root'),\n);\n```\n\nFirst, we create our `IsUserLoggedIn` local query by adding the `@client` directive to the `isLoggedIn` field. Then, we render a `Query` component, pass our local query in, and specify a render prop function that renders either a login screen or the homepage depending if the user is logged in. Since cache reads are synchronous, we don't have to account for any loading state.\n\nLet's look at another example of a component that queries local state in `src/pages/cart.js`. Just like before, we create our query:\n\n_src/pages/cart.js_\n\n```js\nimport React, { Fragment } from 'react';\nimport { Query } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { Header, Loading } from '../components';\nimport { CartItem, BookTrips } from '../containers';\n\nexport const GET_CART_ITEMS = gql`\n  query GetCartItems {\n    cartItems @client\n  }\n`;\n```\n\nNext, we render our `Query` component and bind it to our `GetCartItems` query:\n\n_src/pages/cart.js_\n\n```js\nexport default function Cart() {\n  return (\n    <Query query={GET_CART_ITEMS}>\n      {({ data, loading, error }) => {\n        if (loading) return <Loading />;\n        if (error) return <p>ERROR: {error.message}</p>;\n        return (\n          <Fragment>\n            <Header>My Cart</Header>\n            {!data.cartItems || !data.cartItems.length ? (\n              <p data-testid=\"empty-message\">No items in your cart</p>\n            ) : (\n              <Fragment>\n                {data.cartItems.map(launchId => (\n                  <CartItem key={launchId} launchId={launchId} />\n                ))}\n                <BookTrips cartItems={data.cartItems} />\n              </Fragment>\n            )}\n          </Fragment>\n        );\n      }}\n    </Query>\n  );\n}\n```\n\nIt's important to note that you can mix local queries with remote queries in a single GraphQL document. Now that you're a pro at querying local data with GraphQL, let's learn how to add local fields to server data.\n\n<h3 id=\"virtual-fields\">Adding virtual fields to server data</h3>\n\nOne of the unique advantages of managing your local data with Apollo Client is that you can add **virtual fields** to data you receive back from your graph API. These fields only exist on the client and are useful for decorating server data with local state. In our example, we're going to add an `isInCart` virtual field to our `Launch` type.\n\nTo add a virtual field, first extend the type of the data you're adding the field to in your client schema. Here, we're extending the `Launch` type:\n\n_src/resolvers.js_\n\n```js\nimport gql from 'graphql-tag';\n\nexport const schema = gql`\n  extend type Launch {\n    isInCart: Boolean!\n  }\n`;\n```\n\nNext, specify a client resolver on the `Launch` type to tell Apollo Client how to resolve your virtual field:\n\n_src/resolvers.js_\n\n```js\nexport const resolvers = {\n  Launch: {\n    isInCart: (launch, _, { cache }) => {\n      const { cartItems } = cache.readQuery({ query: GET_CART_ITEMS });\n      return cartItems.includes(launch.id);\n    },\n  },\n};\n```\n\nWe're going to learn more about client resolvers in the section below. The important thing to note is that the resolver API on the client is the same as the resolver API on the server.\n\nNow, you're ready to query your virtual field on the launch detail page! Similar to the previous examples, just add your virtual field to a query and specify the `@client` directive.\n\n_src/pages/launch.js_\n\n```js line=4\nexport const GET_LAUNCH_DETAILS = gql`\n  query LaunchDetails($launchId: ID!) {\n    launch(id: $launchId) {\n      isInCart @client\n      site\n      rocket {\n        type\n      }\n      ...LaunchTile\n    }\n  }\n  ${LAUNCH_TILE_DATA}\n`;\n```\n\n<h2 id=\"local-mutation\">Update local data</h2>\n\nUp until now, we've focused on querying local data from the Apollo cache. Apollo Client also lets you update local data in the cache with either **direct cache writes** or **client resolvers**. Direct writes are typically used to write simple booleans or strings to the cache whereas client resolvers are for more complicated writes such as adding or removing data from a list.\n\n<h3 id=\"direct-writes\">Direct cache writes</h3>\n\nDirect cache writes are convenient when you want to write a simple field, like a boolean or a string, to the Apollo cache. We perform a direct write by calling `client.writeData()` and passing in an object with a data property that corresponds to the data we want to write to the cache. We've already seen an example of a direct write, when we called `client.writeData` in the `onCompleted` handler for the login `Mutation` component. Let's look at a similar example, where we copy the code below to create a logout button:\n\n_src/containers/logout-button.js_\n\n```js line=14\nimport React from 'react';\nimport styled from 'react-emotion';\nimport { ApolloConsumer } from 'react-apollo';\n\nimport { menuItemClassName } from '../components/menu-item';\nimport { ReactComponent as ExitIcon } from '../assets/icons/exit.svg';\n\nexport default function LogoutButton() {\n  return (\n    <ApolloConsumer>\n      {client => (\n        <StyledButton\n          onClick={() => {\n            client.writeData({ data: { isLoggedIn: false } });\n            localStorage.clear();\n          }}\n        >\n          <ExitIcon />\n          Logout\n        </StyledButton>\n      )}\n    </ApolloConsumer>\n  );\n}\n\nconst StyledButton = styled('button')(menuItemClassName, {\n  background: 'none',\n  border: 'none',\n  padding: 0,\n});\n```\n\nWhen we click the button, we perform a direct cache write by calling `client.writeData` and passing in a data object that sets the `isLoggedIn` boolean to false.\n\nWe can also perform direct writes within the `update` function of a `Mutation` component. The `update` function allows us to manually update the cache after a mutation occurs without refetching data. Let's look at an example in `src/containers/book-trips.js`:\n\n_src/containers/book-trips.js_\n\n```js line=30-32\nimport React from 'react';\nimport { Mutation } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport Button from '../components/button';\nimport { GET_LAUNCH } from './cart-item';\n\nconst BOOK_TRIPS = gql`\n  mutation BookTrips($launchIds: [ID]!) {\n    bookTrips(launchIds: $launchIds) {\n      success\n      message\n      launches {\n        id\n        isBooked\n      }\n    }\n  }\n`;\n\nexport default function BookTrips({ cartItems }) {\n  return (\n    <Mutation\n      mutation={BOOK_TRIPS}\n      variables={{ launchIds: cartItems }}\n      refetchQueries={cartItems.map(launchId => ({\n        query: GET_LAUNCH,\n        variables: { launchId },\n      }))}\n      update={cache => {\n        cache.writeData({ data: { cartItems: [] } });\n      }}\n    >\n      {(bookTrips, { data, loading, error }) =>\n        data && data.bookTrips && !data.bookTrips.success ? (\n          <p data-testid=\"message\">{data.bookTrips.message}</p>\n        ) : (\n          <Button onClick={bookTrips} data-testid=\"book-button\">\n            Book All\n          </Button>\n        )\n      }\n    </Mutation>\n  );\n}\n```\n\nIn this example, we're directly calling `cache.writeData` to reset the state of the `cartItems` after the `BookTrips` mutation is sent to the server. This direct write is performed inside of the update function, which is passed our Apollo Client instance.\n\n<h3 id=\"resolvers\">Local resolvers</h3>\n\nWe're not done yet! What if we wanted to perform a more complicated local data update such as adding or removing items from a list? For this situation, we'll use a local resolver. Local resolvers have the same function signature as remote resolvers (`(parent, args, context, info) => data`). The only difference is that the Apollo cache is already added to the context for you. Inside your resolver, you'll use the cache to read and write data.\n\nLet's write the local resolver for the `addOrRemoveFromCart` mutation. You should place this resolver underneath the `Launch` resolver we wrote earlier.\n\n_src/resolvers.js_\n\n```js\nexport const resolvers = {\n  Mutation: {\n    addOrRemoveFromCart: (_, { id }, { cache }) => {\n      const { cartItems } = cache.readQuery({ query: GET_CART_ITEMS });\n      const data = {\n        cartItems: cartItems.includes(id)\n          ? cartItems.filter(i => i !== id)\n          : [...cartItems, id],\n      };\n      cache.writeQuery({ query: GET_CART_ITEMS, data });\n      return data.cartItems;\n    },\n  },\n};\n```\n\nIn this resolver, we destructure the Apollo `cache` from the context in order to read the query that fetches cart items. Once we have our cart data, we either remove or add the cart item's `id` passed into the mutation to the list. Finally, we return the updated list from the mutation.\n\nLet's see how we call the `addOrRemoveFromCart` mutation in a component:\n\n_src/containers/action-button.js_\n\n```js\nimport gql from 'graphql-tag';\n\nconst TOGGLE_CART = gql`\n  mutation addOrRemoveFromCart($launchId: ID!) {\n    addOrRemoveFromCart(id: $launchId) @client\n  }\n`;\n```\n\nJust like before, the only thing we need to add to our mutation is a `@client` directive to tell Apollo to resolve this mutation from the cache instead of a remote server.\n\nNow that our local mutation is complete, let's build out the rest of the `ActionButton` component so we can finish building the cart:\n\n_src/containers/action-button.js_\n\n```js\nimport React from 'react';\nimport { Mutation } from 'react-apollo';\nimport gql from 'graphql-tag';\n\nimport { GET_LAUNCH_DETAILS } from '../pages/launch';\nimport Button from '../components/button';\n\nconst CANCEL_TRIP = gql`\n  mutation cancel($launchId: ID!) {\n    cancelTrip(launchId: $launchId) {\n      success\n      message\n      launches {\n        id\n        isBooked\n      }\n    }\n  }\n`;\n\nexport default function ActionButton({ isBooked, id, isInCart }) {\n  return (\n    <Mutation\n      mutation={isBooked ? CANCEL_TRIP : TOGGLE_CART}\n      variables={{ launchId: id }}\n      refetchQueries={[\n        {\n          query: GET_LAUNCH_DETAILS,\n          variables: { launchId: id },\n        },\n      ]}\n    >\n      {(mutate, { loading, error }) => {\n        if (loading) return <p>Loading...</p>;\n        if (error) return <p>An error occurred</p>;\n\n        return (\n          <div>\n            <Button\n              onClick={mutate}\n              isBooked={isBooked}\n              data-testid={'action-button'}\n            >\n              {isBooked\n                ? 'Cancel This Trip'\n                : isInCart\n                ? 'Remove from Cart'\n                : 'Add to Cart'}\n            </Button>\n          </div>\n        );\n      }}\n    </Mutation>\n  );\n}\n```\n\nIn this example, we're using the `isBooked` prop passed into the component to determine which mutation we should fire. Just like remote mutations, we can pass in our local mutations to the same `Mutation` component.\n\n---\n\nCongratulations! 🎉 You've officially made it to the end of the Apollo platform tutorial. In the final section, we're going to recap what we just learned and give you guidance on what you should learn next.\n","path":"/tutorial/local-state","filePath":"docs/source/tutorial/local-state.md"}]},{"title":"Platform","pages":[{"title":"Tracking your GraphQL schema","description":"A central hub for your GraphQL API","content":"\nApollo includes a schema registry that serves as a [central hub](https://principledgraphql.com/integrity#3-track-the-schema-in-a-registry) for tracking your GraphQL schema. Adopting a shared schema registry for your project has many benefits:\n\n- Unlike introspection, which provides a snapshot of a particular server's current schema, the registry serves as a global source of truth for the schema. In small projects this frees you from always needing a running server to access the schema. At scale, it avoids issues related to running multiple servers that may not always be in sync (eg, rolling updates).\n- Much like a source control system, Apollo's schema registry tracks a full history of a schema and how it changed over time. This is valuable for understanding and collaborating on a GraphQL API, especially as your team grows.\n- Having a registry allows you to disable introspection in production – a recommended best practice for good security.\n- Tools like the [Apollo VS Code extension](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo) can automatically fetch your schema from the registry and provide intellisense like field descriptions and deprecations directly in your editor.\n- Apollo's registry lets you track related _variants_ of a schema, like staging or alpha versions. It's helpful to have these schema definitions handy without having to juggle running servers that implement them.\n\n<h2 id=\"setup\">Using the Schema Registry</h2>\n\nTo get started using the schema registry, you'll need to make sure your repository is configured to be an Apollo project by:\n\n1. [Installing the Apollo CLI](#install-cli)\n1. [Creating a `.env` file in the root of your project with an `ENGINE_API_KEY`](#api-key)\n1. [Creating an `apollo.config.js` file at the root of your project and adding the right configuration](#apollo-config)\n\n#### CLI commands\n\nOnce you have that set up, you'll be ready to start connecting to the schema regsitry using the CLI:\n\n- `apollo service:push`&mdash; push a new schema to the registry.\n- `apollo service:check`&mdash; calculate a local schema diff and compare the changes against live traffic to validate if the changes are _safe_ or if they will _break_ live running queries.\n\n<h3 id=\"install-cli\">Install the Apollo CLI</h3>\n\nTo install the [`apollo` CLI](https://npm.im/apollo), ensure that `node` and `npm` are both installed, then run:\n\n```bash\nnpm install --global apollo\n```\n\n> **Note:** This guide will utilize the global installation method, but the `apollo` command can also be installed in a project's `devDependencies` and used via [`npm-scripts`](https://docs.npmjs.com/misc/scripts) or [`npx`](https://npm.im/npx).\n\n<h3 id=\"api-key\">Get your Engine API key</h3>\n\nTo get an API key, you will need to [log in to Engine](https://engine.apollographql.com) and create a new service by clicking the \"Add Service\" button. If you already have a service, get your API key by visiting your service's settings page. Once you have your API key, add it to your `.env` file like so:\n\n```\nENGINE_API_KEY=service:foobar:d1rzyrmanmrZXxTTQLxghX\n```\n\nThe Apollo CLI will be looking for your `.env` file because it uses your Engine API key to authenticate with the schema registry when it pushes your schema.\n\n> **Note:** Make sure your `.env` file is in the root of your project so the Apollo CLI knows where to find it. You can also export `ENGINE_API_KEY` as an environment variable.\n\n<h3 id=\"apollo-config\">Create an `apollo.config.js` file</h3>\n\nThe commands executed through the Apollo CLI will be looking for your Apollo config to inform their behavior. To set up schema registration, you'll need to configure a source that the CLI can fetch your schema from like so:\n\n```js\nmodule.exports = {\n  service: {\n    endpoint: {\n      url: \"http://localhost:4000\"\n    }\n    // OR\n    localSchemaFile: './path/to/schema.graphql'\n  }\n};\n```\n\nThe [Apollo config documentation](/docs/references/apollo-config.html#service-config) has more details and advanced configuration options for the `apollo.config.js` format.\n\n<h2 id=\"push\">Registering a schema</h2>\n\nNew versions of your schema are registered to Apollo by running the `apollo service:push` command from within your repository.\n\nThe CLI will know where to fetch your local schema from based on your `apollo.config.js` configuration. Every time you push a new version of your schema it will be logged to your graph's schema history.\n\nHere's what running `apollo service:push` will look like:\n\n```\n~$ apollo service:push\n  ✔ Loading Apollo Project\n  ✔ Uploading service to Engine\n\nid      schema        tag\n──────  ────────────  ───────\n190330  example-4218  current\n```\n\n### Hooking into CI\n\nTo get the full value out of Apollo, your graph's schema history should be as accurately represented in the registry as possible. We _highly recommend_ hooking `apollo service:push` into your repository's continuous delivery pipeline so your schema is updated in the registry on every deploy. This will ensure that you always get intellisense for your live-running schema in your VS Code extension, for example.\n\nHere is a sample continuous delivery configuration for pushing a schema to Apollo using CircleCI:\n\n```yaml line=13,29-31\nversion: 2\n\njobs:\n  build:\n    docker:\n      - image: circleci/node:8\n\n    steps:\n      - checkout\n\n      - run: npm install\n      # CircleCI needs global installs to be sudo\n      - run: sudo npm install --global apollo\n\n      # Start the GraphQL server.  If a different command is used to\n      # start the server, use it in place of `npm start` here.\n      - run:\n          name: Starting server\n          command: npm start\n          background: true\n\n      # make sure the server has enough time to start up before running\n      # commands against it\n      - run: sleep 5\n\n      # When running on the 'master' branch, push the latest version\n      # of the schema to Apollo Engine.\n      - run: |\n          if [ \"${CIRCLE_BRANCH}\" == \"master\" ]; then\n            apollo service:push --tag=master\n          fi\n```\n\n<h2 id=\"history\">Viewing schema change history</h2>\n\nChanges made to your graph's schema over time can be viewed in [Engine](https://engine.apollographql.com) by browsing to the History page for your graph. Each time you push a new version of your schema, it will appear in your graph's history along with a list of the changes introduced in that version.\n\n<img src=\"../images/schema-history.png\" width=\"100%\" alt=\"Schema history page in the Engine UI\">\n\n<h2 id=\"schema-tags\">Managing environments</h2>\n\nProduct cycles move fast and it's common for schemas to be slightly different across environments as changes make their way through your system. To support this, schemas pushed to the registry can be associated with specific _variants_ of your graph (also referred to _tags_).\n\nApollo supports tracking multiple _variants_ for every graph. A variant is just like a regular data graph. It has its own history of schemas, its own metadata store of metrics, and its own operation registry. Variants can be used to track ideas like staging environments, canaries, and deploys of experimental features destined for the production graph.\n\nTo get fully set up associating data sent to Apollo with _variant_ information, you'll need to [configure your CLI commands](#registry-tag) to send data with a `--tag` flag and [configure your Apollo Server](#metrics-tag) with a `schemaTag` option.\n\n<h3 id=\"registry-tag\">Registering schemas to a variant</h3>\n\nTo register your schema to a specific _variant_, simply add the `--tag=<VARIANT>` flag to your push command:\n\n```bash\napollo service:push --tag=beta\n```\n\n> **Note:** All schema pushes without a specified tag are registered under the default graph variant, `current`.\n\n<h3 id=\"metrics-tag\">Associating metrics with a variant</h3>\n\nThere are a few ways to associate metrics reported to [Engine](https://engine.apollographql.com) with a specific variant:\n\n1. The best way to associate metrics with a variant of your graph is to start your server with an environment variable named `ENGINE_SCHEMA_TAG` that contains the name of your variant. This will link metrics sent to Engine with the value of that environment variable.\n1. Alternatively, add the `schemaTag` option to your Apollo Server configuration (works for Apollo Server 2.2+):\n\n```js line=5\nconst server = new ApolloServer({\n  ...\n  engine: {\n    apiKey: \"<ENGINE_API_KEY>\",\n    schemaTag: \"beta\"\n  }\n});\n```\n\n> **Note:** It's important that metrics are associated with the same tag as `service:push` if you want to track isolated data across different variants like production and staging.\n\n<h2 id=\"benefits\">Tools that use the schema registry</h2>\n\nKeeping your schema up-to-date in Apollo's registry will ensure that you get the best experience from Apollo's tools that connect to the registry:\n\n- The [Apollo VS Code extension](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo) provides built-in linting on queries by validating against the schema in your registry. It also annotates fields with their descriptions and with performance indicators collected in Apollo's trace warehouse.\n- The [schema validation](./schema-validation.html) workflow protects your team from accidentally making breaking schema changes. It creates a diff between your local schema and the last schema pushed to the registry, and validates this diff against live traffic seen on your endpoint to warn you about problematic changes.\n- Your schema's full history and current usage can be seen in [Apollo Engine](https://engine.apollographql.com). The History page tracks changes made over time, and the Explorer page shows which clients and which queries are using each field in your schema.\n","path":"/platform/schema-registry","filePath":"docs/source/platform/schema-registry.md"},{"title":"Validating schema changes","description":"Check if schema changes are safe or breaking by comparing against live server traffic","content":"\nThere are many types of schema changes that can be potentially breaking to clients, like removing a field, if made without special consideration. For safety, some organizations take the approach of _never_ making these types of changes, but this leads to an ever-growing schema and reduced API flexibility over time. In reality, making these types of changes to a schema can be very safe as long as you have tools in place to ensure that no queries are broken in the process.\n\nApollo provides a tool to protect for exactly this scenario called **schema validation**.\n\n> **Note:** Schema validation is an Apollo Platform feature available on the [Team and Enterprise plans](https://www.apollographql.com/plans/) of [Apollo Engine](https://engine.apollographql.com).\n\n<h2 id=\"schema-validation\">How it works</h2>\n\nSchema validation is run through the Apollo CLI by executing the `apollo service:check` command. Apollo will generate a diff between your local schema and your most recently registered schema, then validate that the changes are safe by checking if any queries actively running against your graph will be affected.\n\nHere's how it works:\n\n1. You run `apollo service:check` locally or in CI. The proposed schema is sent to Engine's schema registry.\n1. Engine creates a diff between the local schema and the most recently published schema in the registry.\n1. Engine fetches a list of all operations sent to your graph in the last day (time window is [configurable](#cli-advanced)).\n1. Engine walks through the schema diff change-by-change and compares against the operation list to see if the changes will affect the behavior of any operations.\n1. Engine returns the schema diff and indicates any breaking changes found.\n1. The CLI prints the output of this check with a link to view more details in the Engine UI.\n\n<h3 id=\"algorithm\">Breaking change detection</h3>\n\nNot all schema changes are potentially breaking. Some changes, like adding a field, will always be safe and never cause unexpected behavior for active clients. Other changes, like removing a field or changing a return type, can potentially affect the behavior of clients making queries that use those fields. These are what we consider potentially breaking changes.\n\nIf schema validation detects that a proposed schema has a potentially breaking change, the `apollo service:check` command will return a non-0 exit code. Apollo schema validation will detect breaking changes according to the following rules:\n\n#### Removals\n\nEach of these change types removes a schema element. If an element of your graph is being actively used by an operation and it is removed, your GraphQL layer will start returning errors to the dependent operations.\n\n<ul>\n  <li id=\"FIELD_REMOVED\">\n    <code>FIELD_REMOVED</code>: Field used by at least one operation was removed\n  </li>\n  <li id=\"TYPE_REMOVED\">\n    <code>TYPE_REMOVED</code>: Type(scalar, object) used by at least one operation was removed\n  </li>\n  <li id=\"ARG_REMOVED\">\n    <code>ARG_REMOVED</code>: Argument was removed from a field used by at least one operation\n  </li>\n  <li id=\"TYPE_REMOVED_FROM_UNION\">\n    <code>TYPE_REMOVED_FROM_UNION</code>: Type was removed from a union used by at least one operation\n  </li>\n  <li id=\"INPUT_FIELD_REMOVED\">\n    <code>INPUT_FIELD_REMOVED</code>: Field removed from an input type referenced by an argument on a field used by at least one operation\n  </li>\n  <li id=\"VALUE_REMOVED_FROM_ENUM\">\n    <code>VALUE_REMOVED_FROM_ENUM</code>: A value removed from an enum used by at least one operation\n  </li>\n  <li id=\"TYPE_REMOVED_FROM_INTERFACE\">\n    <code>TYPE_REMOVED_FROM_INTERFACE</code>: An object removed from an interface used by at least one operation\n  </li>\n</ul>\n\n#### Required arguments\n\nEach of these changes adds a required input to a schema element. If an operation is actively using an element of your graph and doesn't update itself to add the new required input argument, the GraphQL layer will start returning an error to the operation.\n\n<ul>\n  <li id=\"REQUIRED_ARG_ADDED\">\n    <code>REQUIRED_ARG_ADDED</code>: Non-nullable argument added to field used by at least one operation\n  </li>\n  <li id=\"NON_NULL_INPUT_FIELD_ADDED\">\n    <code>NON_NULL_INPUT_FIELD_ADDED</code>: Non-null field added to an input object used by at least one operation\n  </li>\n</ul>\n\n#### In-place updates\n\nEach of these changes updates an existing schema element. If an operation is activley using an element of your graph and that element is updated, the operation could start receiving an error from the GraphQL layer or, in some cases, an unexpected result.\n\n> **Note:** In some cases, these changes are compatible with the client at runtime, such as a type rename or an object to interface conversion with the same fields. Schema validation still marks these breaking changes because validation does not have enough information to ensure safety and these changes deserve extra scrutiny, such as their impact on type generation.\n\n<ul>\n  <li id=\"FIELD_CHANGED_TYPE\">\n    <code>FIELD_CHANGED_TYPE</code>: Field used by at least one operation changed return type\n  </li>\n  <li id=\"INPUT_FIELD_CHANGED_TYPE\">\n    <code>INPUT_FIELD_CHANGED_TYPE</code>: Field in input object changed type and is referenced by argument on field used by at least one operation\n  </li>\n  <li id=\"TYPE_CHANGED_KIND\">\n    <code>TYPE_CHANGED_KIND</code>: Type used by at least one operation changed, ex: scalar to object or enum to union\n  </li>\n  <li id=\"ARG_CHANGED_TYPE\">\n    <code>ARG_CHANGED_TYPE</code>: Argument changed type on field used by at least one operation\n  </li>\n</ul>\n\n#### Type extensions\n\nThese changes add a type to an existing union or interface in your graph. If an operation is actively using an element of the union or interface, it could receive and unexpected result when updated depending on the fragment spreads requested.\n\n<ul>\n  <li id=\"TYPE_ADDED_TO_UNION\">\n    <code>TYPE_ADDED_TO_UNION</code>: Type added to a union used by at least one operation\n  </li>\n  <li id=\"TYPE_ADDED_TO_INTERFACE\">\n    <code>TYPE_ADDED_TO_INTERFACE</code>: Interface added to an object used by at least one operation\n  </li>\n</ul>\n\n#### Default arguments\n\nThese changes update the default value for an argument. If an operation is using an element of your graph and does not specify a value for this argument, the operation could experience unexpected results when the schema is updated if it was relying on the original default value.\n\n<ul>\n  <li id=\"ARG_DEFAULT_VALUE_CHANGE\">\n    <code>ARG_DEFAULT_VALUE_CHANGE</code>: Default value added or changed for argument on a field used by at least one operation\n  </li>\n</ul>\n\n#### Non-breaking changes\n\nThese are change types detected ny the `apollo service:check` command, but they are \"safe\" and will always be compatible with all exisitng client usage of the graph. They will not affect the behavior of any clients if deployed.\n\n<ul>\n  <li>Optional arguments</li>\n  <ul>\n    <li id=\"OPTIONAL_ARG_ADDED\"><code>OPTIONAL_ARG_ADDED</code> Nullable argument added to a field</li>\n    <li id=\"NULLABLE_FIELD_ADDED_TO_INPUT_OBJECT\"><code>NULLABLE_FIELD_ADDED_TO_INPUT_OBJECT</code> Nullable field added to an input object</li>\n  </ul>\n  <li>Additions</li>\n  <ul>\n    <li id=\"FIELD_ADDED\"><code>FIELD_ADDED</code> Field added to a type</li>\n    <li id=\"TYPE_ADDED\"><code>TYPE_ADDED</code> Type added to the schema</li>\n    <li id=\"VALUE_ADDED_TO_ENUM\"><code>VALUE_ADDED_TO_ENUM</code> Value added to an enum. If clients contain a switch case on the enum and do not include the `default`, this change could cause unexpected behavior</li>\n  </ul>\n  <li>Deprecations</li>\n  <ul>\n    <li id=\"FIELD_DEPRECATED\"><code>FIELD_DEPRECATED</code> Field deprecated</li>\n    <li id=\"FIELD_DEPRECATION_REMOVED\"><code>FIELD_DEPRECATION_REMOVED</code> Field no longer deprecated</li>\n    <li id=\"FIELD_DEPRECATED_REASON_CHANGE\"><code>FIELD_DEPRECATED_REASON_CHANGE</code> Reason for deprecation changed</li>\n    <li id=\"ENUM_DEPRECATED\"><code>ENUM_DEPRECATED</code> Enum deprecated</li>\n    <li id=\"ENUM_DEPRECATION_REMOVED\"><code>ENUM_DEPRECATION_REMOVED</code> Enum no longer deprecated</li>\n    <li id=\"ENUM_DEPRECATED_REASON_CHANGE\"><code>ENUM_DEPRECATED_REASON_CHANGE</code> Reason for enum deprecation changed</li>\n  </ul>\n</ul>\n\n### Validation response\n\nRunning a schema validation check is as simple as running `apollo service:check` on the command line from within a service repository\nthat is configured to be an Apollo project.\n\nRunning `apollo service:check` will output the diff of all schema changes found and highlight changes determined to be breaking. Here's an example:\n\n```console\n$ npx apollo service:check --tag=prod\n  ✔ Loading Apollo Project\n  ✔ Validated local schema against tag prod on service engine\n  ✔ Compared 8 schema changes against 110 operations over the last 24 hours\n  ✖ Found 3 breaking changes and 5 compatible changes\n    → breaking changes found\n\nFAIL    ARG_REMOVED                `ServiceMutation.checkSchema` arg `gitContext` was removed\nFAIL    FIELD_REMOVED              `Schema.fieldCount` was removed\nFAIL    FIELD_REMOVED              `Schema.typeCount` was removed\n\nPASS    FIELD_ADDED                `SchemaTag.schemaRepoID` was added\nPASS    FIELD_CHANGED_TYPE         `ServiceMutation.uploadPartialSchema` changed type from `UploadPartialSchemaResponse!` to `CompositionResult!`\nPASS    FIELD_DEPRECATION_REMOVED  `IntrospectionSchema.fieldCount` is no longer deprecated\nPASS    FIELD_DEPRECATION_REMOVED  `IntrospectionSchema.typeCount` is no longer deprecated\nPASS    TYPE_REMOVED               `UploadPartialSchemaResponse` removed\n\nView full details at: https://engine.apollographql.com/service/example-1234/check/<DETAILS>\n```\n\nEach change to the schema will be labeled with `PASS` or `FAIL` and a URL with full details on the changes and their impact on clients and operations will be generated. Following the URL will take you to Engine:\n\n<img src=\"../img/schema-validation/service-check-page.png\" width=\"100%\" alt=\"Service check page in the Engine UI\">\n\n> **Note:** If you have [installed schema validation checks on your GitHub PRs](#github), the \"Details\" link in your GitHub checks will take you to the same details link in this output.\n\nA failed `apollo service:check` command will exit with a non-0 exit code and fail CI checks. There are many cases where it is safe to make a potentially breaking change, as long as the change is made intentionally with an understanding of its impact.\n\nSince breaking changes are detected using live traffic, your service will _need active metrics_ for the change algorithm to detect failures. If there are no metrics associated with your service, _all changes will be labeled as a `PASS` as opposed to a `FAIL`_.\n\n<h2 id=\"setup\">Set up schema validation</h2>\n\nTo set up schema validation, you wlil need to be both actively sending traces and registering schemas to Apollo:\n\n1. [Set up trace reporting to Apollo Engine](/docs/references/setup-analytics)\n1. [Set up schema registration in your continuous delivery pipeline](/docs/platform/schema-registry.html)\n\nThen, you will need to configure your project for the `apollo service:check` command:\n\n1. [Set up a `.env` file with your `ENGINE_API_KEY`](/docs/platform/schema-registry.html#Get-your-Engine-API-key)\n1. [Set up an `apollo.config.js` file with a `service` configured](/docs/platform/schema-registry.html#Create-an-apollo-config-js-file)\n\n> **Note:** If you have set up one of Apollo's workflows previously, your project may already have its `.env` file and `apollo.config.js` file configured.\n\nOnce you've got these set up, running your schema check is as simple as running:\n\n```console\n$ npm install apollo\n$ npx apollo service:check\n```\n\nThe command can be placed in any continuous integration pipeline. To surface results, `apollo` emits an exit code and [integrates with GitHub statuses](#github). The time window of live traffic that the check command validates against can be [configured](#cli-advanced) to any range within your data retention window.\n\n> **Note:** The Apollo CLI will be looking in your Apollo config for a location from which to fetch your local schema and using your ENGINE_API_KEY to authenticate its requests with the Engine service.\n\n<h3 id=\"service-check-on-ci\">Run validation on each commit</h3>\n\nWe highly recommended that you add validation to your continuous integration workflow (e.g. Jenkins, CircleCI, etc.). In doing so, you can detect potential problems automatically and display the results of checks directly on pull requests.\n\nHere's a example of how to add a schema validation check to CircleCI:\n\n```yaml line=29\nversion: 2\n\njobs:\n  build:\n    docker:\n      - image: circleci/node:8\n\n    steps:\n      - checkout\n\n      - run: npm install\n\n      # Start the GraphQL server.  If a different command is used to\n      # start the server, use it in place of `npm start` here.\n      - run:\n          name: Starting server\n          command: npm start\n          background: true\n\n      # make sure the server has enough time to start up before running\n      # commands against it\n      - run: sleep 5\n\n      # This will authenticate using the `ENGINE_API_KEY` environment\n      # variable. Configure your endpoint's location in your Apollo config.\n      - run: npx apollo service:check\n```\n\n> **Note:** If you're using GitHub status checks, we recommend ignoring the exit code of the `apollo service:check` command so your continuous integration can complete without failing early. This can be done by appending `|| echo 'validation failed'` to the command call.\n\n<h3 id=\"github\">GitHub integration</h3>\n\n<div style=\"text-align:center\">\n\n![GitHub Status View](../img/schema-validation/github-check.png)\n\n</div>\n\nLike most tools, schema validation is best used when it is integrated directly into the rest of your workflow. If you're using GitHub, you can install the Apollo Engine GitHub app. This will enable Apollo's systems to send a webhook back to your project on each `apollo service:check`, providing built-in pass/fail status checks on your pull requests.\n\nTo install the Apollo Engine integration on GitHub, go to [https://github.com/apps/apollo-engine](https://github.com/apps/apollo-engine), click the `Configure` button, and select the appropriate GitHub profile or organization.\n\n### Posting a comment to your PRs\n\nFor teams using GitHub Enterprise, Bitbucket, and other source control tools, we recommend setting up your CI to post a comment on your PRs with the results of schema validation. Surfacing schema diffs and breaking changes directly in your PR will speed up your review workflow by saving you the time of searching your CI logs to check why validation didn't pass.\n\nThe CLI supports passing a `--markdown` flag to `apollo service:check`, which outputs the results of schema validation in a markdown format specifically. This markdown can be piped directly into a comment to your source control tool, like in [this example of posting a comment with the results of schema validation to GitHub](https://gist.github.com/daniman/e53d0589d18b778878bd8ef32d2e793c).\n\nThe output of `apollo service:check --markdown` looks like this:\n\n```md\n### Apollo Service Check\n\n🔄 Validated your local schema against schema tag `staging` on service `engine`.\n🔢 Compared **18 schema changes** against **100 operations** seen over the **last 24 hours**.\n❌ Found **7 breaking changes** that would affect **3 operations** across **2 clients**\n\n🔗 [View your service check details](https://engine.apollographql.com/service/engine/checks?...).\n```\n\n<h3 id=\"multiple-environments\">Multiple environments</h3>\n\nProduct cycles move fast and it's common for schemas to be slightly different across environments as changes make their way through your system. To support this, schemas pushed to the registry can be associated with specific _variants_ of your graph (also referred to tags).\n\nVariants mostly commonly represent environments and can also indicate branches or future schemas. Passing the `--tag=<VARIANT>` flag to `apollo service:check` specifies which schema variant to compara against, such as `prod` or `staging`. It's common to run checks against multple different graph variants in the same continuous integration pipeline to ensure that all important deployments are accounted for. Running `service:check` against multiple variants will result in status checks similar to:\n\n<div style=\"text-align:center\">\n\n![multiple service checks](../img/schema-validation/multi-github-check.png)\n\n</div>\n\n<h2 id=\"cli-advanced\">Adjusting validation parameters</h2>\n\nDepending on the requirements of your application, you may want to configure the timeframe to validate operations against. You can do so by providing a `validationPeriod` flag to the CLI. The timeframe will always end at \"now\", and go back in time by the amount specified.\n\n```bash\napollo service:check --validationPeriod=P2W\n```\n\n> **Note:** Valid durations are represented in [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601#Durations). It can also be provided as a number in seconds, i.e. 86400 for a single day.\n\nTwo other parameters for customizing the results of `service:check` are threshold values. For example, you may wish to drop support for an old version of an app in order to remove some deprecated fields. Using these parameters, you can decide what amount of breakage is acceptable before shipping any breaking changes.\n\n- `queryCountThreshold` - This flag will only validate the schema against operations that have been executed at least the specified number of times within the provided duration.\n- `queryCountThresholdPercentage` - Similar to `queryCountThreshold`, but expressed as a percentage of all operation volume.\n\n> **Note:** these flags are compatible with each other. In the case that both are provided, an operation must meet or exceed both thresholds.\n\nHere's an example of how to run a `service:check` with custom thresholds set:\n\n```bash\nnpx apollo service:check \\\n# Validate the schema against operations that have run in the last 5 days\n--validationPeriod=P5D \\\n# Only validate against operations that have run at least 5 times during the 5 day duration\n--queryCountThreshold=5 \\\n# Only validate against operations that account for at least 3% of total operation volume\n--queryCountThresholdPercentage=3\n```\n\nIf you have any requests for other filtering or threshold mechanisms, please get in touch with us on the [apollo-tooling](https://github.com/apollographql/apollo-tooling/) repository.\n","path":"/platform/schema-validation","filePath":"docs/source/platform/schema-validation.md"},{"title":"Identifying clients","description":"Know who is using your graph and what exactly they're using","content":"\nUsing GraphQL, clients describe exactly the data they want through the fields they put in their requests. This gives us the ability to precisely connect which clients, and which queries from those clients, are using exactly which fields in our schema &mdash; an insight that's immensely valuable as GraphQL development scales within an organization.\n\nApollo provides a client identification and tracking system, which allows you to answer questions like _\"which query is using this field?\"_ and _\"which versions of my iOS app are running this query?\"_. It segments usage data by **client name and version** and allows for **field-level understanding** of how consumers are interacting with your graph in real-time.\n\nLike any API, your graph will end up with many consumers with different frequencies, subselections, and permissions as it grows over time. Apollo allows all reported data to be tagged with client information so it can be filtered and analyzed across different sets of clients and stacks.\n\nHere's an example of client identity reporting in Engine:\n\n![client overview](../img/client-awareness/overview.png)\n\n## Setup\n\nApollo Server 2.2.3+ will look for specific the request headers, `apollographql-client-name` and `apollographql-client-version`, by default. If present, Apollo Server will extract them and make sure the data for that request is reported to Apollo's systems with the correct client and version tag.\n\nWith Apollo Client 2.4.6+, simply passing the `name` and `version` options in your `ApolloClient` constructor will automatically add these headers to every request. Setting up client identity reporting is as simple as adding configuration to Apollo Client:\n\n```js line=8-9\nimport { ApolloClient } from 'apollo-client';\nimport { HttpLink } from 'apollo-link-http';\n\nconst client = new ApolloClient({\n  link: new HttpLink({\n    uri: 'http://localhost:4000/graphql'\n  }),\n  name: 'insert your client name',\n  version: 'insert your client version'\n});\n```\n\nIf you are not using Apollo Server and would like to gain client awareness,\nplease reach out to opensource [at] apollographql.com to work with us to add\nsupport to your server language of choice.\n\n## Use Cases\n\n### Isolating Clients\n\nFiltering queries by client enables isolation of issues that affect a portion\nof all clients. In the opposite sense, if a client becomes problematic, such as\nrequesting expensive fields or using deprecated fields, the Apollo Platform\nenables tracking down the faulty client to start solving the issue with the\nowner. When changing, replacing, or deprecating a field in the API, the client\nmetadata enables quickly identifying the client-side changes that need to\noccur to completely remove the field.\n\n![client field](../img/client-awareness/field-usage.png)\n\n### Cutover\n\nSimilarly to deprecation, adding fields to your graph often means that clients will also change. These modifications can be done incrementally or discretely during a cutover period. The cutover period and time immediately following change the utilization of the graph drastically and can expose some unexpected behavior. Filtering by client version enables monitoring the health of a release in real-time. The following demonstrates a cutover from one backend to another.\n\n![druid cutover](../img/client-awareness/cutover.png)\n\n## Advanced setup\n\n### Client\n\nThe requester is responsible for setting HTTP headers on its requests in a way the server will understand. As noted in \"setup\", Apollo Client and Server will handle this automatically. For advanced cases, rather than setting the `name` and `version` on `ApolloClient`, `headers` can be set on the `HttpLink` directly.\n\n```js line=8-16\nimport { ApolloClient } from 'apollo-client';\nimport { HttpLink } from 'apollo-link-http';\nimport { ApolloLink } from 'apollo-link';\n\nconst client = new ApolloClient({\n  link: new HttpLink({\n    uri: 'http://localhost:4000/graphql',\n    headers: {\n      'client-name-for-advanced-use-cases': 'Web',\n      'client-version-for-advanced-use-cases': '1'\n    }\n  })\n});\n```\n\n### Server\n\nThe server is responsible for collecting and assigning the client information\nto a request. To send client-tagged metrics to Apollo, pass a\n`generateClientInfo` function into the `ApolloServer` constructor. The\nfollowing example checks the headers and provides a fallback:\n\n```js line=8-22\nconst { ApolloServer } = require('apollo-server');\n\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  engine: {\n    apiKey: 'YOUR API KEY HERE',\n    generateClientInfo: ({ request }) => {\n      // The default approach suggested in \"Setup\", which\n      // uses headers provided by Apollo Client, should work\n      // for most use cases, but advanced cases can use\n      // their own logic for determining the client name\n      // and version and return them from this function.\n      const { clientName, clientVersion } = userSuppliedLogic(request);\n      return {\n        clientName,\n        clientVersion\n      };\n    }\n  }\n});\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀  Server ready at ${url}`);\n});\n```\n","path":"/platform/client-awareness","filePath":"docs/source/platform/client-awareness.md"},{"title":"Operation registry","description":"How to secure your graph with operation safelisting","content":"\n## Overview\n\n> The operation registry is an Apollo Platform feature available on the [_Team_ and _Enterprise_ plans](https://www.apollographql.com/plans/). To get started with the Apollo Platform, begin with [the documentation](https://www.apollographql.com/docs/).\n\nAny API requires security and confidence prior to going to production. During development, GraphQL offers front-end engineers the ability to explore all the data available to them and fetch exactly what they need for the components they're building. However, in production, it can be unnecessary and undesirable to provide this flexibility.\n\nThe Apollo Operation Registry allows organizations to:\n\n- Provide demand control for their production GraphQL APIs.\n- Permit the exact operations necessary for their client applications.\n- Eliminate the risk of unexpected, and possibly costly, operations being executed against their graph.\n\nOperations defined within client applications are automatically extracted and uploaded to Apollo Engine using the Apollo CLI. Apollo Server fetches a manifest of these operations from Apollo Engine and forbids execution of operations which were not registered from the client bundle.\n\n## Getting started\n\n### Prerequisites\n\n- Apollo Server 2.2.x (or newer).\n  - To get started with Apollo Server, visit [its documentation](/docs/apollo-server/).\n- A client application which utilizes `gql` tagged template literals for its operations or, alternatively, stores operations in `.graphql` files.\n- An Apollo Engine API key.\n  - To obtain an API key, visit [Apollo Engine](https://engine.apollographql.com) and create a service.\n\n### Limitations\n\n- Subscriptions within Apollo Server should be disabled. For more information, see the instructions below.\n- Only the default schema tag (`current`) is supported.\n\n  To use the operation registry with schema tags, the schema which necessitates demand control should also be registered to the default (`current`) tag for the same service. For example, if a service is using a `prod` schema tag and publishing the schema with `apollo service:push --tag=prod`, the same schema should also be pushed to the default tag with `apollo service:push --tag=current`.\n\nPlease contact the Apollo sales team if you require a solution to any of these limitations.\n\n### Installation steps\n\n> Make sure you've met the requirements for _Prerequisites_ above and understand the current _Limitations_.\n\nThese installation steps require access to both the client and server codebases to perform the following tasks:\n\n- The `apollo` CLI is used to search the client codebase for GraphQL operations and upload them to Apollo Engine.\n- Apollo Server is then configured with a plugin which fetches the manifest from Apollo Server and enforces safe-listing using that manifest.\n\nThe following steps will walk through the steps necessary for both the client and server codebases.\n\n**1. Install the `apollo` command line tool as a development dependency of your client application:**\n\n```\nnpm install apollo --save-dev\n```\n\n> Yarn users should run `yarn add apollo --dev`.\n\n**2. Push your schema to the Apollo schema registry:**\n\n> If this server's schema has already been registered using `apollo service:push`, you can skip this step. For additional options and details, see the [documentation for the schema registry](./schema-registry.html).\n\nFirst, make sure Apollo Server is running and that introspection is enabled (it is often disabled in production).\n\nNext, using the following command as a reference, replace the `<ENGINE_API_KEY>` with the Apollo Engine API key from the appropriate service and specify the correct server endpoint with the `--endpoint` flag:\n\n```\nnpx apollo service:push               \\\n    --key <ENGINE_API_KEY>            \\\n    --endpoint https://server/graphql\n```\n\nWhen successful, this command should return output similar to the following:\n\n```\n✔ Loading Apollo config\n✔ Fetching current schema\n✔ Publishing <service> to Apollo Engine\n\nid      schema        tag\n------  ------------- -------\nabc123  <service>     current\n```\n\n> If you encounter any errors, refer to the _**Troubleshooting**_ section below.\n\n**3. Register operations from the client bundle.**\n\nNow we'll use `apollo client:push` to locate operations within the client codebase and upload a manifest of those operations to Apollo operation registry. Once Apollo Server has been configured to respect the operation registry, only operations which have been included in the manifest will be permitted.\n\nThe `apollo client:push` command:\n\n- Supports multiple client bundles. Each bundle is identified by a `clientName` (e.g. `react-web`) and `clientVersion`.\n- Supports JavaScript, TypeScript and `.graphql` files.\n- Accepts a list of files as a glob (e.g. `src/**/*.ts`) to search for GraphQL operations.\n- By default, includes the `__typename` fields which are added by Apollo Client at runtime.\n\nTo register operations, use the following command as a reference, taking care to replace the `<ENGINE_API_KEY>` with the appropriate Apollo Engine API key, specifying a unique name for this application with `<CLIENT_IDENTIFIER>`, and indicating the correct glob of files to search:\n\n```\nnpx apollo client:push \\\n    --key <ENGINE_API_KEY> \\\n    --clientName <CLIENT_IDENTIFIER> \\\n    --clientVersion <CLIENT_VERSION> \\\n    --includes=\"src/**/*.{ts,js,graphql}\"\n```\n\n> _Note:_ Operations that are stored in the registry are legal for _all_ clients. The client name and client version are collected as metadata to make debugging easier and provide more insights.\n\nWhen succesfull, the output from this command should look similar to the following:\n\n```\n✔ Loading Apollo project\n✔ Pushing client to Engine service <service>\n```\n\nCurrently, once an operation is registered it will remain registered indefinitely. For production operation registration, it's recommended that operations be registered from a deployment pipeline step rather than manually.\n\nIf you encounter any errors, check the _**Troubleshooting**_ section below.\n\n**4. Disable subscription support on Apollo Server**\n\nSubscription support is enabled by default in Apollo Server 2.x and provided by a separate server which does not utilize Apollo Server 2.x's primary request pipeline. Therefore, the operation registry plugin (and any plugin) is unable to be invoked during a request which comes into the subscription server and enforcement of operation safelisting is not possible. **For proper enforcement of operation safelisting, subscriptions should be disabled.**\n\nIn the future, the subscription support will have its request pipeline unified with that of the main request pipeline, thus enabling plugin support and permitting the the operation registry to work with subscriptions in the same way that it works with regular GraphQL requests.\n\nTo disable subscriptions support on Apollo Server 2.x, a `subscriptions: false` setting should be included on the instantiation of Apollo Server, as follows:\n\n```js line=5-6\nconst server = new ApolloServer({\n  // Existing configuration\n  typeDefs,\n  resolvers,\n  // Ensure that subscriptions are disabled.\n  subscriptions: false\n  // ...\n});\n```\n\n**5. Enable demand control by adding the operation registry to Apollo Server.**\n\nTo enable the operation registry within Apollo Server, it's necessary to install and enable the `apollo-server-plugin-operation-registry` plugin and ensure Apollo Server is configured to communicate with Apollo Engine.\n\nFirst, add the appropriate plugin to the Apollo Server's `package.json`:\n\n```\nnpm install apollo-server-plugin-operation-registry\n```\n\n> Yarn users should run: `yarn add apollo-server-plugin-operation-registry`.\n\nNext, the plugin must be enabled. This requires adding the appropriate module to the `plugins` parameter to the Apollo Server options:\n\n```js line=8-12\nconst server = new ApolloServer({\n  // Existing configuration\n  typeDefs,\n  resolvers,\n  subscriptions: false,\n  // ...\n  // New configuration\n  plugins: [\n    require('apollo-server-plugin-operation-registry')({\n      forbidUnregisteredOperations: true\n    })\n  ]\n});\n```\n\n**6. Start Apollo Server with Apollo Engine enabled**\n\nIf the server was already configured to use Apollo Engine, no additional changes are necessary, but it's important to make sure that the server is configured to use the same service as the operations were registered with in step 3.\n\nIf the server was not previously configured with Apollo Engine, be sure to start the server with the `ENGINE_API_KEY` variable set to the appropriate API key. For example:\n\n```\nENGINE_API_KEY=<ENGINE_API_KEY> npm start\n```\n\nAlternatively, the API key can be specified with the `engine` parameter on the Apollo Server constructor options:\n\n```js line=3\nconst server = new ApolloServer({\n  // ...\n  engine: '<ENGINE_API_KEY>'\n  // ...\n});\n```\n\nFor security, it's recommended to pass the Engine API key as an environment variable so it will not be checked into version control (VCS).\n\n**7. Verification**\n\nWith the operation registry enabled, _only_ operations which have been registered will be permitted.\n\nTo confirm that everything is configured properly, try executing an operation against the server which was **not** registered from the client bundle in step 3.\n\nFor example, using `curl` this could be done with a command similar to:\n\n```\ncurl 'http://server/graphql/' \\\n    -H 'Content-Type: application/json' \\\n    --data-binary '{\"query\":\"query { likes{title} }\"}'\n```\n\nIf the server is configured properly, it should return:\n\n```\nExecution forbidden\n```\n\nFinally, to confirm that the server will allow permitted operations, try running an operation from the client.\n\n## Configuration\n\n### Selective enforcement\n\nIn some cases, deployments may want to selectively enable the behavior of `forbidUnregisteredOperations` depending on environmental conditions (e.g. based on headers).\n\nTo selectively enable operation safe-listing, the `forbidUnregisteredOperations` setting supports a [predicate function](https://en.wikipedia.org/wiki/Predicate_(mathematical_logic) which receives the request context and can return `true` or `false` to indicate whether enforcement is enabled or disabled respectively.\n\n> In the example below, the `context` is the shared request context which can be modified per-request by plugins or using the [`context`](https://www.apollographql.com/docs/apollo-server/api/apollo-server.html#constructor-options-lt-ApolloServer-gt) function on the `ApolloServer` constructor. The `headers` are the HTTP headers of the request which are accessed in the same way as the [Fetch API `Headers` interface](https://developer.mozilla.org/en-US/docs/Web/API/Headers) (e.g. `get(...)`, `has(...)`, etc.).\n\nFor example, to enforce the operation registry safe-listing while skipping enforcement for any request in which the `Let-me-pass` header was present with a value of `Pretty please?`, the following configuration could be used:\n\n```js line=12-27\nconst server = new ApolloServer({\n  // Existing configuration\n  typeDefs,\n  resolvers,\n  subscriptions: false,\n  engine: '<ENGINE_API_KEY>',\n  plugins: [\n    require('apollo-server-plugin-operation-registry')({\n      // De-structure the object to get the HTTP `headers` and the GraphQL\n      // request `context`.  Additional validation is possible, but this\n      // function must be synchronous.  For more details, see the note below.\n      forbidUnregisteredOperations({\n        context, // Destructure the shared request `context`.\n        request: {\n          http: { headers } // Destructure the `headers` class.\n        }\n      }) {\n        // If a magic header is in place, allow any unregistered operation.\n        if (headers.get('Let-me-pass') === 'Pretty please?') {\n          return false;\n        }\n\n        // Enforce operation safe-listing on all other users.\n        return true;\n      }\n    })\n  ]\n});\n```\n\n> _Note:_ The `forbidUnregisteredOperations` callback must be synchronous. If it is necessary to make an `async` request (e.g. a database inquiry) to make a determination about access, such a lookup should occur within the [`context` function](https://www.apollographql.com/docs/apollo-server/api/apollo-server.html#constructor-options-lt-ApolloServer-gt) on the `ApolloServer` constructor (or any life-cycle event which has access to `context`) and the result will be available on the `context` of `forbidUnregisteredOperations`.\n\n## Testing the plugin\n\nWe recommend testing the behavior of the plugin, as well as your `forbidUnregisteredOperations` function, before actually forbidding operation execution in production. To do so, you can use the `dryRun` option, which will log information about the operation in lieu of actually forbidding anything.\n\n```js line=7\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  plugins: [\n    require(\"apollo-server-plugin-operation-registry\")({\n      forbidUnregisteredOperations: true,\n      dryRun: true\n    });\n  ],\n});\n```\n\n## Troubleshooting\n\n#### The server indicates `Access denied.` (or `AccessDenied`) when fetching the manifest\n\nWhen the server cannot fetch the manifest, the message may indicate indicate that access is denied:\n\n```xml\nCould not fetch manifest\n<?xml version='1.0' encoding='UTF-8'?>\n<Error>\n   <Code>AccessDenied</Code>\n   <Message>Access denied.</Message>\n   <Details>Anonymous caller does not have storage.objects.get access (...snipped...)</Details>\n</Error>\n```\n\nThis can occur if the schema hasn't been published since the operation registry plugin was enabled. You can publish the schema using the `apollo service:push` command. When receiving this message on a service which has already had its schema pushed, the `apollo client:push` command can be used. Check the above documentation for more information on how to use those commands.\n\n#### Operations aren't being forbidden or operations which should be permitted are not allowed\n\nThe first step in debugging the operation registry behavior is to enable debugging. This can be done by enabling the `debug` setting on the plugin within the Apollo Server constructor options:\n\n```js line=7\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  plugins: [\n    require(\"apollo-server-plugin-operation-registry\")({\n      // ... other, existing options ...\n      debug: true,\n    });\n  ],\n});\n```\n\nWhen the server is started with debugging enabled, additional information will be displayed at server startup which can be useful in determining the source of the problem. For example:\n\n```\nChecking for manifest changes at https://...\n🚀 app running at http://localhost:4000/\nIncoming manifest ADDs: ba4573fca2e1491fd54b9f3984...\nIncoming manifest ADDs: 32a21510374c3c9ad25e064240...\nIncoming manifest ADDs: c60ac6dfe19ba70dd9d6a29a27...\n```\n\nBy clicking on the URL listed in the `Checking for manifest changes at` message, it will be possible to see the full contents of the manifest and see the list of permitted operations. This information is not publicly available and this URL should not be shared.\n\n#### Schema registration\n\nIf a problem occurs during the `apollo service:push` command, make sure that the running Apollo Server can be accessed from the machine where the command is being executed.\n\nAdditionally, make sure that introspection is enabled on the server since introspection details are used to obtain and publish the schema.\n","path":"/platform/operation-registry","filePath":"docs/source/platform/operation-registry.md"},{"title":"Connecting Apollo to your editor","description":"How to get the most out of your editor with Apollo","content":"\nGraphQL has the potential to create incredible developer experiences, thanks to its strongly typed schema and query language. The Apollo platform brings these possibilities to life by enhancing your editor with rich metadata from your graph API. Currently only [Visual Studio Code](https://code.visualstudio.com/) (VS Code) is supported, but more are coming soon.\n\n<img src=\"../images/editors/jump-to-def.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"Using jump to definition on a fragment\">\n\n<h2 id=\"vscode\">Apollo VS Code</h2>\n\nThe [VS Code extension](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo) for Apollo brings an all-in-one tooling experience for developing apps with Apollo.\n\n- Add [syntax highlighting](#syntax) for GraphQL files and gql templates inside JavaScript files\n- Get instant feedback and [intelligent autocomplete](#autocomplete) for fields, arguments, types, and variables as you write queries\n- Manage client side schema alongside remote schema\n- See [performance information](#performance-insights) inline with your query definitions\n- Validate field and argument usage in operations\n- [Navigate projects more easily](#navigating-projects) with jump-to and peek-at definitions\n- Manage [client-only](#client-only-schemas) schemas\n- [Switch schema tags](#commands) to work with schemas running on different environments\n\n<h2 id=\"getting-started\">Getting started</h2>\n\nTo get all of the benefits of the VS Code experience, it's best to link the schema that is being developed against **before** installing the extension. The best way to do that is by [publishing a schema](./schema-registry.html#publish) to the Apollo schema registry. Once that is done, two steps are needed:\n\n1. Create an `apollo.config.js` at the root of the project\n2. Copy an API key from the Engine dashboard of the published service\n\n<h3 id=\"apollo-config\">Setting up an Apollo config</h3>\n\nIn order for the VS Code plugin to know how to find the schema, it needs to be linked to either a published schema or a local one. To link a project to a published schema, edit the `apollo.config.js` file to look like this:\n\n```js\nmodule.exports = {\n  client: {\n    service: 'my-graphql-app'\n  }\n};\n```\n\nThe `service` name here is the ID of the graph you've created in [Engine](https://engine.apollographql.com).\n\n> **Note:** The ID of your graph can be found in its URL in Engine. We use the ID so you can change your graph's name freely without having to update this. This will be easier to manage in the future.\n\n<h3 id=\"api-key\">Setting up an API key</h3>\n\nTo authenticate with Engine to pull down the schema, create a file next to the `apollo.config.js` called `.env`. This should be an untraced file (i.e. don't push it to GitHub). Go to the settings page of your graph in Engine to get the API key.\n\n> **Note:** It is best practice to create a new API key for each member of the team and name the key so its easy to find and revoke if needed. This will be easier to manage in the future.\n\nAfter the key is found, add the following line to the `.env` file:\n\n```bash\nENGINE_API_KEY=<enter copied key here>\n```\n\nAfter this is done, VS Code can be reloaded and the Apollo integration will connect to Engine to provide autocomplete, validation, and more.\n\n<h3 id=\"local-schemas\">Local schemas</h3>\n\nSometimes it may make sense to link the editor to a locally running version of a schema to try out new designs that are in active development. To do this, the `apollo.config.js` file can be linked to a local service definition:\n\n```js\nmodule.exports = {\n  client: {\n    service: {\n      name: 'my-graphql-app',\n      url: 'http://localhost:4000/graphql'\n    }\n  }\n};\n```\n\nLinking to the local schema won't provide all features such as switching schema tags and performance metrics. See [the Apollo config docs](https://www.apollographql.com/docs/references/apollo-config) for more details on configuration options.\n\n<h3 id=\"client-only-schemas\">Client-only schemas</h3>\n\nOne of the best features of the VS Code extension is the automatic merging of remote schemas and local ones when using integrated state management with Apollo Client. This happens automatically whenever schema definitions are found within a client project. By default, the VS Code extension will look for all files under `./src` to find both the operations and schema definitions for building a complete schema for the application.\n\nClient side schema definitions can be spread throughout the client app project and will be merged together to create one single schema. The default behavior can be controlled by adding specifictions to the `apollo.config.js`:\n\n```js\nmodule.exports = {\n  client: {\n    service: \"my-graphql-app\"\n    includes: [\"./src/**/*.js\"],\n    excludes: [\"**/__tests__/**\"]\n  }\n}\n```\n\n<h3 id=\"get-the-extension\">Get the extension</h3>\n\nOnce you have a config set up and a schema published, [install the Apollo GraphQL extension](https://marketplace.visualstudio.com/items?itemName=apollographql.vscode-apollo), then try opening a file containing a GraphQL operation.\n\nWhen a file open, clicking the status bar icon will open the output window and print stats about the project associated with that file. This is helpful when confirming the project is setup properly.\n\n<img src=\"../images/editors/stats.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"Clicking the status bar icon to open the output pane\">\n\n<h2 id=\"features\">Features</h2>\n\nApollo for VS Code brings many helpful features for working on a GraphQL project.\n\n<h3 id=\"autocomplete\">Intelligent autocomplete</h3>\n\nOnce configured, editors have full knowledge of the schema clients are running operations against, including client-only schemas (for things like local state mutations). Because of this, editors have the ability to autocomplete fields and arguments as you type.\n\n<img src=\"../images/editors/autocomplete.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"vscode completing a field when typing\">\n\n<h3 id=\"errors-and-warnings\">Inline errors and warnings</h3>\n\nEditors can use local or published schemas to validate operations before running them. **Syntax errors**, **invalid fields or arguments**, and even **deprecated fields** instantly appear as errors or warnings right in your editor, ensuring all developers are working with the most up-to-date production schemas.\n\n<img src=\"../images/editors/warnings-and-errors.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"tooltip showing a field deprecation warning and error\">\n\n<h3 id=\"field-type-info\">Inline field type information</h3>\n\nBecause of GraphQL's strongly-typed schema, editors not only know about which fields and arguments are valid, but also what types are expected. Hover over any type in a valid GraphQL operation to see what type that field returns and whether or not it can be null.\n\n<img src=\"../images/editors/type-info.png\" width=\"80%\" style=\"margin: 5%\" alt=\"a tooltip showing a Boolean type for a field\">\n\n<h3 id=\"performance-insights\">Performance insights</h3>\n\nGraphQL's flexibility can make it difficult to predict the cost of an operation. Without insight into how expensive an operation is, developers can accidentally write queries that place strain on their graph API's underlying backends. Thanks to the Apollo platform's integration with VS Code and our trace warehouse, teams can avoid these performance issues altogether by instantly seeing the cost of a query right in their editor.\n\nTo turn on tracing for your GraphQL server, please visit our [guide](./setup-analytics.html).\n\nThe VS Code extension will show inline performance diagnostics when connected to a service with reported metrics in Engine. As operations are typed, any fields that take longer than 1ms to respond will be annoated to the right of the field inline! This gives team members a picture of how long the operation will take as more and more fields are added to operations or fragments.\n\n<img src=\"../images/editors/perf-annotation.png\" width=\"80%\" style=\"margin: 5%\" alt=\"Performance annotation next to a field\">\n\n<h3 id=\"syntax\">Syntax highlighting</h3>\n\nApollo's editor extension provides syntax highlighting for all things GraphQL, including schema definitions in `.graphql` files, complex queries in TypeScript, and even client-only schema extensions. Syntax highlighting for GraphQL works out-of-the-box for `.graphql`, `.gql`, `.js` and `.ts` file types.\n\n<h3 id=\"navigating-projects\">Navigating projects</h3>\n\nNavigating large codebases can be difficult, but the Apollo GraphQL extension makes this easier. Right-clicking on any field in operations or schemas gives you the ability to jump to (or peek at) definitions, as well as find any other references to that field in your project.\n\n<img src=\"../images/editors/jump-to-def.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"Using jump to definition on a fragment\">\n\n<h3 id=\"commands\">Schema variant switching</h3>\n\nApollo supports publishing multiple versions ([variants](http://localhost:8000/platform/schema-registry#schema-tags)) of a schema. This is useful for developing on a future development schema and preparing your clients to conform to that schema. To switch between schema variants, open the Command Palette (`cmd + shift + p` on mac), search \"Apollo\" and choose the \"Apollo: Select Schema Tag\" option.\n\n<h2 id=\"troubleshooting\">Troubleshooting</h2>\n\nThe most common errors are configuration errors, like a missing `.env` file or incorrect service information in the `apollo.config.js` file. Please see [the Apollo config docs](https://www.apollographql.com/docs/references/apollo-config) for more configuration guidance.\n\nOther errors may be caused from an old version of a published schema. To reload a schema, open the Command Palette (`cmd + shift + p` on mac), search \"Apollo\" and choose the \"Apollo: Reload Schema\" option.\n\nSometimes errors will show up as a notification at the bottom of your editor. Other, less critical, messages may be shown in the output pane of the editor. To open the output pane and get diagnostic information about the extension and the current service loaded (if working with a client project), just click the \"Apollo GraphQL\" icon in the status bar at the bottom.\n\n<img src=\"../images/editors/stats.gif\" width=\"80%\" style=\"margin: 5%\" alt=\"Clicking the status bar icon to open the output pane\">\n\nIf problems persist or the error messages are unhelpful, an [issue](https://github.com/apollographql/apollo-tooling/issues) can be opened on the `apollo-tooling` repository.\n","path":"/platform/editor-plugins","filePath":"docs/source/platform/editor-plugins.md"},{"title":"Analyzing performance","description":"Tracking your graph's performance at the field level","content":"\nApollo includes a performance monitoring system which, through a single line of configuration, brings insights about the queries being executed against your graph, the fields being used in your graph, the clients making requests against your graph, how long your requests are taking, and more.\n\nFrom that information it is possible to track down slow or frequently erroring resolvers, clients using deprecated fields, queries from native apps that need to be supported indefinitely, resolvers that are executing in series instead of in parallel, for example.\n\n#### How it works\n\nWith [one line of configuration](/docs/references/setup-analytics), Apollo Server will start recording traces of every request it receives and sending summaries of that performance data to Engine. Engine aggregates and summarizes those traces to provide segmented, filterable insights about your graph's usage.\n\n<h2 id=\"trace\">Traces</h2>\n\nWith the metrics reporting set up, you'll be able to see traces of your operations in [Engine](https://engine.apollographql.com). Execution of a GraphQL request happens layer by layer, and each field in the query calls a function in your server called a resolver. The [_trace_ view in Engine](https://blog.apollographql.com/the-new-trace-view-in-apollo-engine-566b25bdfdb0) allows you to look at a detailed breakdown of the execution for individual operations, with timing shown for every resolver.\n\n![Trace view](../img/trace.png)\n\n<h3 id=\"critical-path\">Critical path</h3>\n\nWhen a trace is opened, some resolvers are collapsed and others are expanded. This is Engine automatically expanding resolvers on the \"critical path\" of the query. The critical path is the set of fields and resolvers that makes the longest sequence in the query. If you are trying to speed up your query's execution, this is the set of fields you should be looking at first.\n\n<h3 id=\"sampled-traces\">Trace inspector</h3>\n\nEvery trace stored in Engine records the request's resolver timings, variables, and HTTP headers. This is particularly useful when debugging and the detailed information about the trace can be found by opening up the _trace inspector_:\n\n![Trace Inspector](../img/trace-inspector.png)\n\n<h3 id=\"tracking-subs\">A note on GraphQL subscriptions</h3>\n\nEngine does not currently track statistics or traces for subscriptions. The proxy does, however, support the transparent pass-through of subscription requests and responses.\n\n<h2 id=\"operation-signatures\">Operation signatures</h2>\n\nEngine groups operations that select the same fields together, treating different queries distinctly even if they share the same name. Not every query string can be taken as-is for grouping though, because some queries inline their variables. For these cases, Engine has a _signature_ algorithm to normalize inline variables so that queries of the same shape can still be grouped together.\n\n<h3 id=\"transformations\">Signature algorithm</h3>\n\nThe current signature algorithm performs the following transformations when generating a signature. (Future improvements to Engine will allow users to customize the signature algorithm.)\n\n- Input argument values are mapped according to the following rules:\n  - `Variable`, `BooleanValue`, and `EnumValue` preserved\n  - `IntValue` and `FloatValue` replaced by `0`\n  - `StringValue` replaced by `\"\"`\n  - `ListValue` replaced by `[]`\n  - `ObjectValue` replaced by `{}`\n- [Ignored tokens](http://facebook.github.io/graphql/draft/#sec-Source-Text.Ignored-Tokens) are removed, including redundant `WhiteSpace`. Single spaces are only preserved when required for parsing the request.\n- Only the `OperationDefinition` corresponding to the requested operation and reachable `FragmentDefinition`s are included.\n  The operation appears first. Fragment definitions appear in order of first reachability when traversing spread-first, depth-second.\n- `Alias`es are removed.\n- In `SelectionSet`, fields appear before fragment spreads, fragment spreads appear before inline fragments.\n- Otherwise, elements are sorted by name alphanumerically, including `Argument` and `Directive`.\n- Otherwise, elements are kept in order. For example in `{north:neigh(dir:NORTH) east:neigh(dir:EAST)}`, `EAST` should always appear after `NORTH`.\n\nFor example:\n\n```\nquery Foo {\n  user(id : \"hello\") {\n    ... Baz\n    timezone\n    aliased: name\n  }\n}\nfragment Baz on User {\n  dob\n}\n```\n\nbecomes\n\n```\nquery Foo{user(id:\"\"){name timezone...Baz}}fragment Baz on User{dob}\n```\n\nSee the reference implementation of [query signatures](https://github.com/apollographql/apollo-tooling/blob/7e1f62a8635466e653d52064745bf8c66bb7dd10/packages/apollo-graphql/src/operationId.ts#L60) for more information.\n\n<h3 id=\"signatures-sensitive-data\">Signatures and sensitive data</h3>\n\nThe signature algorithm is primarily designed to make it possible to treat operations that differ only in trivial ways as the same operation. It also happens that removing the content of string literals appears to achieve greater data privacy within Engine, but this is not the primary goal. In fact, Engine also sends the full raw query along with traces (though it does not currently expose them in the user interface), so relying on the signature to ensure sensitive data never hits Engine's servers is inappropriate.\n\nFuture versions of Engine are likely to change this default algorithm to leave string literals alone, though it will still be easy to configure your server to remove string literals like in the current implementation. We also intend to stop sending the full raw query in future versions of Engine, so that the signature algorithm really can be used to avoid sending sensitive data in queries to Engine.\n\nBut where possible, we strongly advise that you keep sensitive data in GraphQL variables instead of in literal arguments in the query body, as you can more easily control which variables should be stripped out of the Engine reporting pathway for privacy purposes. See [data privacy](../data-privacy.html) for further detail on how this works.\n\n## Error tracking\n\nMetrics reporting to Engine comes with built-in error tracking for basic GraphQL errors. Engine will be able to classify errors by **error type**, **class**, and **message**.\n\n![Errors](../img/error.png)\n\nThe errors tab in Engine's metrics layer automatically shows errors aggregated across your service, and this can be filtered to errors for a specific operation using the filter panel. Each operation can have multiple requests that return errors and will list these. Each error listed that has one trace can have multiple errors under each resolver. Clicking into the trace for a request with errors will take you to details of that error instance.\n","path":"/platform/performance","filePath":"docs/source/platform/performance.md"},{"title":"Integrate with third party services","description":"Integrate Apollo tools with the existing parts of your workflow","content":"\nOne of our fundamental beliefs is that our Apollo workflows should hook into and enhance the workflows you're already using. As such, we've built a number of integrations into third-party services that are common in the developer world:\n\n1. [**GitHub**](#github) &mdash; Ensure the safe evolution of your graph by adding schema change validation directly to your continuous integration and GitHub checks.\n1. [**Slack**](#slack) &mdash; Get a daily summary of key information from your server, including the overall request rate, error rate, and performance latency. Set up notifications for noteworthy events in your service, like increases in errors or particularly slow response times for important queries.\n1. [**Datadog**](#datadog) &mdash; Forward the key metrics and performance data available from Engine to Datadog as well.\n\n<h2 id=\"github\">GitHub</h2>\n\nBuilding tools to help you safely collaborate on the evolution of your graph is one of our biggest focuses at Apollo. To make [schema change validation](/docs/platform/schema-validation.html) as easy to set up as possible, we've built an Apollo app for GitHub that provides status checks on pull requests when schema changes are proposed.\n\n![GitHub Status View](../img/schema-validation/github-check.png)\n\n<h3 id=\"install-github\">Install the GitHub application</h3>\n\nGo to [https://github.com/apps/apollo-engine](https://github.com/apps/apollo-engine) and click the `Configure` button to install the Apollo Engine integration on the GitHub profile or organization that you want to set up checks for.\n\n<h3 id=\"check-schema-on-ci\">Run validation on each commit</h3>\n\nNext, make sure your CI has a step to run the schema validation command. This is accomplished by adding the `apollo schema:check` command directly as a step in your CI. For CircleCI it could look something like this:\n\n```yaml line=13,29,33-36\nversion: 2\n\njobs:\n  build:\n    docker:\n      - image: circleci/node:8\n\n    steps:\n      - checkout\n\n      - run: npm install\n      # CircleCI needs global installs to be sudo\n      - run: sudo npm install --global apollo\n\n      # Start the GraphQL server.  If a different command is used to\n      # start the server, use it in place of `npm start` here.\n      - run:\n          name: Starting server\n          command: npm start\n          background: true\n\n      # make sure the server has enough time to start up before running\n      # commands against it\n      - run: sleep 5\n\n      # This will authenticate using the `ENGINE_API_KEY` environment\n      # variable. If the GraphQL server is available elsewhere than\n      # http://localhost:4000/graphql, set it with `--endpoint=<URL>`.\n      - run: apollo service:check\n\n      # When running on the 'master' branch, publish the latest version\n      # of the schema to Apollo Engine.\n      - run: |\n          if [ \"${CIRCLE_BRANCH}\" == \"master\" ]; then\n            apollo service:push\n          fi\n```\n\n> **Note:** Your `apollo service:check` command needs a source to from which to fetch your schema. This is most commonly provided as a URL to a running server (with introspection enabled), but can also be provided as a path to a file with your schema in it. See [Using the Schema Registry](/docs/platform/schema-registry.html#setup) setup for other options.\n\nThe `apollo schema:check` command checks for differences in your schema between what's on your current branch and the last version you uploaded to Engine. If you've removed or changed any types or fields, it will validate that those changes won't break any of the queries that your clients have made recently. If your changes do break any queries, the check will fail.\n\nBecause you installed the Engine app on GitHub, the check you've added will show up as a line in your GitHub checks list. If there are changes in your schema you'll be able to review them by clicking the \"Details\" link. By enabling schema validation in your continuous integration workflow (eg. CircleCI, etc.), you're alerting developers of any potential problems directly in their pull requests, thereby giving them critical feedback where it's most useful.\n\n<h2 id=\"slack\">Slack</h2>\n\nOur Apollo Slack integration brings your server's performance metrics and analytics data from Apollo Engine directly to your team's Slack workspace so you can be notified of potential issues proactively. The integration does two main things:\n\n1. Send a [**daily snapshot**](#slack-reports) of the request rate, error rate, and performance latency of your graph.\n1. Send [**notifications**](#slack-notifications) that are triggered on thresholds like error percentage and performance latency.\n\n<h3 id=\"setup-slack\">Configure the integration</h3>\n\nThe Apollo Slack integration is set up and configured through the Engine UI. If you do not yet have account, [**follow this guide**](/docs/apollo-server/features/metrics.html#Apollo-Engine) to get started connecting your server to Engine.\n\nIf you already have an Engine account, [**log in**](https://engine.apollographql.com) and ––\n\n1. Select the service you want to turn on Slack notifications for.\n1. Visit the \"Integrations\" tab in the left nav.\n1. You'll notice a \"Reporting Channels\" section at the bottom of this page. Click the \"Add channel\" button and follow the steps in the Engine UI to get a webhook from Slack.\n\nOnce you've configured your Slack channel you'll be able to turn on daily reports snapshotting and configure notifications in the \"General\" and \"Performance Alerts\" sections.\n\n![The Integrations tab in Engine](../img/integrations/integrations-tab.png)\n\n<h3 id=\"slack-reports\">Daily reports</h3>\n\nDaily reports from Engine are sent out around 9am in whichever timezone you configure them to be in. You turn them on in the \"Integrations\" tab as shown above. The reports have a set format that gives a birds-eye view of what your GraphQL API delivered in the previous day:\n\n![Engine slack report](../img/integrations/slack-report.png)\n\n#### Using the report\n\nWe've constructed the report provided to give you an actionable summary of what's happened in your API in the last 24 hours. Here’s how you can use it to identify issues:\n\n1.  **Request rate:** This shows you how many queries are hitting your server every minute, along with a list of the most popular operations. If you see a huge dip in this and it's usually a busy time for your app, it might mean that queries aren’t able to reach your server, or some client is down.\n2.  **p95 service time:** This shows you how long queries are taking to execute. We selected p95 since it’s the best overall representation of how your users are experiencing your app. You can use this to identify that your API is overloaded and users are seeing long loading delays, or to find out which queries are taking the longest to run. This is usually directly connected to UI performance, so a 500ms query probably means some part of your UI is taking that long to display.\n3.  **Error percentage:** This will show you how many of your GraphQL requests end up with an error result. Spikes in errors might be the result of some underlying backend malfunctioning. You can also see which of your operations are most error-prone.\n\n<h3 id=\"slack-notifications\">Notifications</h3>\n\nIn Engine you can configure notifications that are triggered on the performance data of your graph, like error percentages and request latencies. This is particularly useful for detecting anomalies, especially around releases. Notifications can be configured to monitor the following metrics for either your entire GraphQL service or individual operations:\n\n- **Request rate:**  requests per minute\n- **Request duration:** p50/p95/p99 service time\n- **Error rate:** errors per minute\n- **Error percentage:** the number of requests with errors, divided by total\n  requests\n\nThe triggers you set up are evaluated on a rolling five minute window. For example, you can configure a notification to trigger when an operation's error rate exceeds 5%. In production, if 6 out of 100 requests result in an error during the last five minutes, the alert will trigger with an error rate of 6%. Once the error rate falls back below 5% your notification will resolve. Here's an example of what the notification looks like:\n\n![Slack Alert](../img/integrations/slack-notification.png)\n\n<h2 id=\"datadog\">Datadog</h2>\n\nThe Apollo Datadog integration allows you to forward all the performance metrics and analytics data that's available to you in Engine to Datadog as well. This is particularly convenient for teams already relying on Datadog for their monitoring, and of the best perks is that Datadog has advanced filtering features that alerts can be set on, and teams can set those alerts based on their GraphQL metrics data from Engine through Datadog.\n\nThe Datadog metrics forwarded by Engine are:\n\n- `apollo.engine.operations.count`: the number of GraphQL operations that were executed. This includes queries, mutations, and operations that resulted in an error.\n- `apollo.engine.operations.error_count`: the number of GraphQL operations that resulted in an error. This includes GraphQL execution errors, and HTTP errors if Engine failed to connect to your server.\n- `apollo.engine.operations.cache_hit_count`: the number of GraphQL queries whose result was served from Apollo Engine's full query cache.\n- A histogram of GraphQL operation response times, measured in milliseconds. Due to Engine's aggregation method (logarithmic binning), these values are accurate to +/- 5%:\n  - `apollo.engine.operations.latency.min`\n  - `apollo.engine.operations.latency.median`\n  - `apollo.engine.operations.latency.95percentile`\n  - `apollo.engine.operations.latency.99percentile`\n  - `apollo.engine.operations.latency.max`\n  - `apollo.engine.operations.latency.avg`\n\nAll of Engine's new Datadog metrics are tagged with the GraphQL operation name, as `operation:<query-name>`. Unique query signatures with the same operation name are merged, and queries without an operation name are ignored.\nAll of the metrics are also tagged with the Engine graph ID, `service:<graph-id>`, so multiple graphs from Engine can send data to the same Datadog account.\n\nEngine sends metrics to Datadog in 60 second intervals. Data is forwarded with a 60 second delay to allow for reports to be collected, even in the case of temporary network failures.\n\nIf you're reporting metrics to Engine through the Engine proxy, Datadog will merge you statistics across multiple instances of the proxy (per-host metrics are not available). Just like in the Engine UI, each operation inside a query batch is counted individually.\n\n#### Setup\n\nGetting set up with Engine's Datadog integration is as simple as providing a Datadog API key to Engine. There's no further configuration required! You will need to have an account with administrator access to Datadog to acquire that API key.\n\n1.  Go to The [Datadog integrations page](https://app.datadoghq.com/account/settings) and search for \"Apollo Engine\".\n2.  Click the \"+Available\" button and go the the _Configuration_ tab. Copy the API key from the \"Configuration\" tab, click \"Install Integration\" at the bottom, and go to the [service](https://engine.apollographql.com) you'd like to enable Datadog Metric Forwarding for.\n3.  In the settings for the service, scroll to \"Integrations\", and toggle Datadog to ON. When prompted, paste in the API key.\n4.  Go to your Datadog metric explorer and start to see the metrics flow in! Please allow up to five minutes for metrics to be visible.\n\nNavigate to the Apollo Engine Integration in Datadog\n\n![IntegrationTile](../img/datadog/integration-tile.png)\n\nGet the API Key from the Configuration tab before clicking \"Install Integration\":\n\n![ApiKey](../img/datadog/api-key.png)\n\nOnce you've turned on the integration in Datadog, visit the \"Integrations\" tab in your Engine account and turn on the toggle for Datadog.\n\n#### Metrics exploration\n\nOnce you have Datadog forwarding set up, you will start seeing Engine metrics forwarded to your Datadog account within a few minutes. Navigate to the [Datadog metric explorer](http://app.datadoghq.com/metric/explorer?exp_metric=apollo.engine.operations.count&exp_group=service&exp_agg=avg&exp_row_type=metric) to see data from your GraphQL service flowing in.\n\nEach of the metrics reported is [tagged](https://www.datadoghq.com/blog/the-power-of-tagged-metrics/) with the graph ID (`service:<graph-id>`) it is reporting for and the operation name (`operation:<query-name>`), both of which are normalized by Datadog naming requirements (letters are all lower-case and illegal symbols are converted to underscores). This tagging makes it easier to see data at whatever level of granularity you might want.\n\nIf you want to aggregate across all operations or zoom in to a particular operation, it's simply a tag-filtering. Similarly, if you want to compare metrics across staging and production environment, it should be as simple as generating one graph per environment.\n\n**Example**: Suppose you want to see the 95th percentile averaged across all operations for a staging and a production service.\n\n_In the metric explorer, select `apollo.engine.operations.latency.95percentile` and then choose service where it says “one graph per” and select the two services you'd like to compare. At Apollo, we monitor Engine with Engine on our production and staging environments, so this graph for us looks like the following_:\n\n![Compare p95](../img/datadog/datadog.png)\n\n_To perform more advanced manipulation of metrics, open up the [Metrics notebook](https://app.datadoghq.com/notebook)._\n\n#### Monitoring with Datadog\n\nAll of the metrics reported to Datadog can be notified on directly through Engine via the Notifications feature, but Datadog can be a powerful partner in enabling more complex alerts.\n\n**Example**: Suppose you have a query that is run against your GraphQL server with a much higher volume in the morning than in the afternoon. You want to enable monitoring on that query's latency and error rates, but if the query volume is very low, you have a higher tolerance for latency and one error will skew the error rate and make the monitor too noisy.\n\n_You can use Datadog's [composite monitoring](https://docs.datadoghq.com/monitors/monitor_types/composite/) to enable more complex alerting. You need to start by creating a monitor for each condition you want to track and then combining them in a composite monitor, as explained in the [Datadog documentation](https://docs.datadoghq.com/monitors/monitor_types/composite/)._\n","path":"/platform/integrations","filePath":"docs/source/platform/integrations.md"}]},{"title":"Resources","pages":[{"path":"https://www.principledgraphql.com","title":"Principled GraphQL","anchor":true},{"title":"GraphQL Glossary","description":"A comprehensive list of important GraphQL words and acronyms","content":"\nWhen you start diving into the GraphQL ecosystem, you'll probably encounter some unfamiliar terms and phrases along the way. To help you on your journey, we've defined some of the most common GraphQL vocabulary here in this handy cheat sheet.\n\n<h2 id=\"Apollo\">Apollo</h2>\n\nAn open-source implementation of GraphQL that helps you manage data between the cloud and your UI. The Apollo platform is pluggable into your existing architecture and features production-ready tooling that helps you scale GraphQL across your organization ([Server](https://www.apollographql.com/docs/apollo-server/getting-started.html), [Client](https://www.apollographql.com/docs/react/), and [Engine](https://www.apollographql.com/docs/engine/)).\n\n<h2 id=\"automatic-persisted-queries\">Automatic Persisted Queries (APQ) </h2>\n\nA technique for improving GraphQL network performance with zero build-time configuration by reducing request size over the wire. A smaller signature reduces bandwidth utilization and speeds up client loading times. Apollo Server allows implementation of [Automatic Persisted Queries (APQ)](https://www.apollographql.com/docs/guides/performance.html#automatic-persisted-queries).\n\n<h2 id=\"argument\">Argument</h2>\n\nA set of key-value pairs attached to a specific field. Arguments can be literal values or variables.\n\n```js\n{\n  human(id: \"200\") {\n    weight(unit: \"pounds\")\n    height\n  }\n}\n```\n\n`id` is an argument to human in the query above.\n\n<h2 id=\"alias\">Alias</h2>\n\nAn alternative name given to the result of a field to avoid conflicts during data fetching.\n\n```js\n{\n  admins: users(role: \"admin\") {\n    id\n    firstname\n    lastname\n  }\n  managers: users(role: \"manager\") {\n    id\n    firstname\n    lastname\n  }\n}\n```\n\n`admins` and `managers` are aliases in the example query above.\n\n<h2 id=\"data-source\">Data Source</h2>\n\nA new pattern for fetching data from a particular service, with built-in support for caching, deduplication, and error handling. When deploying GraphQL as a layer between your apps and existing APIs and services, [Data sources](https://www.apollographql.com/docs/apollo-server/v2/features/data-sources.html) provide the best experience for fetching and caching data from REST endpoints.\n\n<h2 id=\"deferred-query\">Deferred query</h2>\n\nA query that has certain fields tagged with the [`@defer` directive](https://www.apollographql.com/docs/react/features/defer-support.html), so that fields that take a long time to resolve do not need to slow down the entire query.\n\n```js\nquery NewsFeed {\n  newsFeed {\n    stories {\n      text\n      comments @defer {\n        text\n      }\n    }\n  }\n}\n```\n\n<h2 id=\"directive\">Directive</h2>\n\nA declaration prefixed with an `@` character that encapsulates programming logic for query execution on the client or server. There are built-in directives such as `@skip` or `@include`, and [custom directives](https://www.apollographql.com/docs/graphql-tools/schema-directives.html). Directives can be used for features such as authentication, incremental data loading, etc.\n\n```js\ntype User @auth {\n  name: String!\n  banned: Boolean @auth!\n}\n```\n\n<h2 id=\"docstring\">Docstring</h2>\n\nIt is used for providing descriptions of types, fields and arguments. Docstrings show up in the documentation panel inside GraphQL playground and GraphiQL.\n\n```js\n\"\"\"\nDescription for the User\n\"\"\"\ntype User {\n  \"\"\"\n  Description for first Name\n  \"\"\"\n  firstName: String!\n\n  age(\n    \"\"\"\n    Must be an integer\n    \"\"\"\n    arg: Int\n  )\n}\n```\n\n<h2 id=\"document\">Document</h2>\n\nA file or request string that contains one or multiple definitions of a GraphQL type system and can be interpreted by a GraphQL execution engine.\n\n<h2 id=\"extensions\">Extensions</h2>\n\nSpecial fields in the GraphQL response that allow you to attach extra metadata. [Apollo tracing](https://github.com/apollographql/apollo-server/tree/master/packages/apollo-tracing) is an example of an extension.\n\n<h2 id=\"field\">Field</h2>\n\nA unit of data you are asking for in a Schema, which ends up as a field in your JSON response data.\n\n```js\ntype Author {\n  id: Int!\n  firstName: String\n  lastName: String\n}\n```\n\n`id`, `firstName`, and `lastName` are fields in the Author type above.\n\n<h2 id=\"fragment\">Fragment</h2>\n\nA selection set that can be reused in multiple query operations. A [GraphQL fragment](https://www.apollographql.com/docs/react/advanced/fragments.html) is a shared piece of query logic.\n\n```js\nfragment UserData on User {\n  id: ID!\n  firstName: String!\n  lastName: String!\n}\n\nquery getUsers {\n  allUsers {\n    ...UserData\n  }\n}\n```\n\n<h2 id=\"gql-function\">gql function</h2>\n\nA [JavaScript template literal tag](https://github.com/apollographql/graphql-tag) that parses GraphQL queries into an abstract syntax tree (AST).\n\n```js\nconst typeDefs = gql`\n  type File {\n    filename: String!\n    mimetype: String!\n    encoding: String!\n  }\n`;\n```\n\n<h2 id=\"graphql-playground\">GraphQL Playground</h2>\n\nAn in-browser IDE for GraphQL development and workflow. Added benefits exist such as theme change, automatic schema reloading, HTTP headers configuration, query history and GraphQL subscription support. In addition, it comes [out-of-the-box in Apollo Server 2](https://www.apollographql.com/docs/apollo-server/features/graphql-playground.html).\n\n<h2 id=\"graphql-service\">GraphQL Service</h2>\n\nThe server that contains a GraphQL schema and the ability to run it. Services have runtime information, and through features of the Apollo Platform they can send metrics and maintain a history of the schemas that have been run on that service in the past.\n\n<h2 id=\"graphiql\">GraphiQL</h2>\n\nAn in-browser IDE for GraphQL development.\n\n<h2 id=\"introspection\">Introspection</h2>\n\nA technique to provide detailed information about a GraphQL API's schema. Types and fields used in introspection are prefixed with \"\\_\\_\" two underscores.\n\n```js\n{\n  __schema {\n    types {\n      name\n    }\n  }\n}\n```\n\n<h2 id=\"mutation\">Mutation</h2>\n\nAn operation for creating, modifying and destroying data.\n\n```js\nmutation AddTodo($type: String!) {\n  addTodo(type: $type) {\n    id\n    type\n  }\n}\n```\n\n<h2 id=\"normalization\">Normalization</h2>\n\nA technique for transforming the response of a query operation before saving it to the store by [Apollo Client's `InMemoryCache`](https://www.apollographql.com/docs/react/advanced/caching.html#normalization). The result is split into individual objects, creating a unique identifier for each object, and storing those objects in a flattened data structure.\n\n```js\nimport { InMemoryCache, defaultDataIdFromObject } from 'apollo-cache-inmemory';\n\nconst cache = new InMemoryCache({\n  dataIdFromObject: object => {\n    switch (object.__typename) {\n      case 'foo':\n        return object.key; // use `key` as the primary key\n      case 'bar':\n        return `bar:${object.blah}`; // use `bar` prefix and `blah` as the primary key\n      default:\n        return defaultDataIdFromObject(object); // fall back to default handling\n    }\n  }\n});\n```\n\n<h2 id=\"object-type\">Object Type</h2>\n\nA type in a GraphQL schema that has fields.\n\n```js\ntype User {\n   name: String!\n}\n```\n\n`User` is an Object type in the example above.\n\n<h2 id=\"operation\">Operation</h2>\n\nA single query, mutation, or subscription that can be interpreted by a GraphQL execution engine.\n\n<h2 id=\"operation-name\">Operation name</h2>\n\nA name for a single query, mutation, or subscription. Identifying a query or mutation by name is very useful for logging and debugging when something goes wrong in a GraphQL server.\n\n```js\nmutation AddTodo($type: String!) {\n  addTodo(type: $type) {\n    id\n    type\n  }\n}\n\nquery getHuman {\n  human(id: \"200\") {\n    weight(unit: \"pounds\")\n    height\n  }\n}\n```\n\n`AddTodo` and `getHuman` are names for the mutation and query operation respectively.\n\n<h2 id=\"partial-query-caching\">Partial query caching</h2>\n\nA technique for caching inputs to GraphQL queries. This type of caching ensures that if the query is slightly different but with the same inputs, those inputs can simply be retrieved from the cache instead of fetching data again from the backend. It is implemented in Apollo Server 2 as [Data Source](https://www.apollographql.com/docs/apollo-server/features/data-sources.html) caching.\n\n<h2 id=\"query\">Query</h2>\n\nA read-only fetch operation to request data from a GraphQL service.\n\n<h2 id=\"query-colocation\">Query colocation</h2>\n\nA practice of placing a GraphQL query in the same location as the app component's view logic. Query co-location makes it easier to facilitate a smooth UI and chore of data retrieval. Jumping directly to the query and keeping the component in sync with its data dependencies is a pleasure.\n\n```js\nconst GET_DOG_PHOTO = gql`\n  query dog($breed: String!) {\n    dog(breed: $breed) {\n      id\n      displayImage\n    }\n  }\n`;\n\nexport const queryComponent = ({ breed }) => (\n  <Query query={GET_DOG_PHOTO} variables={{ breed }}>\n    {({ loading, error, data }) => {\n      if (loading) return null;\n      if (error) return 'Error!';\n      return <img src={data.dog.displayImage} />;\n    }}\n  </Query>\n);\n```\n\n<h2 id=\"query-whitelisting\">Query whitelisting</h2>\n\nA technique for preventing unwanted attacks by maintaining a list of approved queries that are allowed in your application. Any query not present in the list that is run against the server will not be allowed. [Automatic Persisted Queries](../guides/performance.html#automatic-persisted-queries) is a feature of Apollo Server 2 that enables query whitelisting and persisted queries.\n\n<h2 id=\"resolver\">Resolver</h2>\n\nA function that connects schema fields and types to various backends. Resolvers provide the instructions for turning a GraphQL operation into data. It can retrieve data from or write data to anywhere, including a SQL, No-SQL, or graph database, a micro-service, and a REST API. Resolvers can also return strings, ints, null, and other primitives.\n\n```js\n...\nconst resolvers = {\n  Query: {\n    author(root, args, context, info) {\n      return find(authors, { id: args.id });\n    },\n  },\n  Author: {\n    books(author) {\n      return filter(books, { author: author.name });\n    },\n  },\n};\n```\n\n<h2 id=\"schema\">Schema</h2>\n\nA GraphQL [schema](https://www.apollographql.com/docs/apollo-server/essentials/schema.html) is at the center of any GraphQL server implementation and describes the functionality available to the clients which connect to it.\n\n<h2 id=\"schema-definition-language\">Schema Definition Language (SDL)</h2>\n\nThe syntax for writing GraphQL Schemas. It is otherwise known as Interface Definition Language. It is the lingua franca shared by all for building GraphQL APIs regardless of the programming language chosen.\n\n```js\ntype Author {\n  id: Int!\n  firstName: String\n  lastName: String\n  posts: [Post]\n}\ntype Post {\n  id: Int!\n  title: String\n  author: Author\n  votes: Int\n}\ntype Query {\n  posts: [Post]\n  author(id: Int!): Author\n}\n```\n\n<h2 id=\"schema-first-development\">Schema first development</h2>\n\nA [development approach](https://www.apollographql.com/docs/fundamentals/tips.html#schema) for designing and building modern UIs that involves the frontend and backend teams agreeing on a Schema first, which serves as a contract between the UI and the backend before any API engineering happens.\n\n<h2 id=\"schema-registry\">Schema registry</h2>\n\nA central source of truth for your schema in Apollo Engine. It enables schema registration, schema validation, tracking of detailed schema changes e.g. types added, fields added, fields deprecated and looking up previous versions of schema.\n\n<h2 id=\"schema-versioning\">Schema versioning</h2>\n\nRefers to the need to evolve a schema over time. As a schema evolves, there is a potential for introducing breaking changes to clients. The Apollo CLI assists schema evolution by validating schema changes and checking for breaking changes using Apollo Engine. Read more in our article about [schema change validation](https://www.apollographql.com/docs/platform/schema-validation#versioning).\n\n<h2 id=\"schema-stitching\">Schema stitching</h2>\n\nThe process of merging [different schemas into one GraphQL schema](./docs/graphql-tools/schema-stitching.html). These schemas can be local, remote, or from third-party services. In a microservice-style deployment model, where your data exists across multiple APIs, schema stitching makes it possible to combine all of them into one schema that can be queried for all the data at once.\n\n<h2 id=\"subscription\">Subscription</h2>\n\nA real-time GraphQL operation. A [Subscription](https://www.apollographql.com/docs/apollo-server/features/subscriptions.html) is defined in a schema along with queries and mutations.\n\n```js\ntype Subscription {\n  commentAdded(repoFullName: String!): Comment\n}\n...\nsubscription onCommentAdded($repoFullName: String!){\n  commentAdded(repoFullName: $repoFullName){\n    id\n    content\n  }\n}\n```\n\n<h2 id=\"scalar-type\">Scalar Type</h2>\n\nA type that qualifies the data a GraphQL field resolves. GraphQL ships with some scalar types out of the box; **Int**, **Float**, **String**, **Boolean** and **ID**. However, a [custom scalar](https://www.apollographql.com/docs/graphql-tools/scalars.html#custom-scalars) type such as **Date** can be specified in a GraphQL service implementation.\n\n<h2 id=\"type-system\">Type System</h2>\n\nA collection of types which characterizes the set of data that can be validated, queried, and executed on a GraphQL API.\n\n<h2 id=\"variable\">Variable</h2>\n\nA value that can be passed to an operation. Variables can be used to fill arguments, or be passed to directives.\n\n```graphql\nquery GetUser($userId: ID!) {\n  user(id: $userId) {\n    firstName\n  }\n}\n```\n\nIn the query above, `userId` is a variable. The variable and its type is declared in the operation signature, signified by a `$`. The type of the variable here is a required `ID`. It's important to note that variable types must match the type of the arguments that they fill.\n\nThe `userId` variable would be passed to the operation by `apollo-client` like this:\n\n```js\nclient.query({ query: getUserQuery, variables: { userId: 1 } });\n```\n\nIn `react-apollo` it would be passed like this:\n\n```jsx\n<Query query={getUserQuery} variables={{ userId: 1 }}>\n  {' '}\n  ...{' '}\n</Query>\n```\n\n<h2 id=\"whole-response-caching\">Whole response caching</h2>\n\nA technique used to cache entire results of GraphQL queries. This process improves performance by preventing the fetching of the same results from the server if it has been obtained before. Read more about GraphQL query caching in our [guide for caching with Apollo Server](https://www.apollographql.com/docs/apollo-server/features/caching).\n","path":"/resources/graphql-glossary","filePath":"docs/source/resources/graphql-glossary.md"},{"title":"Frequently Asked Questions","description":"Common questions asked at each stage of GraphQL adoption","content":"\nEveryone has questions about how to properly set up a GraphQL schema, but not all questions are alike. In different stages of development, different things matter. This guide answers questions that people commonly have at every step along the journey to GraphQL in production.\n\n## Learning GraphQL\n\nYou are just beginning to learn GraphQL. You're learning about syntax, running queries, schemas, and how to connect your existing services to your GraphQL layer.\n\n#### What is GraphQL?\n\nGraphQL is a language for querying data. With GraphQL, your existing services describe the data that they have, and clients describe the data they need. This is possible because of a strongly-typed [schema](http://graphql.github.io/learn/schema/) (type definitions).\n\n#### Why use GraphQL?\n\nGraphQL can make a difference in nearly every area of development: from improving developer experience with quality tooling to improving client performance by reducing bundle sizes. Read more about the benefits of GraphQL [here](../fundamentals/benefits.html).\n\n#### Where can I learn GraphQL?\n\nThere are a number of resources available to learn GraphQL. If you're looking to get started learning the basics, check out [GraphQL.org](https://graphql.org).\n\nThe simplest way to get started with implementing GraphQL is with the Apollo platform. The Apollo platform includes all the tools needed to get started, including a production-ready GraphQL server (`apollo-server`), a fully-featured schema management and monitoring tool, Apollo Engine, and a client that manages local and remote data in your apps (`apollo-client`).\n\nTo get started, read the getting started guides for [`apollo-server`](https://www.apollographql.com/docs/apollo-server/getting-started.html), [Apollo Engine](https://engine.apollographql.com), and [`react-apollo`](https://www.apollographql.com/docs/react/essentials/get-started.html) (the react integration for apollo-client).\n\nThis site and the [Apollo blog](https://blog.apollographql.com) are also great places to learn and keep up with the latest developments in GraphQL and Apollo.\n\n#### How can I host my schema online?\n\nA great tool for learning and building small projects is [Glitch](https://glitch.com). Glitch allows development of a schema in the browser, and even supports cloning from and pushing to GitHub. Glitch provides a public endpoint that projects can query against. To get started with building a GraphQL schema, try using and remixing the [Apollo Launchpad](https://glitch.com/~apollo-launchpad) project.\n\nGraphQL schemas written with `apollo-server` can be deployed anywhere that other Node.js projects can be deployed. `apollo-server` even has variants to support serverless deployment with AWS Lambda.\n\nThere are deployment guides currently written for [Heroku](https://www.apollographql.com/docs/apollo-server/deployment/heroku.html), [Lambda](https://www.apollographql.com/docs/apollo-server/deployment/lambda.html), and [Now](https://www.apollographql.com/docs/apollo-server/deployment/now.html).\n\n#### How do I connect my client app to my schema?\n\nThe Apollo platform has tools available to connect almost any kind of client to your schema: [Apollo Client](https://www.apollographql.com/docs/react/) for JavaScript clients,\n[Apollo iOS](https://www.apollographql.com/docs/ios/) for native iOS clients, and [Apollo Android](https://github.com/apollographql/apollo-android) for native Android clients.\n\nFor Apollo Client projects, there are also many view-layer integrations, to make querying GraphQL schemas easier in [React](https://www.apollographql.com/docs/react/essentials/get-started.html), [Vue](https://github.com/Akryum/vue-apollo), and [Angular](https://www.apollographql.com/docs/angular/).\n\n## Building a proof of concept\n\nYou understand how GraphQL works and what benefits it offers. You are trying to create a proof of concept for your projects or company to test GraphQL's viability in production.\n\n#### Should I use Node.js for schema development?\n\nThere are GraphQL server tools available for most popular languages, but we recommend using [apollo-server](https://www.apollographql.com/server) (Node.js) because of the ecosystem of tools developed for GraphQL in JavaScript. Node servers can also be run nearly anywhere, including on the edge.\n\n#### How do I wrap existing APIs?\n\nOne of the best things about GraphQL is that it works excellently with existing APIs. It's possible to connect any number of existing services to your schema.\n\nThe most common source is a REST API. The [`RESTDataSource`](https://www.apollographql.com/docs/apollo-server/features/data-sources.html) is a tool that integrates with `apollo-server` to simplify fetching and caching for existing REST APIs.\n\nOther DataSources are under development, but even without the `DataSource` API, it's possible to connect any backend to a schema. [Resolvers](https://www.apollographql.com/docs/apollo-server/essentials/data.html) can do anything, including fetch data from an SDK or ORM.\n\n#### How do I design the schema?\n\nSchemas should be designed with the needs of the client in mind. Rather than modeling queries and types after the underlying services, they should be designed to make querying as easy as possible. GraphQL's resolver structure makes it possible to allow this flexibility without many performance consequences. For more, read the [schema design guide](../guides/schema-design.html).\n\n#### How do I discover and reproduce errors?\n\nAs with any service, it's important to track errors and their causes. There are many kinds of errors that can occur with a GraphQL Schema. Some of these include service errors, where the schema can't access underlying services, and user errors, where a user enters invalid information in a query or mutation.\n\nGraphQL is resilient to some of these errors. Since the schema is strongly typed, the designer has the ability to restrict what type of data users can enter and what type the resolvers can return. This type system catches many errors and requires no manual checks.\n\nFor errors not prevented by the type system, it's helpful to know what exact queries were made, and with what variables. [Apollo Engine](https://www.apollographql.com/engine) is a tool that does exactly this. It can help discover and reproduce errors by showing the exact conditions in which the error occurred.\n\n## Moving a feature to GraphQL\n\nYou have decided to use GraphQL in production. You don't want to immediately refactor the APIs or apps. You want to move a single feature over to GraphQL to learn how to use it and monitor it in production.\n\n#### How should the transition to GraphQL happen?\n\nAs with any large change, the adoption of GraphQL should be incremental. GraphQL allows teams to leave existing services as they are and build convenient gateways on top of them.\n\n#### Who owns the schema design?\n\nGraphQL schemas work best when their design is heavily influenced by the needs of the product developers. It's tempting to design a schema to resemble the underlying sources or databases, but this can be hurtful to the usefulness of GraphQL.\n\n#### How do I set up authentication/authorization for my GraphQL schema?\n\nAuthentication and authorization are important topics to discuss with any API. GraphQL provides a very granular approach to handling these topics. But don't worry, if an API being consumed by GraphQL already has authorization built-in, it may be possible to ignore it completely.\n\n#### How can I secure my schema from malicious or expensive queries?\n\nPublic APIs of any kind need some kind of safeguards against malicious queries. Since GraphQL allows for recursive queries, it wouldn't be hard to create a query that is overly complicated and acts as a DoS attack, even by accident. There are multiple ways to prevent something like this from happening, from complexity limiting to query depth limiting. Read the [guide on security](https://blog.apollographql.com/securing-your-graphql-api-from-malicious-queries-16130a324a6b) to learn more.\n\n#### What kinds of cache should I set up?\n\nGraphQL can be cached in multiple places.\n\nOn the client, caches can prevent multiple queries from being called when not necessary. Client caches for GraphQL differ from REST clients in one important way: cache can handle queries that have never been made. This is possible because of how a GraphQL response is normalized and stored. For example, if a client requests a list of movies, each movie is cached separately on the client. Later, if the client requests a single movie in a different query and the needed information is in the cache, the request doesn't have to be made. This normalized cache is a part of `apollo-client` by default.\n\nCache can also be set up at the schema level. Whole-query caching, partial-query caching, and cache backed by a CDN can all be used to lower response times and make a GraphQL schema as performant as possible.\n\nWhole-query and CDN caches are most useful when an API receives many of the same queries. This commonly happens with public data, like content on pages of a site. Regardless of whether the API is used for public data or not, these caches almost always provide large performance benefits and are highly recommended. You can read more about how to set up whole-query and CDN caching with `apollo-server` 2.0 [here](https://www.apollographql.com/docs/guides/performance.html).\n\nPartial query caching can be achieved by caching the responses from underlying services with something like Redis or Memcache. With this strategy, even if two queries look completely different from one another, if there is any duplication of data fetched, those results can be shared, preventing unnecessary traffic. The [`RESTDataSource`](https://www.apollographql.com/docs/apollo-server/features/data-sources.html) does this automatically if the appropriate `cache-control` headers are present in REST responses.\n\n#### How can I monitor the health of my GraphQL schema?\n\nMany apps and sites are powered almost completely by an API such as a GraphQL schema, so it's important to make sure the API is healthy at all times. Indicators of an unhealthy service include long response times, high resource usage, and unusual traffic patterns.\n\n[Apollo Engine](https://www.apollographql.com/platform) is a great tool to track many of these things. It allows close inspection of fields to make it easy to see both total response times as well as how long each field took to execute.\n\nApollo Engine also has some integrations to make monitoring easier. The [Slack Integration](https://www.apollographql.com/docs/platform/integrations#slack) delivers daily reports to give teams a quick overview of the health of their schema. The [DataDog integration](https://www.apollographql.com/docs/platform/integrations#datadog)) works with existing DataDog accounts, to help teams track schema performance.\n\n## Moving a product to GraphQL\n\nYou have a good understanding of how to write, deploy, and monitor GraphQL in production. You are looking to scale GraphQL features to your entire product line.\n\n#### How do I organize schema code to scale for a larger project?\n\nKeeping all schema code together makes sense for smaller projects, but once a project reaches a certain size, or has many people working on it, managing conflicts in the same file and code navigation can get difficult. Splitting types and resolvers up into smaller files can make this process much easier. Read [this blog post](https://blog.apollographql.com/modularizing-your-graphql-schema-code-d7f71d5ed5f2) to learn more.\n\n<!-- TODO: @jakedawkins Add server testing -->\n\n#### How can I test my client?\n\n`react-apollo` comes with everything needed to test a client app that makes queries to a GraphQL schema. Read the [Testing React Components](/docs/react/recipes/testing) guide to learn more.\n\n#### How can I safely make changes to the schema?\n\nSchemas naturally evolve over time. GraphQL schemas are more resilient to change than other APIs, but there are still occasions where breaking changes will need to happen to support new functionality. The [versioning guide](../guides/versioning.html) explains in more detail what kinds of changes are safe to make, and what kinds could break existing clients.\n\nAdditionally, using the [Apollo CLI](https://www.npmjs.com/package/apollo) with Apollo Engine provides the tools needed to [validate schema changes](https://www.apollographql.com/docs/engine/features/schema-history.html) over time. This makes collaboration easier and more transparent.\n","path":"/resources/faq","filePath":"docs/source/resources/faq.md"}]},{"title":"References","pages":[{"title":"Configuring Apollo projects","description":"How to configure Apollo VS Code and CLI with apollo.config.js","content":"\nApollo projects are configured using an `apollo.config.js` file at the root of your project. Many Apollo tools leverage your the Apollo config, reducing the net amount of configuration you need to do in your project in the end.\n\nIf you're using one of our workflow tools like the Apollo CLI or the Apollo VS Code extension, you'll need to have an `apollo.config.js` project to get the features those tools bring.\n\nThere are two types of projects, `client` and `service`, which can be in the same configuration file if necessary. This document describes all the options available in the Apollo config and defines which are required vs. optional.\n\n<h2 id=\"client-config\">Client projects</h2>\n\nClient projects are configured through a top level `client` key in the config.\n\n```js line=2\nmodule.exports = {\n  client: { ... },\n};\n```\n\n### `client.service`\n\n**Required** –– the CLI and VS Code extension rely on knowledge of your schema to show you \"intellisense\" (eg. autocomplete on fields, metrics annotations, query validation).\n\nThere are a few different ways you can link your client to a schema:\n\n1. Use the Apollo [schema registry](/docs/platform/schema-registry.html)\n1. With a remote endpoint (from a running server)\n1. With a local schema file\n\n#### _Option 1_: Use the Apollo schema registry\n\nTo link your client to a schema through the Apollo schema registry, you'll need to have at least one version of your schema uploaded to the [registry](/docs/platform/schema-registry.html).\n\nWith Engine set up, you can point your client directly to your graph's schema by putting your graph's Engine ID in your Apollo config, like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    service: 'my-apollo-service' // the id of your service in Engine (from the URL)\n  }\n};\n```\n\n> **Note:** you must have a [registered schema](/docs/platform/schema-registry.html#publish) for features like VS Code intellisense, which requires knowledge of your schema, to work properly.\n\nIf you're tracking different versions of your schema in the registry using schema variants, you can link your client to a specific variant like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    service: 'my-apollo-service@staging' // \"staging\" is the schema variant we're using\n  }\n};\n```\n\nIf a schema variant is not specified, Apollo tools will fall back to the default value of `current`.\n\n#### _Option 2_: Link a schema from a remote endpoint\n\nRemote endpoints can be used to pull down a schema from a running service. This can be configured like so:\n\n```js line=3-11\nmodule.exports = {\n  client: {\n    service: {\n      name: 'github',\n      url: 'https://api.github.com/graphql',\n      // optional headers\n      headers: {\n        authorization: 'Bearer lkjfalkfjadkfjeopknavadf'\n      },\n      // optional disable SSL validation check\n      skipSSLValidation: true\n    }\n  }\n};\n```\n\n#### _Option 3_: Link a schema from a local file\n\nIn some cases you may have a locally generated file with your schema that you want to link. This can be either a `.graphql` file with the schema in SDL form or a saved introspection result in `.json`. To link your client project to a local schema file, configure it like so:\n\n```js line=3-6\nmodule.exports = {\n  client: {\n    service: {\n      name: 'my-service-name',\n      localSchemaFile: './path/to/schema.graphql'\n    }\n  }\n};\n```\n\n### `client.includes`\n\n_Optional_ –– by default, Apollo tools will look under a `./src` directory to find all operations and SDL to extract.\n\nClient projects often contain client-side schema definitions for local state with Apollo Client. To make sure the Apollo CLI and VS Code extension can find these files and read them correctly, you may need to tell Apollo which folders to look for your schema and queries in like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    includes: ['./imports/**/*.js'], // array of glob patterns\n    service: ...\n  },\n};\n```\n\n### `client.excludes`\n\n_Optional_ –– by default, Apollo tools will exclude `**/node_modules` and `**/__tests___` when looking for your queries and schema files.\n\nIf you want Apollo to ignore any of your other folders when looking for queries and schema definitions, adjust your config like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    excludes: ['**/__tests__/**/*'], // array of glob patterns\n    service: ...\n  },\n};\n```\n\n### `client.tagName`\n\n_Optional_ –– custom tagged template literal.\n\nWhen using GraphQL with JavaScript or TypeScript projects, it is common to use the `gql` tagged template literal to write out operations. Apollo tools will be looking through your files for the `gql` tag to extract your queries, so if you use a different template literal, you can configure it like so:\n\n```js line=3\nmodule.exports = {\n  client: {\n    tagName: \"graphql\",\n    service: ...\n  }\n};\n```\n\n### `client.addTypename`\n\n_Optional_ –– Apollo will by default add the `__typename` field to all your operations automatically and to all your generated types during codegen.\n\nGraphQL clients like Apollo Client often add the `__typename` field to operations automatically when they're sent over the wire. This can come in really handy for things like caching, but it can be turned off by adding `addTypename: false` to the client config:\n\n```js line=3\nmodule.exports = {\n  client: {\n    addTypename: false,\n    service: ...\n  }\n};\n```\n\n> **Note:** For consistency, we recommend that you keep this option consistent with how your `ApolloClient` is configured.\n\n### `client.clientOnlyDirectives`, `client.clientSchemaDirectives`\n\n_Optional_ –– By default, Apollo projects support the following client-side directives:\n\n- `@client` for local state\n- `@rest` for using apollo-link-rest\n- `@connection` for custom pagination with Apollo Client\n- `@type` for dynamic type names with apollo-link-rest\n\nClient side applications can use custom directives on their queries that aren't meant to be sent to the server. Configuration of client side directives beyond the defaults listed above can be set up like so:\n\n```js line=3-4\nmodule.exports = {\n  client: {\n    clientOnlyDirectives: [\"connection\", \"type\"],\n    clientSchemaDirectives: [\"client\", \"rest\"],\n    service: ...\n  }\n};\n```\n\n`clientOnlyDirectives` are directives that should be stripped out of the operation before being sent to the server. An example of this is the `@connection` directive.\n\n`clientSchemaDirectives` are directives that indicate a portion of the operation that is not meant to be sent to the server. These directives are removed as well as the fields they are placed on. An example of this type of directive is the `@client` directive.\n\n<h2 id=\"service-config\">Server projects</h2>\n\nServer projects are configured through a top level `service` key in the config.\n\n```js line=2\nmodule.exports = {\n  service: { ... },\n};\n```\n\nDefining a `service` key in your Apollo config will provide the CLI with the information it needs to perform commands like `apollo service:push` and `apollo service:check`. You can set up the schema for your service to load in one of two ways:\n\n1. Using a remote endpoint\n1. Using a local schema file\n\n<h4 id=\"service-remote-endpoint\">Option 1: Remote endpoint</h4>\n\nRemote endpoints can be used to pull down a schema from a running service. This can be configured like so:\n\n```js line=2-10\nmodule.exports = {\n  service: {\n    endpoint: {\n      url: 'https://api.github.com/graphql', // defaults to http://localhost:4000\n      headers: {\n        // optional\n        authorization: 'Bearer lkjfalkfjadkfjeopknavadf'\n      },\n      skipSSLValidation: true // optional, disables SSL validation check\n    }\n  }\n};\n```\n\n<h4 id=\"service-local-file\">Option 2: Local schema</h4>\n\nIn some cases you may have a locally generated file with your schema that you want to link. This can be either a `.graphql` file with the schema in SDL form or a saved introspection result in `.json`. To link your client project to a local schema file, configure it like so:\n\n```js line=3\nmodule.exports = {\n  service: {\n    localSchemaFile: './path/to/schema.graphql'\n  }\n};\n```\n","path":"/references/apollo-config","filePath":"docs/source/references/apollo-config.md"},{"title":"Turning on analytics","description":"Turn on metrics reporting to get performance and schema usage insights","content":"\nGraphQL offers a number of interesting insights in the realm of server performance and usage monitoring. Because the structure of GraphQL queries requires clients to request exactly the fields they need, simple instrumentation allows us to elicit exactly which fields in the schema are being used at any given time. This helps us understand how much usage different parts of our data model get at a far more granular level than we could achieve out of the box with non-GraphQL APIs.\n\n<h4>Tracing query execution</h4>\n\nA \"trace\" corresponds to exactly one [GraphQL operation](https://www.apollographql.com/docs/resources/graphql-glossary.html#operation) and represents a breakdown of timing and error information for each individual field resolved as part of that operation.\n\nBy recording which resolvers executed in our server and their traces, we can build a rich dataset. From it, we see exactly which query shapes are being run, who is sending them, which parts of the schema are most utilized, which resolvers in the server are bottlenecks, etc.\n\nWe've specifically built an interface to view this information into [Apollo Engine](https://engine.apollographql.com/) and any GraphQL server can report metrics to Engine by sending data in the `apollo-tracing` format to our metrics ingress. Read on to learn how to set this up in your environment.\n\n<h2 id=\"apollo-server\">Apollo Server</h2>\n\nApollo Server has had the ability to report its performance usage metrics to Engine built-in. To set it up, get an API key from [Engine](https://engine.apollographql.com/) by logging in and creating a graph. Then set your API key in the `ENGINE_API_KEY` environment variable or pass it into your Apollo Server constructor like so:\n\n```js line=6-8\nconst { ApolloServer } = require('apollo-server');\n\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  engine: {\n    apiKey: 'YOUR API KEY HERE'\n  }\n});\n\nserver.listen().then(({ url }) => {\n  console.log(`🚀  Server ready at ${url}`);\n});\n```\n\nFor advanced configuration options to set up logging, error filtering, and client-aware metrics reporting take a look at our [server documentation](https://www.apollographql.com/docs/apollo-server/features/metrics.html).\n\n<h2 id=\"other-servers\">Other servers</h2>\n\nThere are 2 ways to send metrics data from your server to Engine:\n\n1. Report traces directly from your server to our reporting endpoint\n2. Use an Apollo tracing package and the Engine proxy (deprecated)\n\n### Engine reporting endpoint\n\nWe recommend following the agent pattern to report trace metrics from your server to the Engine reporting endpoint. This is what Apollo Server does internally and you can view the code for the [Apollo Server reference agent](https://github.com/apollographql/apollo-server/blob/3d6912434051ae7038153ef39e32f485a35609f0/packages/apollo-engine-reporting/src/agent.ts) as an example.\n\nWe've been working with our community to build agent integrations for non-JavaScript servers. If you're interested in collaborating with us on an integration for your server, please get in touch with us at <support@apollographql.com> or via our [Apollo Spectrum Community](https://spectrum.chat/apollo).\n\nThere are four steps to creating a reporting agent for any server:\n\n1. Translating execution information into the correct Tracing format\n2. Implementing a default signature function to identify operations\n3. Emitting batches of Traces to the reporting endpoint\n4. Providing plugins for more advanced reporting functionality\n\n<h3 id=\"tracing-format\">1. Tracing Format</h3>\n\nThe first step of creating a metrics reporting agent will be to hook into the GraphQL execution pipeline to create the metrics and translate them into the proper data format.\n\nThe reporting endpoint accepts a batch of \"traces\" encoded as protobuf. Each individual trace represents execution of a single operation, specifically timing and error information of that execution, broken down by field. Each trace also contains context that is operation-specific (e.g. which client an operation was sent from, if the response was fetched from the cache). In addition to the batch of trace details, the metrics report also includes the context within which all operations were executed (e.g. staging vs prod) in a report header.\n\nAs mentioned, this batch of traces and context is encoded via protobuf. The schema for the protobuf message is defined as the `FullTracesReport` message in the [TypeScript reference implementation](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting-protobuf/src/reports.proto#L380). The reporting agent is **not** responsible for aggregating this list of individual traces and filtering out certain traces to persist. That process is handled via Apollo's cloud services.\n\nAs a good starting point, we recommend implementing an extension to the GraphQL execution that creates a report with one trace, as defined in the `Trace` message of [the protobuf schema](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting-protobuf/src/reports.proto#L9). The next step will be to batch multiple traces into a single report, which we recommend batches of 5-10 seconds while limiting reports to a reasonable size (~4MB).\n\n> Many server runtimes already have support for emitting tracing information as a [GraphQL extension](https://github.com/apollographql/apollo-tracing), which involves hooking into the request pipeline and capturing timing and error data about each resolver's execution. These implementations include runtimes in [Node](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/extension.ts), [Ruby](https://github.com/uniiverse/apollo-tracing-ruby), [Scala](https://github.com/sangria-graphql/sangria-slowlog#apollo-tracing-extension), [Java](https://github.com/graphql-java/graphql-java/pull/577), [Elixir](https://github.com/sikanhe/apollo-tracing-elixir), and [.NET](https://graphql-dotnet.github.io/docs/getting-started/metrics/). If you're working on adding metrics reporting functionality for one of _these languages_, reading through that tracing instrumentation is a good place to start and to plug into. For _other languages_, we recommend reading through the [Apollo Server instrumentation](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/extension.ts) as reference.\n\nAn example of a FullTracesReport message, represented as JSON, can be found below\\*\n\n<h3 id=\"query-signature\">2. Operation Signing</h3>\n\nIn order to correctly group GraphQL operations, it's important to define a method for \"signing\" a query. Because GraphQL queries can be expressed in a variety of ways, this is a harder problem than it may\nappear to be at first thought. For instance, even though all of the following queries request the same\ninformation, it's ambiguous whether they should be treated equally.\n\n```gql\nquery AuthorForPost($foo: String!) {\n  post(id: $foo) {\n    author\n  }\n}\n\nquery AuthorForPost($bar: String!) {\n  post(id: $bar) {\n    author\n  }\n}\n\nquery AuthorForPost($foo: String!) {\n  post(id: $foo) {\n    author\n  }\n}\n\nquery AuthorForPost {\n  post(id: \"my-post-id\") {\n    author\n  }\n}\n\nquery AuthorForPost {\n  post(id: \"my-post-id\") {\n    writer: author\n  }\n}\n```\n\nEven though this concept lacks definition, it's important to decide on how queries should be grouped together when tracking metrics about GraphQL execution. The concept of a **\"query signature\"** is what we use at Apollo to group similar operations together even if their exact textual representations are not identical. The query signature, along with the operation name, are used to group queries together in the `FullTracesReport`.\n\nThe TypeScript reference implementation uses a default signature method and allows for that signature method to also be overridden by the user. The [implementation of the default](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/signature.ts) drops unused fragments and/or operations, hides String literals, ignores aliases, sorts the tree deterministically, and ignores whitespace differences. We recommend using the same default signature method for consistency across different server runtimes.\n\n<h3 id=\"sending-metrics\">3. Sending Metrics</h3>\n\nOnce a metrics report (i.e. batch of traces) is prepared, it will need to be sent to an ingress for aggregation and sampling. Currently, this is all performed in Apollo's cloud services. The endpoint for this aggregation and sampling is at `https://engine-report.apollodata.com/api/ingress/traces`, which supports the protobuf format mentioned above via a `POST` request. The reporting endpoint accepts a gzipped body as well. To see the full reference implementation, see the `sendReport()` method in the [TypeScript reference agent](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/agent.ts#L210).\n\nReporting agents can authenticate either via the `X-Api-Key` header or the `authtoken` cookie with the service API key.\n\nWe recommend implementing retries with backoff on 5xx responses and network errors and allowing for the batching size to be tunable by the user. Additionally, we recommend adding a shutdown hook to send all pending reports to ensure that healthy server shutdowns do not result in missing data, as this tracing information is especially important.\n\n> NOTE: In the future, we plan to release a local aggregation and sampling agent that could be used to lessen the bandwidth requirements on reporting agents.\n\n<h3 id=\"advanced-features\">4. [Optional] Advanced Reporting Features</h3>\n\nThe reference TypeScript implementation also includes several more advanced features which may be worth porting to new implementations. All of these features are implemented in the agent itself and are documented in the interface description for the EngineReportingOptions of [the agent](https://github.com/apollographql/apollo-server/blob/master/packages/apollo-engine-reporting/src/agent.ts#L51).\n\nFor example, the option to send reports immediately may be particularly useful to GraphQL servers running in a serverless environment, like AWS Lambda or Google Cloud Functions.\n\nAnother important feature is the ability to limit information sent, particularly to avoid reporting [personal data](https://en.wikipedia.org/wiki/Personal_data). Because the most common place for personal data to appear is in variables and headers, the TypeScript agent offers options for `privateVariables` and `privateHeaders`.\n\n<h3 id=\"traces-report-example\">Example FullTracesReport, represented as JSON</h3>\n\n```json\n{\n  \"header\": {\n    \"hostname\": \"www.example.com\",\n    \"schemaTag\": \"staging\",\n    \"schemaHash\": \"alskncka384u1923e8uino1289jncvo019n\"\n  },\n  \"tracesPerQuery\": {\n    \"# Foo\\nquery Foo { user { email } }\": {\n      \"trace\": [\n        {\n          \"endTime\": \"2018-11-25T18:28:36.604Z\",\n          \"startTime\": \"2018-11-25T18:28:36.104Z\",\n          \"clientName\": \"c1\",\n          \"clientVersion\": \"v1\",\n          \"http\": {\n            \"method\": \"POST\"\n          },\n          \"durationNs\": \"2498055950907169\",\n          \"root\": {\n            \"fieldName\": \"user\",\n            \"type\": \"User!\",\n            \"startTime\": \"1\",\n            \"endTime\": \"10\",\n            \"child\": [\n              {\n                \"fieldName\": \"email\",\n                \"type\": \"String!\",\n                \"startTime\": \"11\",\n                \"endTime\": \"12\",\n                \"parentType\": \"User\"\n              }\n            ],\n            \"parentType\": \"Query\"\n          }\n        },\n        {\n          \"endTime\": \"2018-11-25T18:28:37.004Z\",\n          \"startTime\": \"2018-11-25T18:28:36.404Z\",\n          \"clientName\": \"c2\",\n          \"clientVersion\": \"v1\",\n          \"http\": {\n            \"method\": \"POST\"\n          },\n          \"durationNs\": \"13154220\",\n          \"root\": {\n            \"fieldName\": \"user\",\n            \"type\": \"User!\",\n            \"startTime\": \"1\",\n            \"endTime\": \"10\",\n            \"child\": [\n              {\n                \"fieldName\": \"email\",\n                \"type\": \"String!\",\n                \"startTime\": \"13\",\n                \"endTime\": \"15\",\n                \"parentType\": \"User\"\n              }\n            ],\n            \"parentType\": \"Query\"\n          },\n          \"clientReferenceId\": \"c2_id\"\n        }\n      ]\n    }\n  }\n}\n```\n","path":"/references/setup-analytics","filePath":"docs/source/references/setup-analytics.md"},{"title":"Apollo Engine guide","description":"Account management, data privacy, GDPR compliance, and other information about Apollo Engine","content":"\n[Apollo Engine](https://engine.apollographql.com/) is our cloud service for schema management and performance metrics monitoring. Its foundation is built on a few types of data input from servers: publishing schema introspections, publishing operations from clients, and sending traces of request execution. From those data inputs we can provide rich schema usage insights, schema history management, schema change validation, operation safelisting, query usage insights, and more.\n\nEngine's core schema management features are all available in an unlimited capacity for free, and always will be. Engine's advanced features, like operation safelisting, schema change validation, resolver-level query tracing, longer data retention, and third-party integrations are available with subscriptions to the Apollo Team plan.\n\nMore information on pricing and billing can be found [here](https://www.apollographql.com/plans/).\n\n![The Apollo Engine Architecture](../img/apollo-engine/engine-architecture.png)\n\n<h2 id=\"accounts\">Accounts</h2>\n\nEngine accounts are authenticated using GitHub by default. We also offer single sign-on (SAML or OIDC) to our [Enterprise](https://www.apollographql.com/plans/) customers.\n\n<h3 id=\"team-collaboration\">Team collaboration</h3>\n\nEngine accounts mirror your GitHub organizations. The first time you log in, we create a personal Engine account for you with the same name as your GitHub username.\n\nThe Engine GitHub application asks for permission to read which GitHub organizations you’re in and their members and teams (but not code!). If you grant Engine permission to see an organization, we create an Engine account with the same name as that GitHub organization. All members of that organization on GitHub will be able to see the new account in Engine. This is how you create a shared team account in Engine.\n\nWhen you sign in to Engine, you will have access to all the teams where you're a member of the organization on GitHub. You can use the organization account picker to switch between accounts. If another member of a GitHub organization you belong to has already signed up the GitHub organization for Engine access, you’ll have access to that existing account.\n\nIf you’d like to work with additional team members and you are the admin of a GitHub organization, simply add them to your GitHub organization. If you aren’t an admin, have an admin add you to their GitHub organization.\n\n<h3 id=\"add-organization\">Adding an organization</h3>\n\nIf you’re looking for a GitHub organization that you’re a member of and don’t see it in Engine, it’s likely that Engine does not have read access for that organization.\n\nIf you want to add or remove an organization from Engine, you should manage those settings on GitHub. There, you will be able to Grant or Revoke access to Engine for organizations you can administer. For organizations you do not administer, you can\n\"Request\" access to Engine and the administrators will receive a request by E-mail.\n\n<h3 id=\"github-permissions\">GitHub permissions</h3>\n\nGitHub’s OAuth service is used for read-only information about organizations and users. Engine does not need access rights to your source code or to any other sensitive data in its login system.\n\nIf your Engine account is owned by a GitHub organization, then Engine will allow all members of that organization to access the account. As you add or remove team members from your Github org, Engine will know about that and accordingly update the authorization for those users.\n\n<!--\n######################################################################\nServices\n######################################################################\n-->\n\n<h2 id=\"services\">Graphs</h2>\n\nA _graph_ (formerly called _service_) in Engine represents a _project_ or _application_. When you create a new graph, we provide an API key used to send performance metrics and schema versions to our cloud service. This information is then accessible through the Engine interface.\n\n<h3 id=\"creating-services\">Creating a graph</h3>\n\nTo create a graph, you will need to select an account for that graph to belong to. All members of the account will be able to see the graph's data and settings options. You can transfer graphs between any of your Engine accounts by visiting its Settings page and change the “owner” to whichever account you’d like.\n\nGraphs in Engine have globally unique IDs. We recommend that you prefix your ID with the name of your company or organization to avoid naming collisions with other graphs in the system.\n\n<h3 id=\"environments\">Managing environments</h3>\n\nEach graph in Engine should represent a single application, and environments within your application should be tracked using [_variants_](https://www.apollographql.com/docs/platform/schema-registry.html#schema-tags). All metrics that your server reports to Engine and all schema versions that you register should be tagged with their environment, and you'll be able to filter and look at the data for individual variants within Engine.\n\n#### API keys\n\nAPI keys can be added and removed from a graph at any time. They are used to both send data to Engine (eg. server reporting configuration) and fetch information from Engine (eg. vs code extension configuration).\n\nYou can manage your API keys on your graph's settings page. It is recommended that you use one API key per function (eg. one key per data source) to have more granular control over how your Engine data is sent and accessed.\n\n<h2 id=\"data-privacy\">Data privacy</h2>\n\nAll data that is sent to Engine from your server can be configured and turned off to meet your data privacy needs. This section will walk through what information Engine sees about your GraphQL graph's requests, what Engine’s default behavior to handle request data is, and how you can configure Engine to the level of data privacy your team needs.\n\n<h3 id=\"architecture\">Architecture</h3>\n\nEngine is primarily a cloud service that ingests and stores performance metrics data from your server. There are two ways to get data into Engine:\n\n1. Use **Apollo Server 2** (Node servers) and configure performance metrics reporting by providing an Engine API key in your server configuration.\n2. Run the **Engine proxy** (deprecated) in front of your server and install an Apollo tracing package in your server.\n\n#### Apollo Server 2\n\nIf you’ve set up Engine metrics forwarding using Apollo Server 2, Apollo Server will automatically start tracing the execution your requests and forwarding that information to Engine. Engine uses this trace data to reconstruct both operation-level timing data for given query shapes and field-level timing data for your overall schema. This data will become available for you to explore in the Engine interface.\n\nApollo Server will never forward the responses of your requests to Engine, but it will forward the shape of your request, the time it took each resolver to execute for that request, and the variables and headers of the request (configurable, see below).\n\n#### Engine Proxy (deprecated)\n\nThis configuration option is primarily used to forward metrics to the Engine ingress from non-Node servers. The proxy is installed and run in your own environment on-prem as a separately hosted process that you route your client requests through.\n\nAs your clients make requests to your server, the proxy reads response extension data to make caching decisions and aggregates tracing and error information into reports that it sends to the Engine ingress.\n\nWhile the Engine proxy sees your client request data and service response data, it only collects and forwards data that goes into the reports you see in the Engine dashboards. All information sent by your on-premise proxy to the out-of-band Engine cloud service is configurable, and can be turned off through configuration options. Data is aggregated and sent approximately every 5 seconds.\n\n<h3 id=\"data-collection\">Data collection</h3>\n\nThis section describes which parts of your GraphQL HTTP requests are seen and collected by Engine.\n\n#### Query operation string\n\nBoth Apollo Server 2 and the Engine proxy report the full operation string of your request to the Engine cloud service. Because of this, you should be careful to put any sensitive data like passwords and personal data in the GraphQL variables object rather than in the operation string itself.\n\n#### Variables\n\nBoth Apollo Server 2 and the Engine proxy will report the query variables for each request to the Engine cloud service by default. This can be disabled in the following ways:\n\n- **Apollo Server 2** – use the privateVariables option in your Apollo Server configuration for Engine.\n- **Engine proxy** – use the privateVariables option in your proxy configuration, or prevent all variables from being reported with noTraceVariables option.\n\n#### Authorization & Cookie HTTP Headers\n\nEngine will **never** collect your application's `Authorization`, `Cookie`, or `Set-Cookie` headers and ignores these if received. Engine will collect all other headers from your request to show in the trace inspector unless turned off with these configurations:\n\n- **Apollo Server 2** – use the [`privateHeaders` option](https://www.apollographql.com/docs/apollo-server/api/apollo-server.html#EngineReportingOptions) in your Apollo Server configuration for Engine.\n- **Engine Proxy** – use the [`privateHeaders` option](./proxy-config.html#Reporting) in your proxy configuration.\n\nIf you perform authorization in another header (like `X-My-API-Key`), be sure to add this to `privateHeaders` configuration. Note that unlike headers in general, this configuration option **is** case-sensitive.\n\n<h3 id=\"response\">Response</h3>\n\nLet’s walk through Engine’s default behavior for reporting on fields in a typical GraphQL response:\n\n```\n// GraphQL Response\n{\n  \"data\": { ... },          // Never sent to the Engine cloud service\n  \"errors\": [ ... ],        // Sent to Engine, used to report on errors for operations and fields.\n  \"extensions\": {\n    \"tracing\": { ... },     // Sent to Engine, used to report on performance data for operations and fields.\n    \"cacheControl\": { ... } // Sent to Engine, used to determine cache policies and forward CDN cache headers.\n  }\n}\n```\n\n#### `response.data`\n\nNeither Apollo Server 2 nor the Engine proxy will ever send the contents of this to the Engine cloud service. The responses from your GraphQL service stay on-prem.\n\nIf you've configured whole query caching through the Engine proxy and Engine determines that a response it sees is cacheable, then the response will be stored in your [cache](https://www.apollographql.com/docs/apollo-server/features/caching#saving-full-responses-to-a-cache) (either in-memory in your proxy or as an external memcached you configure).\n\n#### `response.errors`\n\nIf either Apollo Server 2 or the Engine proxy sees a response with an `\"errors\"` field, they will read the `message` and `locations` fields if they exist and report them to the Engine cloud service.\n\nYou can disable reporting errors to the out-of-band Engine cloud service like so:\n\n- **Apollo Server 2** &mdash; enable the [`maskErrorDetails` option](/docs/apollo-server/api/apollo-server#EngineReportingOptions) to remove the messages and other details from error traces sent to Apollo's cloud service.\n- **Apollo Server 2** &mdash; specify a [`rewriteError` function](https://www.apollographql.com/docs/apollo-server/features/errors#for-apollo-engine-reporting) that filters or transforms your errors before they are sent to Apollo's cloud service. This can be used to strip sensitive data from errors or filter \"safe\" errors from Engine's reporting.\n- **Engine proxy** &mdash; use the [`noTraceErrors` option](./proxy-config.html#Reporting) to disable sending error traces to the Engine cloud service.\n\n#### Disable Reporting (Engine proxy)\n\nWe've added the option to disable reporting of proxy stats and response traces to the Engine cloud service so that integration tests can run without polluting production data.\n\nTo disable all reporting, use the [`disabled` option](./proxy-config.html#Reporting) for the Engine proxy.\n\n<!--\n######################################################################\nGDOR\n######################################################################\n-->\n\n<h2 id=\"gdpr\" title=\"GDPR\">GDPR</h2>\n\nEffective May 25, 2018, the General Data Protection Regulation (GDPR) expands European Union (EU) residents’ (Data Subjects) rights concerning their personal data. Meteor Development Group Inc. (“MDG” also dba Apollo) stands ready to assist our customers to become or remain compliant with GDPR after this crucial transition.\n\n#### What is GDPR?\n\nGDPR standardizes EU regulations and expands the rights of Data Subjects pertaining to personal data while expanding the definition of what constitutes personal data. GDPR provides Data Subjects with increased rights to control and delete their personal data, and it broadly prohibits the processing of special categories of personal data.\n\n#### How has Apollo prepared for GDPR?\n\nWe have been complying with GDPR since before it became enforceable on May 25, 2018. We are enhancing our products, processes, and procedures to meet our obligations as a data processor (Processor).\n\n#### How will GDPR affect the way companies use Apollo's products or services?\n\nOur products and services are not intended to be used for processing personal data. Our products and services are focused on software, systems, and applications - not individuals. If a customer wishes to set up a custom API, custom attribute, or custom event to track such data, it may do so. Our processing is data agnostic and automated, so all data is processed in the same way in accordance with a customer’s configuration. If, however, a customer believes that it has included personal data in the information processed by Apollo, we will assist the customer in meeting its obligations in accordance with the requirements of GDPR and the terms of our Data Processing Agreement.\n\n#### How can Apollo assist customers in meeting their obligations under GDPR?\n\nAs a Processor, we will assist customers in fulfilling their obligations as data controllers (Controllers) by:\n\n- supporting customers in complying with requests from Data Subjects\n- aggregating applicable personal data for customers replying to complaints from Data Subjects\n- replying to investigations and inquiries from supervisory authorities concerning processing activities on behalf of a customer\n- conducting Data Protection Impact Assessments\n\n#### How can Apollo help address requests from Data Subjects?\n\nApollo has implemented a process to intake, review, and fulfill customer requests arising from Data Subject Access Requests (DSAR) they receive. As a result of a DSAR, customers might request that Apollo securely delete or return the Data Subject’s personal data. Due to their sensitivity, such requests will be handled by Apollo on a case-by-case basis.\n\n#### Where can I learn more about Apollo's security and privacy policies?\n\nThe legal terms and policies that apply to Apollo's corporate websites and customer products or services are available at https://www.meteor.com/policy.\n\n#### Where can I get more help?\n\nIf you have any questions (including interest in a Data Processing Addendum or DPA), or encounter any issues, please reach out to <a href=\"https://engine.apollographql.com/support\">support</a>.\n\n<!--\n######################################################################\nPolicies and Agreements\n######################################################################\n-->\n\n<h2 id=\"policies\" title=\"Policies and Agreements\">Policies and Agreements</h2>\n\nTo learn about other ways that we protect your data, please read over our [Terms of Service](https://www.apollographql.com/policies/terms) and [Privacy Policy](https://www.apollographql.com/policies/privacy).\n","path":"/references/apollo-engine","filePath":"docs/source/references/apollo-engine.md"},{"title":"Apollo Engine proxy (deprecated)","description":"Configuring and running the Engine proxy","content":"\n> DEPRECATED: The engine proxy is not maintained, and to integrate with the Apollo platform's metrics, we recommend using Apollo Server's native reporting functionality. To integrate a non-Node server, take a look at our guide [here](./setup-analytics#other-servers).\n\n## Background\n\nThe Apollo Engine proxy is a small process that can be run in front of your GraphQL server. Its primary functions are:\n\n1. Sending **performance metrics** data from your server, which extends its responses with [`apollo-tracing`](https://github.com/apollographql/apollo-tracing) information, to the Engine cloud service.\n1. Proving a **full query caching** layer, which is controlled using the [`cacheControl`](https://github.com/apollographql/apollo-cache-control) directive and configured to be either in-memory or shared through Memcache.\n1. Automatically **persisting queries** through a caching layer that can map query IDs to full query strings, allowing clients to send just query IDs over the wire.\n\nThe proxy has been **deprecated since Apollo Server 2** was released. Apollo Server 2+ has [metrics reporting](https://www.apollographql.com/docs/apollo-server/features/metrics.html), [data source caching](https://www.apollographql.com/docs/apollo-server/features/data-sources.html), [persisted queries](/docs/apollo-server/features/apq), and [full query caching](https://github.com/apollographql/apollo-server/blob/release-2.5.0/docs/source/features/caching.md) (starting at Apollo Server 2.5) as built-in features, and using it allows you to forego running the proxy. The newest features in Apollo Engine are not supported in the Engine proxy and we recommend that all Node users use Apollo Server 2+ instead of running the proxy.\n\nThat said, the proxy is still a good option for getting set up with Engine in a few **specific** circumstances:\n\n1. You are not using Apollo Server, your server has an [`apollo-tracing`](https://github.com/apollographql/apollo-tracing) plugin, and you want to get **performance metrics** insights.\n1. You are not using Apollo Server and you want to use Apollo's **automatic persisted queries**.\n\n## Setup\n\nTo get started with using Engine through the Engine proxy, you will need to:\n\n1. [Install a package in your GraphQL server that adds `extension` data (in the Apollo Tracing format) to each request's response.](#Instrument-your-server)\n1. [Get your Engine API key.](#Get-your-API-key)\n1. [Configure and deploy the Engine proxy to run in front of your server using either Docker or npm.](#Run-the-proxy)\n\n### Instrument your server\n\nTo get the performance metrics value out of Engine, you'll need to install a package in your server that adds the `apollo-tracing` GraphQL extension. If you want to set up response caching, you'll also need to install a package that adds the `apollo-cache-control` extension.\n\n> **Note:** If you're installing the Engine proxy _just_ to set up automatic persisited queries, you can skip ahead to the [next section](#Get-your-API-key).\n\nThe `apollo-tracing` and `apollo-cache-control` extensions are open specifications that can be implemented by any GraphQL server, and the following is a list of implementations:\n\n1. **Node** with [Apollo Server](https://www.apollographql.com/docs/apollo-server/) natively supports tracing and cache control. See [Node setup instructions](#run-the-proxy) for a more streamlined Node setup option.\n1. **Ruby** with [GraphQL-Ruby](http://graphql-ruby.org/) supports tracing with the [apollo-tracing-ruby](https://github.com/uniiverse/apollo-tracing-ruby) gem.\n1. **Java** with [GraphQL-Java](https://github.com/graphql-java/graphql-java) natively supports tracing. [Read the docs about using Apollo tracing.](https://www.graphql-java.com/documentation/master/instrumentation/)\n1. **Scala** with [Sangria](https://github.com/sangria-graphql/sangria) supports tracing with [sangria-slowlog](https://github.com/sangria-graphql/sangria-slowlog#apollo-tracing-extension) project.\n1. **Elixir** with [Absinthe](https://github.com/absinthe-graphql/absinthe) supports tracing with the [apollo-tracing-elixir](https://github.com/sikanhe/apollo-tracing-elixir) package.\n\nYou can test that you’ve correctly enabled Apollo Tracing by running any query against your API using GraphiQL.\n\nThe `tracing` field should now be returned as part of the response's `extensions` like below. Don’t worry, this data won’t make it back to your clients once you've set up the Engine proxy, because the proxy will filter it out.\n\n```js line=3-5\n{\n  \"data\": { ... },\n  \"extensions\": {\n    \"tracing\": { ... }\n  }\n}\n```\n\n### Get your API key\n\n[Log into Apollo Engine](http://engine.apollographql.com/?_ga=2.233930590.1351805406.1542648368-1704540304.1492481658) and create a graph to get an API key. We’ll be using your new key in the next step.\n\n### Run the proxy\n\nThe proxy is a small process written in Go that you host and run inside your infrastructure. It's designed to allow all of your requests and responses to pass through normally while it collects trace data, caches results, and identifies persisted queries. It's designed to handle large volumes of traffic comfortably without overloading. It does not rely on accessing the Engine cloud service to run or perform caching functions, but if it cannot talk to the Engine cloud service it will not be able to report metrics.\n\nApollo distributes the Engine proxy in two forms: as an **npm package** and as a **Docker container**. You can use any one of the following options for running the proxy, depending what works best for you and your team:\n\n1. [Run the proxy with Apollo Server](#proxy-with-apollo-server)\n1. [Run a standalone proxy using Node](#standalone-proxy-with-node)\n1. [Run a standalone proxy using Docker](#standalone-proxy-with-docker)\n1. [Run the proxy through a Platform as a Service (eg. Heroku)](#platform-as-a-service)\n1. [Run the proxy in a serverless environment (eg. Lambda)](#serverless)\n\n<h4 style=\"position: relative;\">\n<span id=\"proxy-with-apollo-server\" style=\"position: absolute; top: -100px;\" ></span>\nOption 1: Running the proxy with Apollo Server\n</h4>\n\nThe two cases where you should be running the Engine proxy with Apollo Server are:\n\n1. You are using Apollo Server 1 and want the Apollo platform features that Engine brings.\n1. You are using Apollo Server >2 & <2.5+ and want full query caching using the Engine proxy.\n\n> **Note:** If you're using Apollo Server but neither of these conditions apply to you, you should be using the built-in features of Apollo Server 2+ instead of the Engine proxy.\n\nThis section assumes you're running your GraphQL server with the `express` web server package for Node, but if you're using a different framework the steps will be similar.\n\nFirst, install the `apollo-engine` package from npm:\n\n```bash\nnpm install --save apollo-engine\n```\n\nThen import the `ApolloEngine` constructor and create a new Engine instance. You'll need to replace `app.listen()` with `engine.listen()` like below:\n\n```js\n// Import ApolloEngine\nconst { ApolloEngine } = require('apollo-engine');\nconst { ApolloServer } = require('apollo-server-express');\nconst express = require('express');\n\n// Initialize Apollo Server\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n\n  // Make sure that tracing and cacheControl are both enabled\n  tracing: true,\n  cacheControl: true,\n\n  // By setting this to \"false\", we avoid using Apollo Server 2's\n  // integrated metric reporting and fall-back to using the Apollo\n  // Engine Proxy (running separately) for metric collection.\n  engine: false\n});\n\n// Initialize your Express app like usual\nconst app = express();\n\n// All of your GraphQL middleware goes here\nserver.applyMiddleware({ app });\n\n// Initialize engine with your API key. Alternatively,\n// set the ENGINE_API_KEY environment variable when you\n// run your program.\nconst engine = new ApolloEngine({\n  apiKey: 'API_KEY_HERE'\n});\n\n// Call engine.listen(...) instead of app.listen(port) as you usually would\nengine.listen({\n  port: 4000,\n  expressApp: app\n});\n```\n\nEngine is now wrapping your endpoint and processing your GraphQL requests and responses like normal. If you call your endpoint again, your requests will be routed through the Engine proxy to your server and back. If everything is working, you will no longer see `tracing` data in your responses because your Engine proxy is filtering and processing that information for you.\n\n<h4 style=\"position: relative;\">\n<span id=\"standalone-proxy-with-node\" style=\"position: absolute; top: -100px;\" ></span>\nOption 2: Running a standalone proxy using Node\n</h4>\n\nEven if your GraphQL server is not implemented with Node, you may find it easier to run a tiny Node program in your hosting environment than to run a Docker container. If so, this proxy deployment option is for you.\n\nThe `apollo-engine` npm package contains an `ApolloEngineLauncher` API, which simply runs the Engine proxy with a given configuration.\n\nFirst, install the `apollo-engine` package from npm:\n\n```bash\nnpm install --save apollo-engine\n```\n\nThen write a small Node program that uses it, like so:\n\n```js\nconst { ApolloEngineLauncher } = require('apollo-engine');\n\n// Define the Engine configuration.\nconst launcher = new ApolloEngineLauncher({\n  // Note: you can also provide this in the ENGINE_API_KEY environment variable.\n  apiKey: 'API_KEY_HERE',\n  origins: [\n    {\n      http: {\n        // The URL that the proxy should use to connect to your GraphQL server.\n        url: 'http://localhost:4000/api/graphql'\n      }\n    }\n  ],\n  // Tell the proxy which ports to listen to and which paths should\n  // be treated as GraphQL instead of transparently proxied as raw HTTP.\n  frontends: [\n    {\n      port: 3000, // default if left out: process.env.PORT\n      endpoints: ['/api/graphql'] // default if left out: /['/graphql]\n    }\n  ]\n});\n\n// Start the Proxy; crash on errors.\nlauncher.start().catch(err => {\n  throw err;\n});\n```\n\n> **Note:** Every deployment has its unique needs and we provide a variety of configuration options to fulfill them. For more configuration options, please see the [proxy config docs](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md).\n\n> **Note:** The argument to `new ApolloEngineLauncher()` is generally the same as the argument Node GraphQL users pass to `new ApolloEngine()`. The main differences are that you need to specify the origin's HTTP URL yourself with `new ApolloEngineLauncher()`, and the frontend `port` and `endpoints` are specified inside the constructor instead of as options to `listen()`.\n\nIf you run this program with Node, the proxy will start up and start accepting connections at http://localhost:3000. It will forward all requests to your server, which you told it is running on http://localhost:4000.\n\nIf you open up GraphiQL on http://localhost:3000, you'll notice that the `tracing` extension data is no longer in the result of your query. This is because Engine is consuming it! You can verify that everything is working correctly by checking the Engine UI for your new service and confirming that you see data in the Metrics section.\n\n<h4 style=\"position: relative;\">\n<span id=\"standalone-proxy-with-docker\" style=\"position: absolute; top: -100px;\" ></span>\nOption 3: Running a standalone proxy with Docker\n</h4>\n\nThe Engine proxy is also distributed as a Docker image that you can deploy and manage separate from your server. It does not matter where you choose to deploy and manage your proxy, though it's more efficient if your proxy is located on the same machine or network as your GraphQL server.\n\nThe Docker container distribution of Engine proxy is configured using a JSON `engine-config.json` configuration file, like so:\n\n```js\n{\n  \"apiKey\": \"API_KEY_HERE\",\n  \"origins\": [{\n    \"http\": {\n      \"url\": \"http://localhost:4000/api/graphql\"\n    }\n  }],\n  \"frontends\": [{\n    \"port\": 3000,\n    \"endpoints\": [\"/api/graphql\"]\n  }]\n}\n```\n\n> **Note:** Every deployment has its unique needs, and we provide a variety of configuration options to fulfill them. For example, if your origin GraphQL server is running in a virtual-hosted environment (e.g. Heroku, AWS), you may need to override the `Host` header sent to HTTP origins. For more details and instruction on configuration options, please see the [proxy config docs](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md).\n\nAs it is JSON file, all object keys must be quoted, and trailing commas and comments are not allowed. Any reference in our docs to options passed to `new ApolloEngine()` otherwise translates directly into the engine config file. Like with `ApolloEngineLauncher`, you need to specify your GraphQL server's origin http URL (or other origin type like [Lambda](./setup-lambda.html)) inside the config file, and you need to specify the frontend port and GraphQL paths inside the config file rather than separately (if you're not using the default values of `process.env.PORT` and `['/graphql']`).\n\nNext, make sure you have a working [Docker installation](https://docs.docker.com/engine/installation/) and type the following lines in your shell:\n\n```\n$ ENGINE_PORT=3000\n$ docker run --env \"ENGINE_CONFIG=$(cat engine-config.json)\" -p \"${ENGINE_PORT}:${ENGINE_PORT}\" gcr.io/mdg-public/engine:1.1\n```\n\n> **Note:** We use [semver](https://semver.org/) to name Engine Proxy release versions, and we release version 1.2.3 under the tags `1.2.3`, `1.2`, and `1`. If you want to pin to a precise version, use the `1.2.3` tag. If you'd like to take patch upgrades but not minor upgrades, use the `1.2` tag. If you'd like to take minor upgrades, use the `1` tag.\n\nThis will run the Engine Proxy via Docker, routing port 3000 inside the container to port 3000 outside the container. (You can also pass `--net=host` instead of the `-p 3000:3000` to just allow the Proxy direct access to your host's network.)\n\nThe Proxy should start up and accept connections at http://localhost:3000 and forward all requests to your server at http://localhost:4000. Load GraphiQL through Engine at http://localhost:3000/graphiql (or wherever you have configured your app to serve GraphiQL) and run any query. You should no longer see the `tracing` data in the result since Engine is now consuming it! Checking the Engine UI for your service, you should see data from the request you sent via GraphiQL come through in the metrics tab.\n\nYou can find the complete documentation for Engine configuration options on the [full API docs](./proxy-config.html) page, and some commonly-used fields worth knowing about are described in the [`new ApolloEngineLauncher()` docs](#api-apollo-engine-launcher).\n\n<h4 style=\"position: relative;\">\n<span id=\"platform-as-a-service\" style=\"position: absolute; top: -100px;\" ></span>\nOption 4: Running the proxy through a Platform as a Service (eg. Heroku)\n</h4>\n\nIt may be most convenient for you to run and host the Engine proxy outside your app's deployment altogether. If that is the case, automatically running the proxy on a Platform as a Service like Heroku might be the easiest option for you.\n\nWe have an example repository with a guide for [running the Engine proxy on Heroku](https://github.com/apollographql/engine-heroku-example) that you can follow along in. Like running a [standalone proxy with Docker](#standalone-proxy-with-docker), you'll need to configure your proxy with an `engine-config.json` file like so:\n\n```\n{\n  \"apiKey\": \"<ENGINE_API_KEY>\",\n  \"origins\": [\n    {\n      \"http\": {\n        \"url\": \"http://yourappname.herokuapp.com/graphql\",\n        \"overrideRequestHeaders\": {\n          \"Host\": \"yourappname.herokuapp.com\"\n        }\n      }\n    }\n  ],\n  \"frontends\": [\n    {\n      \"host\": \"0.0.0.0\",\n      \"port\": \"3000\",\n      \"graphqlPaths\": [\"/graphql\"]\n    }\n  ]\n}\n```\n\n> **Note:** For Virtual Hosted environments where the `PORT` is dynamically set in an environment variable named `$PORT`, you can leave out the `port` option. If your environment uses a different environment variable, you can name it with the `portFromEnv` option instead. For more details and instruction on configuration options, please see the [proxy config docs](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md).\n\nIt does not matter where you choose to deploy and manage your Engine proxy. We've built this guide for Heroku because they have an easy deployment mechanism for Docker containers, but we run our own Engine proxy on Amazon's [EC2 Container Service](https://aws.amazon.com/ecs/).\n\n<h4 style=\"position: relative;\">\n<span id=\"serverless\" style=\"position: absolute; top: -100px;\" ></span>\nOption 5: Running the proxy in a serverless environment (eg. Lambda)\n</h4>\n\nLast but not least, you may be wondering how to use Engine if you run your application in a serverless environment like Lamdba. If so, this is the guide for you!\n\n> **Note:** The best option for using Engine if you're running in a serverless environment is to use Apollo Server 2+ and its built-in reporting mechanism. Running the Engine proxy in serverless environments is tricky because the **proxy is stateful** and needs to be run separately from your cloud function.\n\nTo use Engine when running in serverless environments, we will need to configure and deploy the Engine proxy as a standalone docker container that is **separate** from your cloud function. The Engine proxy is stateful (it collects and aggregates your metrics across requests), and as such it should not be deployed with your cloud function, but separately.\n\nThe only available option for running the Engine proxy with cloud functions is to run the proxy in a standalone docker container. To do that, you can follow one of our guides here:\n\n1. [Run a standalone proxy using Node](#standalone-proxy-with-node)\n1. [Run a standalone proxy using Docker](#standalone-proxy-with-docker)\n1. [Run the proxy through a Platform as a Service (eg. Heroku)](#platform-as-a-service)\n\nThe proxy needs to be run separately from your function because it's responsible for capturing, aggregating, and sending to Engine the trace data from each Lamdba instance GraphQL response.\n\nThe main difference between setting up the proxy to work with cloud functions versus setting it up with a persistent server is in how you configure it. You'll want an `engine-config.json` that looks something like this:\n\n```\n{\n  \"apiKey\": \"<ENGINE_API_KEY>\",\n  \"origins\": [\n    {\n      \"lambda\": {\n          \"functionArn\":\"arn:aws:lambda:xxxxxxxxxxx:xxxxxxxxxxxx:function:xxxxxxxxxxxxxxxxxxx\",\n          \"awsAccessKeyId\":\"xxxxxxxxxxxxxxxxxxxx\",\n          \"awsSecretAccessKey\":\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n      }\n    }\n  ],\n  \"frontends\": [\n    {\n      \"host\": \"0.0.0.0\",\n      \"port\": 3001,\n      \"endpoints\": [\"/graphql\"]\n    }\n  ]\n}\n```\n\n> **Note:** This example is for AWS Lambda specifically, for which we have a special `origins` type. Other cloud functions are supported with the standard HTTP invocation, and for non-AWS cloud functions see [the standalone docs](#standalone-proxy-with-docker) for instructions on settup up the Engine proxy as a standalone API gateway to your cloud function. For full configuration details see [proxy config](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md)\n\nThe Engine proxy will invoke the Lambda function as if it was called from Amazon's [API Gateway](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-set-up-simple-proxy.html#api-gateway-simple-proxy-for-lambda-input-format), and the function should return a value suitable for [API Gateway](https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-set-up-simple-proxy.html#api-gateway-simple-proxy-for-lambda-output-format).\n\nIf you've got a proxy running and successfully configured to talk to your cloud functions, then sending a request to it will invoke your function and return the response back to you. If everything is working, you should be able to visit the Metrics tab in the Engine UI and see data from the requests you're sending in the interface!\n\n## Feature configuration\n\nThe following proxy features require specific setup steps to get working.\n\n1. [Automatically **persisting** your queries](#automatic-persisted-queries)\n1. [**Caching** full query responses](#caching)\n1. [Integrating with your **CDN**](#cdn)\n1. [Using the Engine proxy with **query batching**](#query-batching)\n\n<h3 id=\"automatic-persisted-queries\">Automatic Persisted Queries (APQ)</h3>\n\nAutomatically persisting your queries is a performance technique in which you send a query hash to your server instead of the entire GraphQL query string. Your server keeps track of the map between these hashes and their full query strings and does the lookup on its end, saving you the bandwidth of sending the full query string over the wire.\n\nAn added benefit of using APQs with GraphQL is that it's an easy mechanism to transform your GraphQL POST requests into GET requests, allowing you to easily leverage any CDN infrastructure you may already have in place.\n\n> **Note:** Apollo Server 2 reduces the setup necessary to use automatic persisted queries, and these instructions are only necessary when using the Apollo Engine Proxy. To find out more visit the [Apollo Server](/docs/apollo-server/features/apq) docs.\n\nThe query registry that maps query hashes to query strings is stored in a user-configurable cache and read by the Engine proxy. This can either be an in-memory store (configured by default to be 50MB) within each Engine proxy instance, or an external, configurable [memcached](https://memcached.org/) store.\n\nTo use automatic persisted queries with the Engine proxy:\n\n- Use Engine proxy `v1.0.1` or newer.\n- If your GraphQL server is hosted on a different origin domain from where it will be accessed, setup the appropriate [CORS headers](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing) using the `overrideGraphqlResponseHeaders` object on the proxy's `frontend` configuration:\n\n  ```javascript\n  frontends: [{\n    overrideGraphqlResponseHeaders: {\n      'Access-Control-Allow-Origin': '*',\n    },\n  }],\n  ```\n\n- Configure your client to use APQs. If you're using Apollo Client, you can easily use [`apollo-link-persisted-queries`](https://github.com/apollographql/apollo-link-persisted-queries#automatic-persisted-queries) to set this up.\n  <!-- * Verify APQ is working properly using the [verification procedure] (// TODO(dman): get link to new article). -->\n  <!-- * Read [how it works] (// TODO(dman): get link to new article) for additional details. -->\n\nIf everything is set up correctly, you should see your client sending hashes insteady of query strings over the network, but receiving data as if it had sent a normal query.\n\n<h3 id=\"caching\">Caching</h3>\n\nTo bring caching to GraphQL we've developed [Apollo Cache Control](https://github.com/apollographql/apollo-cache-control), an open standard that allows servers to specify exactly which parts of a response can be cached and how long they can be cached for.\n\nWe've built a mechanism into the Engine proxy that allows it to read these \"cache hints\" that servers send along with their responses. It uses these hints to determine if the response can be cached, wether or not it should be cached for everyone or a specific user, and how long it can be cached for.\n\nThe Engine proxy computes a cache privacy level and expiration date by combining the data from all of the fields returned by the server for a particular request. It errs on the safe side, so shorter `maxAge` results override longer and `PRIVATE` scope overrides `PUBLIC`. A missing `maxAge` on a field will default to `0`, meaning that all fields in the result must have a `maxAge > 0` for the response to be cached at all.\n\nThe Engine proxy reads Apollo Cache Control extensions, caching whole query responses based on the computed cacheability of each new query. The Engine UI will visualize how each query was impacted by the cache policy set on it.\n\nThere are just a few steps to enable response caching in Engine proxy, and one of them is optional!\n\n1. [Extend your server's responses with `cacheControl` extensions.](#add-cache-extensions)\n1. [Annotate your schema and/or resolvers with cache control hints.](#annotate-your-responses)\n1. [Optional: Configure cache options in your Engine Proxy configuration.](#configure-cache-options)\n\n<h4 style=\"position: relative;\">\n<span id=\"add-cache-extensions\" style=\"position: absolute; top: -100px;\" ></span>\n1. Add `cacheControl` extensions to your sevrer\n</h4>\n\nIf you're using Apollo Server for your Node GraphQL server, the only server code change required is to add `cacheControl: true` to the options passed to your Apollo Server configuration.\n\n```js line=5,12\n// Apollo Server 2:\nconst server = new ApolloServer({\n  typeDefs,\n  resolvers,\n  cacheControl: true\n});\n\n// Apollo Server 1.2 and onwards:\napp.use(\n  '/graphql',\n  bodyParser.json(),\n  graphqlExpress({\n    schema,\n    context: {},\n    cacheControl: true\n  })\n);\n```\n\nWe're working with the community to add support for Apollo Cache Control to non-Node GraphQL server libraries. Contact us at suppot@apollogrqphql.com if you're interested in joining the community to work on support for `express-graphql` or non-Node GraphQL servers.\n\n<h4 style=\"position: relative;\">\n<span id=\"annotate-your-responses\" style=\"position: absolute; top: -100px;\" ></span>\n2. Add cache hints to your responses\n</h4>\n\nNext we'll add some cache hints to our GarphQL responses. There are two ways to do this -- either dynamically in your resolvers or statically on your schema types and fields. Each `cacheControl` hint has two parameters:\n\n- The `maxAge` parameter defines the number of seconds that Engine Proxy should serve the cached response.\n- The `scope` parameter declares that a unique response should be cached for every user (`PRIVATE`) or a single response should be cached for all users (`PUBLIC`/default).\n\n**Interpreting `maxAge` for a query (how long the query can be cached for):**\n\nTo determine the expiration time of a particular query, the Engine proxy looks at all of the `maxAge` hints returned by the server, which have been set on a per-field basis, and picks the shortest.\n\nFor example, the following trace indicates a 4 minute (`maxAge = 240`) for one field and 1 min (`maxAge = 60`) for another. This means that the Engine proxy will use \"1 minute\" as the overall expiration time for the whole result. You can use the Trace view in the Engine UI to understand your cache hit rates and the overall `maxAge` for your queries:\n\n![Cache hints](../img/apollo-engine/cache-hints.png)\n\n> **Note:** If your query calls a type with a field referencing list of type objects, such as `[Post]` referencing `Author` in the `author` field, Engine will consider the `maxAge` of the `Author` type as well.\n\n**Setting cache scope for a query (public vs. private):**\n\nApollo Engine supports caching of personalized responses using the `scope: PRIVATE` cache hint. Private caching requires that Engine identify unique users, using the methods defined in the `sessionAuth` configuration section.\n\nEngine supports extracting users' identity from an HTTP header (specified in `header`), or an HTTP cookie (specified in `cookie`).\n\nFor security, Engine can be configured to verify the extracted identity before serving a cached response. This allows your service to verify the session is still valid and avoid replay attacks.\nThis verification is performed by HTTP request, to the URL specified in `tokenAuthUrl`.\n\nThe token auth URL will receive an HTTP POST containing: `{\"token\": \"AUTHENTICATION-TOKEN\"}`.\nIt should return an HTTP `200` response if the token is still considered valid.\nIt may optionally return a JSON body:\n\n- `{\"ttl\": 300}` to indicate the session token check can be cached for 300 seconds.\n- `{\"id\": \"alice\"}` to indicate an internal user ID that should be used for identification. By returning a persistent identifier such as a database key, Engine's cache can follow a user across sessions and devices.\n- `{\"ttl\": 600, \"id\": \"bob\"}` to combine both.\n\nAuthentication checks with `ttl>0` will be cached in a `store` named in `sessionAuth`, or in the default 50MB in-memory store.\n\n**Setting static cache hints in your schema:**\n\nCache hints can be added to your schema using directives on your types and fields. When executing your query, these hints will be added to the response and interpreted by Engine to compute a cache policy for the response.\n\nEngine sets cache TTL as the lowest `maxAge` in the query path.\n\n```graphql\ntype Post @cacheControl(maxAge: 240) {\n  id: Int!\n  title: String\n  author: Author\n  votes: Int @cacheControl(maxAge: 500)\n  readByCurrentUser: Boolean! @cacheControl(scope: PRIVATE)\n}\n\ntype Author @cacheControl(maxAge: 60) {\n  id: Int\n  firstName: String\n  lastName: String\n  posts: [Post]\n}\n```\n\nYou should receive cache control data in the `extensions` field of your response:\n\n```js\n\"cacheControl\": {\n  \"version\": 1,\n  \"hints\": [\n    {\n      \"path\": [\n        \"post\"\n      ],\n      \"maxAge\": 240\n    },\n    {\n      \"path\": [\n        \"post\",\n        \"votes\"\n      ],\n      \"maxAge\": 30\n    },\n    {\n      \"path\": [\n        \"post\",\n        \"readByCurrentUser\"\n      ],\n      \"scope\": \"PRIVATE\"\n    }\n  ]\n}\n```\n\nFor the above schema, there are a few ways to generate different TTLs depending on your query. Take the following examples:\n\n_Example 1_\n\n```graphql\nquery getPostsForAuthor {\n  Author {\n    posts\n  }\n}\n```\n\n`getPostsForAuthor` will have `maxAge` of 60 seconds, even though the `Post` object has `maxAge` of 240 seconds.\n\n_Example 2_\n\n```graphql\nquery getTitleForPost {\n  Post {\n    title\n  }\n}\n```\n\n`getTitleForPost` will have `maxAge` of 240 seconds (inherited from Post), even though the `title` field has no `maxAge` specified.\n\n_Example 3_\n\n```graphql\nquery getVotesForPost {\n  Post {\n    votes\n  }\n}\n```\n\n`getVotesForPost` will have `maxAge` of 240 seconds, even though the `votes` field has a higher `maxAge`.\n\n**Setting dynamic cache hints in your resolvers:**\n\nIf you'd like to add cache hints dynamically, you can use a programmatic API from within your resolvers.\n\n```js\nconst resolvers = {\n  Query: {\n    post: (_, { id }, _, { cacheControl }) => {\n      cacheControl.setCacheHint({ maxAge: 60 });\n      return find(posts, { id });\n    }\n  }\n}\n```\n\n**Setting a default `maxAge` for your whole schema:**\n\nThe power of cache hints comes from being able to set them precisely to different values on different types and fields based on your understanding of your implementation's semantics. But when getting started, you might just want to apply the same `maxAge` to most of your resolvers. You can specify a default max age when you set up `cacheControl` in your server. This max age will be applied to all resolvers which don't explicitly set `maxAge` via schema hints (including schema hints on the type that they return) or the programmatic API. You can override this for a particular resolver or type by setting `@cacheControl(maxAge: 0)`.\n\nJust like when you set `@cacheControl(maxAge: 5)` explicitly on a field or a type, data is considered to be public by default and the cache will be shared among all users of your site, so when using this option, be sure that you're really OK with creating a shared cache for all of your GraphQL queries. You can still override a specific type or resolver to use the private cache by setting `@cacheControl(scope: PRIVATE)`.\n\nFor example, for Express:\n\n```javascript\napp.use(\n  '/graphql',\n  bodyParser.json(),\n  graphqlExpress({\n    schema,\n    context: {},\n    tracing: true,\n    cacheControl: {\n      defaultMaxAge: 5\n    }\n  })\n);\n```\n\nSetting `defaultMaxAge` requires `apollo-server-*` 1.3.4 or newer.\n\n<h4 style=\"position: relative;\">\n<span id=\"configure-cache-options\" style=\"position: absolute; top: -100px;\" ></span>\n3. Optional: Configure cache options\n</h4>\n\nAs long as you're using a version of the Engine proxy that's greater than `1.0`, you won't have to configure anything to use public response caching. The proxy comes with a default 50MB in-memory cache. To enable private response caching or to configure details of how caching works, there are a few fields in the Engine configuration (ie, argument to `new ApolloServer`) that are relevant.\n\nHere is an example of changing the Engine config for caching `scope: PUBLIC` responses to use memcached instead of an in-memory cache.\nSince no `privateFullQueryStore` is provided, `scope: PRIVATE` responses will not be cached.\n\n```js\nconst engine = new ApolloEngine({\n  stores: [\n    {\n      memcache: {\n        url: ['localhost:4567']\n      }\n    }\n  ]\n  // ...\n});\n```\n\nBelow is an example of an Engine config for caching `scope: PUBLIC` and `scope: PRIVATE` responses, using the default (empty-string-named 50MB in-memory cache) for public responses and authorization tokens, and memcached for private responses.\nBy using a private response cache, we guarantee that a response affecting multiple users is never evicted for a response affecting only a single user.\n\n```js\nconst engine = new ApolloEngine({\n  stores: [\n    {\n      name: 'privateResponseMemcache',\n      memcache: {\n        url: ['localhost:4567']\n      }\n    }\n  ],\n  sessionAuth: {\n    header: 'Authorization',\n    tokenAuthUrl: 'https://auth.mycompany.com/engine-auth-check'\n  },\n  queryCache: {\n    privateFullQueryStore: 'privateResponseMemcache'\n    // By not mentioning publicFullQueryStore, we keep it enabled with\n    // the default empty-string-named in-memory store.\n  }\n  // ...\n});\n```\n\n**stores**\n\nStores is an array of places for Engine to store data such as: query responses, authentication checks, or persisted queries.\n\nEvery store must have a unique `name`. The empty string is a valid name; there is a default in-memory 50MB cache with the empty string for its name which is used for any caching feature if you don't specify a store name. You can specify the name of `\"disabled\"` to any caching feature to turn off that feature.\n\nEngine supports two types of stores:\n\n- `inMemory` stores provide a bounded LRU cache embedded within the Engine Proxy.\n  Since there's no external servers to configure, in-memory stores are the easiest to get started with.\n  Since there's no network overhead, in-memory stores are the fastest option.\n  However, if you're running multiple copies of Engine Proxy, their in-memory stores won't be shared --- a cache hit on one server may be a cache miss on another server.\n  In memory caches are wiped whenever Engine Proxy restarts.\n\n  The only configuration required for in memory stores is `cacheSize` --- an upper limit specified in bytes. It defaults to 50MB.\n\n- `memcache` stores use external [Memcached](https://memcached.org/) server(s) for persistence.\n  This provides a shared location for multiple copies of Engine Proxy to achieve the same cache hit rate.\n  This location is also not wiped across Engine Proxy restarts.\n\n  Memcache store configuration requires an array of addresses called `url`, for the memcached servers. (This name is misleading: the values are `host:port` without any URL scheme like `http://`.) All addresses must contain both host and port, even if using the default memcached port. The AWS Elasticache discovery protocol is not currently supported.\n  `keyPrefix` may also be specified, to allow multiple environments to share a memcached server (i.e. dev/staging/production).\n\nWe suggest developers start with an in-memory store, then upgrade to Memcached if the added deployment complexity is worth it for production.\nThis will give you much more control over memory usage and enable sharing the cache across multiple Engine proxy instances.\n\n**sessionAuth**\n\nThis is useful when you want to do per-session response caching with Engine. To be able to cache results for a particular user, Engine needs to know how to identify a logged-in user. In this example, we've configured it to look for an `Authorization` header, so private data will be stored with a key that's specific to the value of that header.\n\nYou can specify that the session ID is defined by either a header or a cookie. Optionally, you can specify a REST endpoint which the Engine Proxy can use to determine whether a given token is valid.\n\n**queryCache**\n\nThis maps the types of result caching Engine performs to the stores you've defined in the `stores` field.\nIn this case, we're sending public and private cached data to unique stores, so that responses affecting multiple users will never be evicted for responses affecting a single user.\n\nIf you leave `queryCache.publicFullQueryStore` blank, it will use the default 50MB in-memory cache. Set it to `\"disabled\"` to turn off the cache.\n\nIf you configure `sessionAuth` but leave `queryCache.privateFullQueryStore` blank, it will use the default 50MB in-memory cache. Set it to `\"disabled\"` to turn off the cache.\n\n#### Visualizing caching\n\nOne of the best parts about using caching via the Engine proxy is that you can easily see how it's working once you set it up. The Metrics views in the Engine UI show you exactly which responses are cached and which are not, so you can understand how caching is helping you make your server more performant. Here's what the Engine metrics charts look like when you have everything set up correctly:\n\n![Cache metrics charts](../img/apollo-engine/cache-metrics.png)\n\n#### How HTTP headers affect caching\n\nThe main way that your GraphQL server specifies cache behavior is through the `cacheControl` GraphQL extension, which is rendered in the body of a GraphQL response. However, Engine also understands and sets several caching-related HTTP headers.\n\n**HTTP headers interpreted by Engine**\n\nEngine will never decide to cache responses in its response cache unless you tell it to with the `cacheControl` GraphQL extension. However, Engine does observe some HTTP headers and can use them to restrict caching further than what the extension says. These headers include:\n\n- `Cache-Control` **response** header: If the `Cache-Control` response header contains `no-store`, `no-cache`, or `private`, Engine will not cache the response. If the `Cache-Control` response header contains `max-age` or `s-maxage` directives, then Engine will not cache any data for longer than the specified amount of time. (That is, data will be cached for the minimum of the header-provided `max-age` and the extension-provided `maxAge`.) `s-maxage` takes precedence over `max-age`.\n- `Cache-Control` **request** header: If the `Cache-Control` request header contains `no-cache`, Engine will not look in the cache for responses. If the `Cache-Control` request header contains `no-store`, Engine will not cache the response.\n- `Expires` response header: If the `Expires` response header is present, then Engine will not cache any data past the given date. The `Cache-Control` directives `s-maxage` and `max-age` take precedence over `Expires`.\n- `Vary` response header: If the `Vary` response header is present, then Engine will not return this response to any request whose headers named in the `Vary` header don't match the request that created this response. (For example, if a request had a `Accept-Language: de` header and the response had a `Vary: Accept-Language` header, then that response won't be returned from the cache to any response that does not also have a `Accept-Language: de` header.) Additionally, Engine uses a heuristic to store requests that have different values for headers that it suspects may show up in the response `Vary` header under different cache keys; currently that heuristic is that it assumes that any header that has ever shown up in a `Vary` header in a GraphQL response may be relevant.\n\n**HTTP headers set by Engine**\n\nWhen returning a GraphQL response which is eligible for the full-query cache (ie, all of the data has a non-zero `maxAge` set in the `cacheControl` GraphQL extension), Engine sets the `Cache-Control` header with a `max-age` directive equal to the minimum `maxAge` of all data in the response. If any of the data in the response has a `scope: PRIVATE` hint, the `Cache-Control` header will include the `private` directive; otherwise it will include the `public` directive. This header completely replaces any `Cache-Control` and `Expires` headers provided by your GraphQL server.\n\n<h3 id=\"cdn\">CDN integration</h3>\n\nMany high-traffic web services use content delivery networks (CDNs) such as [Cloudflare](https://www.cloudflare.com/), [Akamai](https://www.akamai.com/) or [Fastly](https://www.fastly.com/) to cache their content as close to their clients as possible.\n\n> Apollo Server 2 supports CDN integration out of the box and doesn't require the Engine Proxy. To learn how, read through the [guide on CDN integration](/docs/apollo-server/features/apq#cdn). For other server implementations, the Engine Proxy makes it straightforward to use CDNs with GraphQL queries whose responses can be cached while still passing more dynamic queries through to your GraphQL server.\n\nTo use the Engine proxy behind a CDN, you need to be able to tell the CDN which GraphQL responses it's allowed to cache and you need to make sure that your GraphQL requests arrive in a format that CDNs cache. Engine Proxy supports this by combining its [caching](#caching) and [automatic persisted queries](#automatic-persisted-queries) featues. This section explains the basic steps for setting up these features to work with CDNs; for more details on how to configure these features, see their respective sections.\n\n#### 1. Set up caching using Apollo Cache Contol\n\nYou'll need to follow the guide in the [caching](#caching) section to set up your server to extend its requests with cache hint extensions.\n\nOnce you have your server sending responses with cache hints in the `response.extensions` your Engine proxy will start serving the HTTP `Cache-Control` header on the _fully cacheable_ responses (any response containing only data with non-zero `maxAge` annotations). The header will refer to the minimum `maxAge` value across the whole response, and it will be `public` unless some of the data is tagged `scope: PRIVATE`. You should be able to observe this header in your browser's dev tools. The Engine proxy will also cache the responses in its own default public in-memory cache.\n\n#### 2. Set up automatic persisted queries\n\nAt this point, GraphQL requetss are still POST requests. Most CDNs will only cache GET requests, and GET requests generally work best if the URL is of a bounded size. To work with this, enable Apollo Engine Proxy's Automatic Persisted Queries (APQ) support. This allows clients to send short hashes instead of full queries, and you can configure it to use GET requests for those queries.\n\nTo do this, follow the steps in the [guide above](#automatic-persisted-queries). After completing the steps in that section of the guide, you should be able to observe queries being sent as `GET` requests with the appropriate `Cache-Control` response headers using your browser's developer tools.\n\n#### 3. Set up your CDN\n\nHow precisely this works relies upon which CDN you chose. Configure your CDN to send requests to your Engine proxy-powered GraphQL app. For some CDNs, you may need to specially configure your CDN to honor origin Cache-Control headers. For example, here is [Akamai's documentation on that setting](https://learn.akamai.com/en-us/webhelp/ion/oca/GUID-57C31126-F745-4FFB-AA92-6A5AAC36A8DA.html). If all is well, your cacheable queries should now be cached by your CDN! Note that requests served directly by your CDN will not show up in your Engine dashboard.\n\n<h3 id=\"query-batching\">Query batching</h3>\n\nQuery batching allows your client to batch multiple queries into one request. This means that if you render several view components within a short time interval, for example a navbar, sidebar, and content, and each of those do their own GraphQL query, the queries can be sent together in a single roundtrip.\n\nA batch of queries can be sent by simply sending a JSON-encoded array of queries in the request:\n\n```js\n[\n { \"query\": \"{\n  feed(limit: 2, type: NEW) {\n    postedBy {\n      login\n    }\n    repository {\n      name\n      owner {\n        login\n      }\n    }\n  }\n}\" },\n { \"query\": \"query CurrentUserForLayout {\n  currentUser {\n    __typename\n    avatar_url\n    login\n  }\n}\" }\n]\n```\n\nBatched requests to servers that don’t support batching fail without explicit code to handle batching, however the Engine proxy has batched request handling built-in.\n\nIf a batch of queries is sent, the batches are fractured by the Engine proxy and individual queries are sent to origins in parallel. Engine will wait for all the responses to complete and send a single response back to the client. The response will be an array of GraphQL results:\n\n```js\n[\n  {\n    data: {\n      feed: [\n        {\n          postedBy: {\n            login: 'AleksandraKaminska'\n          },\n          repository: {\n            name: 'GitHubApp',\n            owner: {\n              login: 'AleksandraKaminska'\n            }\n          }\n        },\n        {\n          postedBy: {\n            login: 'ashokhein'\n          },\n          repository: {\n            name: 'memeryde',\n            owner: {\n              login: 'ashokhein'\n            }\n          }\n        }\n      ]\n    }\n  },\n  {\n    data: {\n      currentUser: {\n        __typename: 'User',\n        avatar_url: 'https://avatars2.githubusercontent.com/u/11861843?v=4',\n        login: 'johannakate'\n      }\n    }\n  }\n];\n```\n\nIf your origin supports batching and you'd like to pass entire batches through instead of having the Engine proxy break them up, set `supportsBatch: true` within the origins section of the configuration:\n\n```js\nconst engine = new ApolloEngine({\n  apiKey: 'ENGINE_API_KEY',\n  origins: [\n    {\n      supportsBatch: true\n    }\n  ]\n});\n```\n\n#### Batching in Apollo Client with Engine\n\nApollo Client has built-in support for batching queries in your client application. To learn how to use query batching with Apollo Client, visit the in-depth guide on our package [`apollo-link-batch-http`](/docs/link/links/batch-http.html).\n\nIf you have questions, we're always available at support@apollographql.com.\n\n## Proxy configuration\n\nView our [full proxy configuration doc](https://github.com/apollographql/apollo/blob/master/docs/source/references/proxy-config.md) for information on every available configuration option for the Engine proxy.\n\n## Release notes\n\nView our [proxy release notes doc](https://github.com/apollographql/apollo/blob/master/docs/source/references/engine-proxy-release-notes.md) for documentation on each proxy version that's been released and a changelog of what that version contained.\n\n## Troubleshooting\n\n#### Check that your server is supported\n\nCheck that your server is one of the supported GraphQL servers listed [here](apollo-tracing.html).\n\nIf it is, please make sure you're running the [currently tested version](https://github.com/apollographql/apollo-engine-js/blob/master/package.json) of Apollo Server and your Node HTTP server package (Express, Connect, Hapi, Koa, etc), and the latest released versions of the Engine and Apollo packages.\n\nYou can enter the following into the commandline to see the latest package version, or look in `package.json`.\n\n```\n$ npm view apollo-engine version\n```\n\n#### Set debug logging levels for the Proxy\n\nSupport may request that you set the Engine Proxy logging level to DEBUG or higher. These logs will be part of your GraphQL server logs (if Proxy is deployed with the `ApolloEngine` Node API) or in the Proxy process logs (if Proxy is deployed standalone).\n\n```js\nconst engine = new ApolloEngine({\n  logging: {\n    level: 'DEBUG' // Engine Proxy logging level. DEBUG, INFO, WARN or ERROR\n  }\n});\n```\n\n#### Ensure you enabled Apollo Tracing\n\nTest that you enabled Apollo Tracing by checking if your GraphQL server returns trace extensions in GraphQL responses when not executed through Engine. If it does, it's is a sign that Apollo Tracing is properly configured.\n\n<h3 id=\"troubleshooting-faqs\">Troubleshooting FAQs</h3>\n\n#### I'm getting an error saying “The query failed!”, how do I fix it?\n\nThis may mean you need to upgrade an NPM package. Check that your package versions are all up-to-date. This also may mean a variety of other things. When this error is paired with a 503 error, the query did not receive an expected response.\n\n#### Why isn't data showing up in my dashboard?\n\nWe recommend double-checking that the Engine API key for the correct service is specified in the `ApolloEngine` constructor.\n\n#### How do I check that the Engine Proxy is up and running?\n\nThere is a health check URL at `[engine-frontend-url]/.well-known/apollo/engine-health`, which returns an HTTP status of 200 if the server is running.\n\n#### What is shown on the Engine Proxy logs?\n\nEach time the Engine proxy starts, you should see the following two lines in the logs indicating the Engine proxy is healthy:\n\n```\nINFO[0000] Started HTTP server.                          address=\"[::]:50485\"\nINFO[0000] Engine proxy started.                         version=2018.02-93-ge050c6b93\n```\n\nThese lines say what port Engine is listening on and the internal version number for the Proxy. If you don't want to see them, set the log level to 'WARN'\n\n```js\nconst engine = new ApolloEngine({\n  logging: {\n    level: 'WARN'\n  }\n});\n```\n\n<h3 id=\"get-support\">Submit a support ticket</h3>\n\nPlease include the following when submitting an issue to our support team:\n\n- Platform of GraphQL server\n- Are you using `new ApolloEngine`, `new ApolloEngineLauncher`, or the Docker container?\n- Engine configuration: arguments to `new ApolloEngine` or `new ApolloEngineLauncher`, or the JSON configuration file for the Docker container\n- Platform of GraphQL server\n- The query submitted and the full response\n\nSubmit your issue to support at apollographql.com or you can join us in [Apollo's Spectrum community](https://spectru.chat/apollo).\n","path":"/references/engine-proxy","filePath":"docs/source/references/engine-proxy.md"},{"content":"The versions given here are both for the [`apollo-engine` Node.js package](https://www.npmjs.com/package/apollo-engine) and the `gcr.io/mdg-public/engine` Docker container.\n\n<h3 id=\"v1.1.2\" title=\"v1.1.2\">1.1.2 - 2018-06-08</h3>\n\n* Fixes bug involving the X-Forwarded-For header not being set.\n* Simplified API for users of the `pipePath` argument in `engine.listen(...)` with the apollo-engine `npm` package. Now, rather than needing to explicitly specify the `pipePath` argument in the call, an string argument to `port` that begins with `\\\\.\\pipe\\` will result in listening on the specified named pipe. Thus, calls such as `engine.listen({pipePath: \"\\\\.\\pipe\\bar\", httpServer: foo})` can be replaced by `engine.listen({port: \"\\\\.\\pipe\\bar\", httpServer: foo})`, which should help users developing locally using TCP and deploying to servers using IISNode, such as Microsoft Azure.\n\n<h3 id=\"v1.1.1\" title=\"v1.1.1\">1.1.1 - 2018-05-07</h3>\n\n* The Engine Proxy now sanitizes invalid UTF-8 in HTTP headers and variables, fixing the error `Error reporting traces. error=\"POST https://engine-report.apollodata.com/api/ss/traces giving up after 6 attempts\"`\n* You may now use Engine with named pipes on Windows machines to support Node server deployments to Microsoft Azure. Instead of using the `port` argument in `engine.listen({port: process.env.PORT, httpServer: foo})`, you can now specify the `pipePath` argument to listen on a named pipe such as `engine.listen({pipePath: \"\\\\.\\pipe\\bar\", httpServer: foo})`. In Microsoft Azure, `process.env.PORT` is an acceptable input to `pipePath`.\n* The Engine Proxy now differentiates request timeouts from failed requests. This will remove the “Unable to communicate with backend” error and replace it with two errors: one for no response or refused connection, and one for request timeouts.\n* The Engine Proxy now sets the `X-Forwarded-For` header and does string appending to other `X-Forwarded-` headers if they are already set.\n\n<h3 id=\"v1.1.0\" title=\"v1.1.0\">1.1.0 - 2018-04-10</h3>\n\nBecause this is a minor release, if you are using Engine via the Docker container and have specified the `1.0` tag, you'll need to change to the `1.1` tag to upgrade to this release.\n\n* The Engine Proxy now supports serving HTTPS over TLS, including HTTP/2.\n* You may now set your API key with the environment variable `ENGINE_API_KEY` in addition to with the `apiKey` configuration option.\n* The Engine Proxy now sets the `X-Apollo-Engine` header on requests it proxies so that your origin GraphQL server can tell if it is running behind Engine. (This is primarily intended to improve diagnostics if Engine is misconfigured.)\n\n\n<h3 id=\"v1.0.6\" title=\"v1.0.6\">1.0.6 - 2018-04-06</h3>\n\n* New `reporting.noTraceErrors` option to disable sending error traces to Apollo servers. Use this if your error messages may contain [personal data](https://en.wikipedia.org/wiki/Personal_data). If you are interested in a more fine-grained way to configure this, contact <a href=\"https://engine.apollographql.com/support\">Apollo support</a>.\n* Fix problems running `ApolloEngine` when a corporate HTTP proxy is configured with an environment variable such as `$HTTP_PROXY`. (Specifically, make the default [`innerHost` option to `engine.listen`](../setup-node.html#api-engine.listen) actually be `127.0.0.1` as documented rather than the unspecified interface; the previously implemented default was unintentional as well as the cause of the corporate proxy bug.)\n\n<h3 id=\"v1.0.5\" title=\"v1.0.5\">1.0.5 - 2018-04-05</h3>\n\nThis release include a variety of changes related to caching.\n\n* The Engine Proxy now observes the `Vary` header in HTTP responses. See the new [documentation of cache header support](../proxy/guides.html#caching) for more details.\n* The Engine Proxy now explicitly requests that \"persisted query not found\" responses are not cached by CDNs or browsers. (Typically these responses are followed by the client informing Engine of the full matching query, so caching the not-found response was effectively cache poisoning.)\n* The Engine Proxy now includes `Cache-Control` headers on responses served from its cache, not just on responses it stores to its cache.\n* The Engine Proxy no longer uses a generic HTTP heuristic to generate a max age limit for responses with the HTTP header `Last-Modified` but no other HTTP-level max age specification. This was added accidentally in v1.0.4 and is not necessary given that we only cache data that explicitly requests it in the GraphQL extension.\n* The Engine Proxy now properly comma-separates fields in generated `Cache-Control` response headers.\n* The warning when trying to insert an oversized item into an in-memory cache is now more explicit about the size limit. (Items in the in-memory cache cannot be larger than approximately 1/1024 of the total cache size.)\n\n<h3 id=\"v1.0.4\" title=\"v1.0.4\">1.0.4 - 2018-03-23</h3>\n\n* The Engine Proxy now will compress responses to GraphQL queries by default if the client sends the standard HTTP `Accept-Encoding: gzip` header. You can disable this by passing `frontends: [{responseCompression: {disabled: true}}]` to the `ApolloEngine` constructor. (The Engine Proxy continues to accept compressed responses from your GraphQL origin by default as well.) Engine will never proactively compress responses to requests on non-GraphQL paths but will pass through any compression applied by the server it is proxying to.\n* The Engine Proxy has better support for HTTP caching headers:\n    * The Engine Proxy has a better parser for `Cache-Control` and similar headers sent by your GraphQL origin, which it can use to constrain the response's cache policy further than what the GraphQL `cacheControl` extension dictates. We still recommend that Engine users use the `cacheControl` GraphQL extension (if supported by your GraphQL server library) rather than HTTP caching headers so that your GraphQL server will be ready for partial query caching.\n    * The Engine Proxy now sets the `Cache-Control` header on cacheable GraphQL responses.\n    * The Engine Proxy now sets the `Age` header when serving responses from the query response cache.\n    * The Engine Proxy now respects the `Cache-Control: no-cache` HTTP header in client requests.\n* The Engine Proxy has more detailed logging about caching decisions when `logging.level` is set to `DEBUG`.\n* The Engine Proxy binary properly shuts down on the `SIGUSR2` signal (which is sent by the `nodemon` utility).\n* More details about GraphQL errors are included in traces sent to the Engine Service.\n* The `apollo-engine` npm package now includes all the dependencies needed to be included in a TypeScript project.\n\n<h3 id=\"v1.0.3\" title=\"v1.0.3\">1.0.3 - 2018-03-19</h3>\n\nThis version only has JS changes: the Docker container release is identical to 1.0.2.\n\n* `engine.listen()` and `launcher.start()` now register handlers for the `exit`, `uncaughtException`, `SIGINT`, `SIGTERM`, and `SIGUSR2` [events on `process`](https://nodejs.org/api/process.html#process_process_events) to kill the Engine Proxy process. You can customize the list of events with the new `processCleanupEvents` option.\n\n<h3 id=\"v1.0.2\" title=\"v1.0.2\">1.0.2 - 2018-03-14</h3>\n\n* Add `overrideGraphqlResponseHeaders` frontend configuration option. This option lets you set HTTP headers to be sent with all GraphQL HTTP responses. For now, this is required to avoid CORS errors if you use [persisted queries](./auto-persisted-queries.html) from clients from a different origin from your GraphQL (Engine) frontend.\n* Fix bug where certain malformed GraphQL requests were reported to Engine as having taken multiple millennia.\n* Improve support for `application/graphql` requests. We still recommend sending your requests as JSON, which is supported by more servers and supports variables, operation name, and client-to-server extension, but we now deal better with `application/graphql` requests if you send them.\n* Improve error handling when your GraphQL origin sends Engine an unsupported Content-Type.\n\n<h3 id=\"v1.0.1\" title=\"v1.0.1\">1.0.1 - 2018-03-07</h3>\n\nv1 of `apollo-engine` has a redesigned streamlined Node API called `ApolloEngine`. See [the 1.0 migration guide](./1.0-migration.html) for details on how to upgrade.  In addition to a simplified API and higher performance, the new API adds support for the Restify and Hapi v16 web frameworks, and it is easy to integrate with any Node web framework that works with `http.Server`.\n\nIf you aren't integrating with a Node GraphQL server but still find Node programs easier to run than Docker Containers, the `apollo-engine` npm module has a new API called `ApolloEngineLauncher` that allows you to run the Engine Proxy with arbitrary configuration without hooking into a Node GraphQL server.\n\nFeatures that used to depend on a caching store definition now are on by default, sharing a 50MB in-memory cache. Specifically:\n* The public full-query response cache is enabled by default. Only responses annotated with the `cache-control` extension are cached.\n* The private full-query response cache is enabled by default if `sessionAuth` is configured. Only responses annotated with the `cache-control` extension are cached.\n* Automatic persisted queries are on by default.\n* If `sessionAuth` is configured with a `tokenAuthUrl`, verifications are cached by default.\nIf you don't like these defaults, you can set each store name field to `\"disabled\"` to turn off the relevant feature. If you want to change the default cache size in bytes, add `stores: [{inMemory: {cacheSize: 123456}}]` to your Engine config (ie, the argument to `new ApolloEngine()`). If you want to change the default cache to memcached, add `stores: [{memcache: {url: [\"localhost:1234\"]}}]` to your Engine config.\n\nStarting with v1, the Docker container releases use the same version numbers as the `apollo-engine` npm releases. The following changes are mostly relevant to users of the Docker container:\n* It's valid to specify zero frontends. Engine Proxy will default to one with all default values.\n* The deprecated `endpoint` field is removed from `frontends` configuration. Put your endpoint (GraphQL URL path) in a list in `endpoints` instead, or continue to let `apollo-engine` set it for you.\n* The `endpoints` field on frontends now defaults to `[\"/graphql\"]` instead of being required.\n* The header secret feature (required so that double proxying middleware could tell if it's seeing the request for the first or second time) is removed. This was intended only for internal use by `apollo-engine`.\n* If you configure a frontend endpoint as `/graphql`, requests to `/graphql/` should be served also. (The `apollo-engine` `Engine` wrapper previously implemented this; now it is implemented natively inside the Engine Proxy.)\n* A bug that could lead to the warning `Encountered trace without end time. This is a bug in Engine proxy.` has been fixed.\n\n\n(v1.0.0 was a mistakenly published empty package from the beginning of apollo-engine's development. Do not use v1.0.0 --- go directly to v1.0.1!)\n\n\n<h3 id=\"v0.9.1\" title=\"v0.9.1\">0.9.1 - 2018-03-01</h3>\n\n* The `prettier` package was accidentally added as a dependency rather than a dev-only dependency in 0.9.0. It is now in devDependencies.\n\n<h3 id=\"v0.9.0\" title=\"v0.9.0\">0.9.0 - 2018-03-01</h3>\n\nSimplify how the apollo-engine npm module communicates with the Engine Proxy binary.  Backwards-incompatible changes:\n  - The `logger` option to `new Engine` added in 0.8.9 no longer exists. It is replaced by `proxyStdoutStream` and `proxyStderrStream` options, as well as a `restarting` event on the `Engine` object.\n  - The default log style is now the same as in the Docker container release of Engine Proxy: textual logs over stdout, instead of JSON over stderr.\n* Unknown fields in the Engine config file (or `engineConfig` option to `new Engine`) and unknown options passed to `new Engine` now result in an error.\n* Added support for receiving client-provided GraphQL extensions such as `persistedQuery` over GET requests. To use GET requests (with or without persisted queries), we recommend you upgrade to [`apollo-link-http` 1.5.0](https://www.npmjs.com/package/apollo-link-http) and pass `useGETForQueries: true` to `createHttpLink` in your client code.\n* Add support for proxying non-GraphQL requests with Lambda origins. This allows serving GraphiQL directly from a Lambda handler.\nNo additional configuration is required to start using this feature.\n* Added the ability to define the frontend port (the port Engine proxy will listen on) from an environment variable.\n  To define the frontend port via the environment, remove `\"port\": 1234,` from the frontend configuration, and add `\"portFromEnv\": \"MY_PORT_VARIABLE\"`.\n  This will cause the proxy to read the `MY_PORT_VARIABLE` environment variable.\n  Heroku users in particular should set `\"portFromEnv\": \"PORT\"`.\n* Improve error messages for GraphQL request parse failures and for several common configuration problems.\n* Bugfix to automatic config reloading.\n\n<h3 id=\"v0.8.10\" title=\"v0.8.10\">0.8.10 - 2018-02-12</h3>\n\n* Added support for GZIP content encoding for responses from Lambda origins.\n* Added support for function qualifiers for Lambda origins.\n* Allows per-endpoint origin specification on frontends via `endpointMap`, a &lt;string,string&gt; map from endpoint path to `originName`. Users can use this field instead of `endpoints` and `originName` to route different URL paths on a frontend to serve different origins. If `endpointMap` is set, the Proxy will return a 404 error to HTTP requests sent to paths that don't match one of its keys. The proxy will also verify that only one of `endpoint` [deprecated], `endpoints`, and `endpointMap` are set.\n\t* For example, if you have two origins with names `[adminOrigin, userOrigin]` and want to forward requests to `/admin` and `/user` respectively, on the `Frontend` config, specify `\"endpointMap\": {\"/admin\":\"adminOrigin\", \"/user\":\"userOrigin\"}` and do not specify `endpoint` or `endpoints`.\n* Fixed a bug where all custom extensions were assumed to be maps.\n\n<h3 id=\"v0.8.9\" title=\"v0.8.9\">0.8.9 - 2018-02-06</h3>\n\n* Fixed a bug where `Host` header was still not forwarded to origin servers if present.\n* Exposed stats field to better track Engine proxy memory usage.\n* Properly forward the Host header to the Engine Proxy.\n* New `logger` option to override some aspects of logging in apollo-engine. (Removed in 0.9.0.)\n* Do not override http origin url if set.\n* Allow endpoint to end with '/' or '\\'.\n\n### 2018.01-54-gce490265c - 2018-01-31\n\n* Fixed a bug where the `Host` header was not forwarded to origin servers. If the `Host` header is present, it will also be sent in the `X-Forwarded-Host` header. Both of these header values can be overridden via the field mentioned below.\n* Added the ability for users to override which headers are sent to their GraphQL origin. Users can do this by specifying the `overrideRequestHeaders` field in `origin.http` in the Engine config object. By default Engine will forward all header values it receives to the origin server. This field is only for users that want to override the default behavior.\n  * For example, to override the `Host` header which may need to be done when deploying Engine inside of a PaaS (such as Heroku) follow instructions [here](../setup-virtual.html).\n\n### 2018.01-43-g1747440e6 - 2018-01-29\n\n* Fixed an issue where Engine proxy would cache responses that set a cookie, causing cache hits to set the same cookie.\n  Engine proxy now skips cache for:\n    * Responses with a `Set-Cookie` header.\n    * Responses with a `WWW-Authenticate` header.\n    * Responses with a `Cache-Control` header value of: `no-cache` ,`no-store` or `private`.\n    * Responses with an `Expires` header of `0`, or any date in the past.\n* Fixed several issues with timestamps included in reports sent to engine backend.\n* Added the ability to dump stacktraces of all running threads when Engine proxy receives a `SIGUSR2` signal.\n  When requested, traces are dumped to stderr. This should not be necessary unless requested by Apollo support.\n* Added the ability to collect performance data from Engine proxy using [Go pprof profiler](https://golang.org/pkg/net/http/pprof/).\n  To enable the pprof server, add `\"debugServer\": {\"port\": 1234}` to your engine configuration.\n  Note that the pprof server offers no security, so a firewall etc is required if running in production.\n  Enabling the debug server should not be necessary unless requested by Apollo support.\n\n### 2018.01-17-g9c203510f - 2018-01-16\n\n* Fixed an issue where a data race could cause the proxy to crash.\n\n### 2018.01-1-gc024df504 - 2018-01-04\n\n* Added a flag to disable certificate validation when communicating with HTTPS origins.\n  To disable certificate validation, set `disableCertificateCheck: true` within the `http` section of the origin's configuration.\n  This is strongly discouraged, as it leaves Engine vulnerable to man-in-the-middle attacks. It is intended for testing only.\n\n* Added a flag to use custom certificate authorities when communicating with HTTPS origins.\n  To use custom certificate authorities, set: `trustedCertificates: /etc/ssl/cert.pem` (or another file path) within the `http` section of the origin's configuration.\n  CA certificates must be PEM encoded. Multiple certificates can be included in the same file.\n\n### 2017.12-45-g12ba029f9 - 2017-12-20\n\n* Added support for multiple endpoints per origin through a new `endpoints` setting, deprecated the previous `endpoint` setting.\n* Added a health check URL at `/.well-known/apollo/engine-health`, currently returning HTTP status 200 unconditionally.\n* Fixed an issue where reports would always be sent on shut down, even when reporting was disabled.\n* Fixed issues with reloading of `frontend`s, and dependencies like logging and caches.\n\n### 2017.12-28-gcc16cbea7 - 2017-12-12\n\n* Added a flag to disable compression when communicating with HTTP origins.\n  To disable compression, set `disableCompression: true` within the `http` section of the origin's configuration.\n* Exposed the maximum number of idle connections to keep open between engine an an HTTP origin.\n  To tune the maximum number of idle connections, set `maxIdleConnections: 1234` within the `http` section of the origin's configuration.\n  If no value is provided, the default is 100.\n* Fixed an issue where Engine would return an empty query duration on internal error.\n* Fixed an issue where Engine would return an empty query duration on cache hit.\n* Fixed an issue where configuration reloading would not affect cache stores.\n* Reduced the overhead of reporting while it is disabled.\n* Added support for GraphQL `\"\"\"block strings\"\"\"`.\n* *Breaking*: Added `name` field to origin configurations. Every defined origin must have a unique name (the empty string is OK).\n  This only affects configurations with multiple origins, which should be rare.\n\n### 2017.11-137-g908dbec6f - 2017-12-05\n\n* Improved persisted query handling so that cache misses are not treated like other GraphQL errors.\n* Fixed an issue where GraphQL query extensions (like `persistedQuery`) would be forwarded to the origin server. This caused issues with origins other than Apollo Server.\n\n### 2017.11-121-g2a0310e1b - 2017-11-30\n\n* Improved performance when reverse proxying non-GraphQL requests.\n* Removed `-restart=true` flag, which spawned and managed a child proxy process. This was only used by the `apollo-engine` Node.js package.\n* Added POSIX signal processing:\n  * On `SIGHUP`, reload configuration. Configurations provided through `STDIN` ignore `SIGHUP`.\n  * On `SIGTERM`, or `SIGINT`, attempt to send final stats and traces  before gracefully shutting down.\n* Added the ability to prevent certain GraphQL variables, by name, from being forwarded to Apollo Engine servers. The proxy replaces these variables with the string `(redacted)` in traces, so their presence can be verified but the value is not transmitted.\n\n  To blacklist GraphQL variables `password` and `secret`, add: `\"privateVariables\": [\"password\", \"secret\"]` within the `reporting` section of the configuration. There are no default private variables.\n* Added the option to disable reporting of stats and traces to Apollo servers, so that integration tests can run without polluting production data.\n\n To disable reporting, add `\"disabled\": true` within the `reporting` section of the configuration. Reporting is enabled by default.\n* Added the ability to forward log output to `STDOUT`, `STDERR`, or a file path. Previously logging was always sent to `STDERR`.\n\n To change log output, add `\"destination\": \"STDOUT\"` within the `logging` section of the configuration.\n Like query/request loggings, rotation of file logs is out of scope.\n* Fixed an issue where `Content-Type` values with parameters (e.g. `application/json;charset=utf=8`) would bypass GraphQL instrumentation.\n* Added support for the Automatic Persisted Queries protocol.\n\n### 2017.11-84-gb299b9188 - 2017-11-20\n\n* Fixed GraphQL parsing bugs that prevented handling requests containing list literals and object literals.\n* Added the ability for the proxy to output JSON formatted logs.\n* Fixed a bug with reverse proxying to HTTPS origins.\n\n### 2017.11-59-g4ff40ec30 - 2017-11-14\n\n* Fixed passing through custom fields on GraphQL errors.\n\n### 2017.11-40-g9585bfc6 - 2017-11-09\n\n* Fixed a bug where query parameters would be dropped from requests forwarded to origins.\n\n* Added the ability to send reports through an HTTP or SOCKS5 proxy.\n\n  To enable reporting through a proxy, set `\"proxyUrl\": \"http://192.168.1.1:3128\"` within the `reporting` section of the configuration.\n\n* Added support for transport level batching, like [apollo-link-batch-http](https://github.com/apollographql/apollo-link/tree/master/packages/apollo-link-batch-http).\n\n  By default, query batches are fractured by the proxy and individual queries are sent to origins, in parallel.\n  If your origin supports batching and you'd like to pass entire batches through, set `\"supportsBatch\": true` within the `origins` section of the configuration.\n\n* *BREAKING*: Changed behaviour when the proxy receives a non-GraphQL response from an origin server.\n  Previously the proxy would serve the non-GraphQL response, now it returns a valid GraphQL error indicating that the origin failed to respond.\n\n* Added support for the `includeInResponse` query extension. This allows clients to request GraphQL response extensions be forwarded through the proxy.\n\n  To instruct the proxy to strip extensions, set: `\"extensions\": { \"strip\": [\"cacheControl\", \"tracing\", \"myAwesomeExtension\"] }` within the `frontends` section of the configuration.\n  By default, Apollo extensions: `cacheControl` and `tracing` are stripped.\n\n  Stripped extensions may still be returned if the client requests them via the `includeInResponse` query extension.\n  To instruct the proxy to _never_ return extensions, set `\"extensions\": { \"blacklist\": [\"tracing\",\"mySecretExtension\"] }` within the `frontends` section of the configuration.\n  By default, the Apollo tracing extension: `tracing` is blacklisted.\n\n* *BREAKING*: Fixed a bug where literals in a query were ignored by query cache lookup. This change invalidates the current query cache.\n\n* Fixed a bug where the `X-Engine-From` header was not set in non-GraphQL requests forwarded to origins. This could result in an infinite request loop in the Node.js `apollo-engine` package.\n\n### 2017.10-431-gdc135a5d - 2017-10-26\n\n* Fixed an issue with per-type stats reporting.\n\n### 2017.10-425-gdd4873ae - 2017-10-26\n\n* Removed empty values in the request to server: `operationName`, `extensions`.\n* Improved error message when handling a request with GraphQL batching. Batching is still not supported at this time.\n\n\n### 2017.10-408-g497e1410\n\n* Removed limit on HTTP responses from origin server.\n* Fixed issue where the `apollo-engine` Node.js package would fail to clean up sidecar processes.\n* Switched query cache compression from LZ4 to Snappy.\n* *BREAKING*: Renamed the `logcfg` configuration section to `logging`.\n* *BREAKING*: Nested HTTP/Lambda origin configurations under child objects: `http` and `lambda`.\n* Added HTTP request logging, and GraphQL query logging options.\n\nThese changes mean that a basic configuration like:\n\n```\n{\n  \"apiKey\": \"<ENGINE_API_KEY>\",\n  \"logcfg\": {\n    \"level\": \"INFO\"\n  },\n  \"origins\": [\n    {\n      \"url\": \"http://localhost:3000/graphql\"\n    }\n  ],\n  \"frontends\": [\n    {\n      \"host\": \"127.0.0.1\",\n      \"port\": 3001,\n      \"endpoint\": \"/graphql\"\n    }\n  ]\n}\n```\n\nIs updated to:\n\n```\n{\n  \"apiKey\": \"<ENGINE_API_KEY>\",\n  \"logging\": {\n    \"level\": \"INFO\"\n  },\n  \"origins\": [\n    {\n      \"http\": {\n        \"url\": \"http://localhost:3000/graphql\"\n      }\n    }\n  ],\n  \"frontends\": [\n    {\n      \"host\": \"127.0.0.1\",\n      \"port\": 3001,\n      \"endpoint\": \"/graphql\"\n    }\n  ]\n}\n```\n\n### 2017.10-376-g0e29d5d5\n\n* Added (debug) log message to indicate if a query's trace was selected for reporting.\n* Fixed an issue where non-GraphQL errors (i.e. a `500` response with an HTML error page) would not be tracked as errors.\n","path":"/references/engine-proxy-release-notes","filePath":"docs/source/references/engine-proxy-release-notes.md"}]}],"localImages":{"assets/apollo-server.svg":"/static/apollo-server-ee7fbac9c0ca5b1dd6aef886bb695e63.svg","assets/engine-architecture.svg":"/static/engine-architecture-ba7f2c7ee5be9bb5011188ae29007476.svg","images/docs.svg":"/static/docs-b59a474b2fb0570c902833d93e1a625e.svg","images/fundamentals.svg":"/static/fundamentals-751b435fd96db75c65a162287342bf53.svg","images/guides.svg":"/static/guides-250d2bc5365d186c839942b48b352672.svg","images/index-get-started.svg":"/static/index-get-started-7a10feb59626e9bdc13c9db39cb43054.svg","images/manual.svg":"/static/manual-06178e29fd1a2c9d88d1a9afe28ead35.svg","images/persistedQueries.optPath.png":"/static/persistedQueries.optPath-98cb0f1ed777fbd3fb0d0701e41d5dee.png","img/account.billing.nav.png":"/static/account.billing.nav-c43fb1d50ab5f7e7c0676d14d09b27d6.png","img/engine-architecture.svg":"/static/engine-architecture-ba7f2c7ee5be9bb5011188ae29007476.svg","img/error.png":"/static/error-432f8f7802eae8a87ca41c8c4d309f8e.png","img/index-get-started.svg":"/static/index-get-started-7a10feb59626e9bdc13c9db39cb43054.svg","img/histogram.png":"/static/histogram-31340e74eb1d52d92a612fbcbcff729d.png","img/slack-setup-confirm.png":"/static/slack-setup-confirm-40b7285953993955a39fdbc6ba0f4d22.png","img/volume.png":"/static/volume-a031c5697c3702a32ba95acb78ef0858.png","img/integrations/slack-notification.png":"/static/slack-notification-4da2300985e218ab800eff749821c818.png","img/datadog/settings-link.png":"/static/settings-link-d7e922341e9e14e2dc77e8a886ad765a.png","img/apollo-engine/cache-hints.png":"/static/cache-hints-0255104ff1ad6edf5cbcd3fe4664532d.png","img/schema-validation/github-check.png":"/static/github-check-4a4238da8832c31605332a6a09ebd4b5.png","img/schema-validation/multi-github-check.png":"/static/multi-github-check-e095bc0eba1f4209a1df51b3cf3ce607.png","img/schema-history/schema-history.png":"/static/schema-history-4754f1046e1cbd09cfb0e694c478082a.png","img/setup-heroku/new-app.png":"/static/new-app-1a4fb1220072c0d2cc6eee851bcabd17.png","img/setup-heroku/create-app.png":"/static/create-app-4a2f86876c44baf7e8936fe595a6167b.png","assets/engine-field.png":"/static/engine-field-9bf148b0832c045767097b6cc5f2a6cf.png","images/graph-layer.png":"/static/graph-layer-6b46e9923358fe9219f762b94c58b45c.png","images/persistedQueries.newPath.png":"/static/persistedQueries.newPath-d500b543a6ad2a7d64ed7f190d40bd8c.png","img/heatmap.png":"/static/heatmap-831e22ea8e750bc7e3043215a20e078a.png","img/persistedQueries.optPath.png":"/static/persistedQueries.optPath-c39bec130a41f81c74391671a9c59074.png","img/persistedQueries.newPath.png":"/static/persistedQueries.newPath-ef211d56355771770478c10917a0901b.png","img/platform-diagram.png":"/static/platform-diagram-9f76c95ca7dea9f8d3f63b8d37b1ce0f.png","img/trace.png":"/static/trace-15bc5862604806e75c9f1fb1bbd0804c.png","img/client-awareness/field-usage.png":"/static/field-usage-963f97491e5bcd9388f1c4db8db99e17.png","img/datadog/datadog.png":"/static/datadog-d9dac87cddea6e2c36ea6803484cc33b.png","img/datadog/api-key.png":"/static/api-key-876acf317512f507e6e06db2d183d119.png","img/apollo-engine/cache-metrics.png":"/static/cache-metrics-865bf4119e5db00164c80c206d01907a.png","img/schema-history/github-diff.png":"/static/github-diff-f334e9dcc1707fd0346d6f10b530268a.png","img/setup-heroku/add-integration.png":"/static/add-integration-16177c9dad37bfd958f13854b44e8a2c.png","img/schema-history/schema-check.png":"/static/schema-check-fbfefbbf9b96c3d0ea83f689e6379cb3.png","assets/dev-tools.png":"/static/dev-tools-07a52e1ffc14e4f245f94c9f620e143e.png","assets/graphql-playground.png":"/static/graphql-playground-b2fa0c739348e9b91922a25e3b21890f.png","images/client-schema.png":"/static/client-schema-84ed12a64c4c57ba46fd55c0200625f1.png","images/schema-history.png":"/static/schema-history-63f8a91c30b6687ede7b5ae61b759e82.png","img/trace-inspector.png":"/static/trace-inspector-b79d4634fb4b3df152b6ca1eb3843524.png","img/traceWaterfall.png":"/static/traceWaterfall-f7e8839330bb8d53d2bff7dcad3a6994.png","img/setup-heroku/add-engine-key.png":"/static/add-engine-key-8f04108b588b4d40d3dfb6b527a0df5b.png","assets/engine-operation.png":"/static/engine-operation-b065ee96bbfeda9777cf1f3b35c0964c.png","images/alaunch.png":"/static/alaunch-be1b49c5bd490b83e43d8571bf8ae230.png","images/tips-apollo-engine-trace.png":"/static/tips-apollo-engine-trace-f8f8948f285f1f5d6393304b0269934d.png","img/overview.png":"/static/overview-26cafbefcab47df44c557c8f3e50efae.png","img/platform.jpg":"/static/platform-e80a1c35cc2a5400ab4a3f977fd4727c.jpg","images/editors/perf-annotation.png":"/static/perf-annotation-3f5358684bd5bf6cc808751425a8059f.png","images/launches.png":"/static/launches-83c2e0a3be0837c56f89f6167ec221d5.png","img/engine-architecture.png":"/static/engine-architecture-4ed38f5dc5db864eadddcdc4efeba67b.png","img/operation.png":"/static/operation-f6e3489e62927018998923a782d827aa.png","img/client-awareness/overview.png":"/static/overview-d6be789eb6757e6cd8f729ab53e890fb.png","images/editors/stats.gif":"/static/stats-aafa2f05ede89bf302dd36b52337cb3e.gif","img/integrations/integrations-tab.png":"/static/integrations-tab-a8d1a952049cc8969b71d90c46694442.png","img/integrations/slack-report.png":"/static/slack-report-654aa614b7e554f9260679b149d5a261.png","img/datadog/integration-tile.png":"/static/integration-tile-ac1e5d65c149af4a3703786e2e8c904e.png","img/schema-validation/service-check-page.png":"/static/service-check-page-1cead193c0c65131e50453559acef1ef.png","images/paginatedlaunches.png":"/static/paginatedlaunches-9332fd0a0679eeeec165328e639d6133.png","img/slack-setup-button.png":"/static/slack-setup-button-22e57bc5f41b1940b30bdf7c02f23b44.png","img/apollo-engine/engine-architecture.png":"/static/engine-architecture-4ed38f5dc5db864eadddcdc4efeba67b.png","img/slack-setup-popup.png":"/static/slack-setup-popup-0da8906197d6001a2f6a1c651a86aa21.png","img/client-awareness/cutover.png":"/static/cutover-ecbaae93dee3b59330da0f33945701a9.png","img/schema-explorer/explorer.png":"/static/explorer-d2f3d6c2571afba79768f4e3c2cc658d.png","img/datadog/settings-toggle.png":"/static/settings-toggle-6d976b5d78d9392b6367fe27732a246f.png","images/editors/jump-to-def.gif":"/static/jump-to-def-5355f10f27506ffbb51acca8d9cd891f.gif","images/editors/type-info.png":"/static/type-info-847eef5ed06f9609f59230a1808b0132.png","images/editors/warnings-and-errors.gif":"/static/warnings-and-errors-f3de1551ea13706f5329f9f94f14effd.gif","images/schematab.png":"/static/schematab-0774a4e5a5b324097895abb779c540ab.png","images/space-explorer.png":"/static/space-explorer-a81f37ed9dd7c56e7eb9ee3b52769e8d.png","img/schema-view/operation-schema-view.png":"/static/operation-schema-view-9a2f6d2bb54fe2829c05571652b802d5.png","img/schema-view/service-schema-view.png":"/static/service-schema-view-d7ad31d0a065c16a6039a1c18df20c23.png","images/moredetailsonatype.png":"/static/moredetailsonatype-b893f681b5b3bbcaf3ad9355bad8def6.png","images/editors/autocomplete.gif":"/static/autocomplete-d4cf44652b86bcb222ed6619c5b2ba0f.gif","assets/engine.png":"/static/engine-7b9cd78ee8057ac3cb3ebebefb36f9d0.png","images/noresolversjustquery.png":"/static/noresolversjustquery-f21bd417c9e97feeff3639f77c9e8700.png","images/introspection.png":"/static/introspection-23678a34fc9bee50688699ea13d9f4b6.png"},"owner":"apollographql","repo":"apollo","ref":"HEAD"}]}}